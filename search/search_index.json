{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"TheHive Project","text":"<p>This is the official documentation website of TheHive Project.</p>"},{"location":"#thehive-4","title":"TheHive 4","text":"<p>TheHive is a scalable, open source and free Security Incident Response Platform designed to make life easier for SOCs, CSIRTs, CERTs and any information security practitioner dealing with security incidents that need to be investigated and acted upon swiftly.</p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/TheHive-Project/TheHive</li> <li>Documentation: https://docs.thehive-project.org/docs/thehive/</li> </ul>"},{"location":"#thehive4py","title":"TheHive4py","text":"<p>TheHive4py is a Python API client for TheHive.</p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/TheHive-Project/TheHive4py</li> <li>Documentation: https://thehive-project.github.io/TheHive4py/</li> </ul>"},{"location":"#cortex","title":"Cortex","text":"<p>Cortex is a powerful observable analysis and active response engine.</p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/TheHive-Project/Cortex</li> <li>Documentation: https://github.com/TheHive-Project/CortexDocs</li> </ul>"},{"location":"#cortex-neurons","title":"Cortex Neurons","text":"<p>Cortex neurons is the repository of  the reviewed Analyzers and Responders, contributed by the community. </p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/TheHive-Project/Cortex-Analyzers/</li> <li>Documentation: https://thehive-project.github.io/Cortex-Analyzers/</li> </ul>"},{"location":"#cortex4py","title":"Cortex4py","text":"<p>Cortex4py is a Python API client for Cortex.</p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/TheHive-Project/Cortex4py</li> <li>Documentation: https://github.com/TheHive-Project/Cortex4py</li> </ul>"},{"location":"#cortexutils","title":"Cortexutils","text":"<p>Cortexutils is a Python library containing a set of classes that aims to make users write Cortex analyzers and responders easier.</p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/TheHive-Project/Cortexutils</li> <li>Documentation: https://github.com/TheHive-Project/Cortexutils</li> </ul>"},{"location":"#docker-templates","title":"Docker-templates","text":"<p>This repository is hosting docker configurations for TheHive, Cortex and 3rd party tools integrations.</p> <p></p> <p> </p> <ul> <li>Sources: https://github.com/TheHive-Project/Docker-Templates</li> </ul> <p></p>"},{"location":"#awesome","title":"Awesome","text":"<p>This repository aims at reference and centralise a curated list of awesome things related to TheHive &amp; Cortex.</p> <p></p> <p></p> <ul> <li>Website: https://github.com/TheHive-Project/awesome</li> </ul> <p></p>"},{"location":"#todo","title":"TODO","text":"<ul> <li>How to update to TheHive 4.1.0</li> <li>User Guides</li> </ul>"},{"location":"cortex/","title":"Home","text":"Cortex : Installation, operation and user guides    <p>Source Code: https://github.com/thehive-project/Cortex/</p> <p>Website: https://www.strangebee.com</p>"},{"location":"cortex/#cortex","title":"Cortex","text":"<p>Cortex solves two common problems frequently encountered by SOCs, CSIRTs and security researchers in the course of threat intelligence, digital forensics and incident response:</p> <ul> <li>How to analyze observables they have collected, at scale, by querying a single tool instead of several?</li> <li>How to actively respond to threats and interact with the constituency and other teams?</li> </ul> <p>Thanks to its many analyzers and to its RESTful API, Cortex makes observable analysis a breeze, particularly if called from TheHive, the highly popular, Security Incident Response Platform (SIRP). </p> <p>TheHive can also leverage Cortex responders to perform specific actions on alerts, cases, tasks and observables collected in the course of the investigation: send an email to the constituents, block an IP address at the proxy level, notify team members that an alert needs to be taken care of urgently and much more.</p> <p>Many features are included with Cortex: </p> <ul> <li>Manage multiple organizations (i.e multi-tenancy)</li> <li>Manage users per organizations and roles</li> <li>Specify per-org analyzer &amp; responder configuration</li> <li>Define rate limits: avoid consuming all your quotas at once</li> <li>Cache: an analysis is not re-executed for the same observable if a given analyzer is called on that observable several times within a specific timespan (10 minutes by default, can be adjusted for each analyzer).</li> </ul>"},{"location":"cortex/#installation-and-configuration-guides","title":"Installation and configuration guides","text":"<p>This documentation contains step-by-step installation instructions for Cortex for different operating systems as well as corresponding binary archives. </p> <p>All aspects of the configuration are aslo detailled in a dedicated section. s</p>"},{"location":"cortex/#user-guides","title":"User guides","text":"<p>The first connection to the application requires several actions. </p> <p>Cortex supports differents roles for users. Refer to User roles for more details.</p>"},{"location":"cortex/#license","title":"License","text":"<p>Cortex is an open source and free software released under the AGPL (Affero General Public License). We, StrangeBee, are committed to ensure that Cortex will remain a free and open source project on the long-run.</p>"},{"location":"cortex/#updates-and-community-discussions","title":"Updates and community discussions","text":"<p>Information, news and updates are regularly posted on several communication channels:</p> <p> TheHive Project Twitter account</p> <p> TheHive Project blog</p> <p> TheHive Project Discord</p> <p> Users forum on Google Groups. Request an access:</p> <ul> <li>using a Gmail address</li> <li>or without it.</li> </ul>"},{"location":"cortex/#contributing","title":"Contributing","text":"<p>We welcome your contributions. Please feel free to fork the code, play with it, make some patches and send us pull requests using issues.</p> <p>We do have a Code of conduct. Make sure to check it out before contributing.</p>"},{"location":"cortex/#community-support","title":"Community support","text":"<p>Please open an issue on GitHub if you'd like to report a bug or request a feature. We are also available on Discord to help you out.</p> <p>If you need to contact the Project's team, send an email to support@thehive-project.org.</p> <p>Note</p> <ul> <li>If you have problems with Cortex4py, please open an issue on its dedicated repository.</li> <li>If you encounter an issue with Cortex or would like to request a Cortex-related feature, please open an issue on its dedicated GitHub repository.</li> <li>If you have troubles with a Cortex analyzer or would like to request a new one or an improvement to an existing analyzer, please open an issue on the analyzers' dedicated GitHub repository.</li> </ul>"},{"location":"cortex/#professional-support","title":"Professional support","text":"<p> Since 2018, Cortex is fully developped and maintained by StrangeBee. Should you need specific assistance, be aware that StrangeBee also provides professional services and support. </p>"},{"location":"cortex/code-of-conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"cortex/code-of-conduct/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"cortex/code-of-conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or   advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic   address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"cortex/code-of-conduct/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior, in compliance with the licensing terms applying to the Project developments.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. However, these actions shall respect the licensing terms of the Project Developments that will always supersede such Code of Conduct.</p>"},{"location":"cortex/code-of-conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"cortex/code-of-conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at support@thehive-project.org. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"cortex/code-of-conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at http://contributor-covenant.org/version/1/4</p> <p>This version includes a clarification to ensure that the code of conduct is in compliance with the free software licensing terms of the project.</p>"},{"location":"cortex/api/api-guide/","title":"API Guide","text":"<p>This guide applies only to Cortex 2 and newer. It is not applicable to Cortex 1.</p>"},{"location":"cortex/api/api-guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Introduction<ul> <li>Request &amp; Response Formats</li> <li>Authentication</li> </ul> </li> <li>Organization APIs<ul> <li>Organization Model</li> <li>List</li> <li>Create</li> <li>Update</li> <li>Delete</li> <li>Obtain Details</li> <li>List Users</li> <li>List Enabled Analyzers</li> </ul> </li> <li>User APIs<ul> <li>User Model</li> <li>List All</li> <li>List Users within an Organization</li> <li>Search</li> <li>Create</li> <li>Update</li> <li>Get Details</li> <li>Set a Password</li> <li>Change a password</li> <li>Set and Renew an API Key</li> <li>Get an API Key</li> <li>Revoke an API Key</li> </ul> </li> <li>Job APIs<ul> <li>Job Model</li> <li>List and Search</li> <li>Get Details</li> <li>Get Details and Report</li> <li>Wait and Get Job Report</li> <li>Get Artifacts</li> <li>Delete</li> </ul> </li> <li>Analyzer APIs<ul> <li>Analyzer Model</li> <li>Enable</li> <li>List and Search</li> <li>Get Details</li> <li>Get By Type</li> <li>Update</li> <li>Run</li> <li>Disable</li> </ul> </li> <li>Miscellaneous APIs<ul> <li>Paging and Sorting</li> </ul> </li> </ul>"},{"location":"cortex/api/api-guide/#introduction","title":"Introduction","text":"<p>Cortex 2 offers a REST API that can be leveraged by various applications and programs to interact with it. The following guide describe the Cortex 2 API to allow developers to interface the powerful observable analysis engine with other SIRPs (Security Incident Response Platforms) besides TheHive, TIPs (Threat Intelligence Platforms), SIEMs or scripts. Please note that the Web UI of Cortex 2 exclusively leverage the REST API to interact with the back-end.</p> <p>Note: You can use Cortex4py, the Python library we provide, to facilitate interaction with the REST API of Cortex. You need Cortex4py 2.0.0 or later as earlier versions are not compatible with Cortex 2.</p> <p>All the exposed APIs share the same request &amp; response formats and authentication strategies as described below.</p> <p>There are also some transverse parameters supported by several calls, in addition to utility APIs.</p> <p>If you want to create an analyzer, please read the How to Write and Submit an Analyzer  guide.</p>"},{"location":"cortex/api/api-guide/#request-response-formats","title":"Request &amp; Response Formats","text":"<p>Cortex accepts several parameter formats within a HTTP request. They can be used indifferently. Input data can be:</p> <ul> <li>A query string</li> <li>A URL-encoded form</li> <li>A multi-part</li> <li>JSON</li> </ul> <p>Hence, the requests shown below are equivalent.</p>"},{"location":"cortex/api/api-guide/#query-string","title":"Query String","text":"<pre><code>curl -XPOST 'https://CORTEX_APP_URL:9001/api/login?user=me&amp;password=secret'\n</code></pre>"},{"location":"cortex/api/api-guide/#url-encoded-form","title":"URL-encoded Form","text":"<pre><code>curl -XPOST 'https://CORTEX_APP_URL:9001/api/login' -d user=me -d password=secret\n</code></pre>"},{"location":"cortex/api/api-guide/#json","title":"JSON","text":"<pre><code>curl -XPOST https://CORTEX_APP_URL:9001/api/login -H 'Content-Type: application/json' -d '{\n  \"user\": \"me\",\n  \"password\": \"secret\"\n}'\n</code></pre>"},{"location":"cortex/api/api-guide/#multi-part","title":"Multi-part","text":"<pre><code>curl -XPOST https://CORTEX_APP_URL:9001/api/login -F '_json=&lt;-;type=application/json' &lt;&lt; _EOF_\n{\n  \"user\": \"me\",\n  \"password\": \"secret\"\n}\n_EOF_\n</code></pre>"},{"location":"cortex/api/api-guide/#response-format","title":"Response Format","text":"<p>For each request submitted, Cortex will respond back with JSON data. For example, if the authentication request is successful, Cortex should return the following output:</p> <pre><code>{\"id\":\"me\",\"name\":\"me\",\"roles\":[\"read\",\"analyze\",\"orgadmin\"]}\n</code></pre> <p>If not, Cortex should return an authentication error:</p> <pre><code>{\"type\":\"AuthenticationError\",\"message\":\"Authentication failure\"}\n</code></pre>"},{"location":"cortex/api/api-guide/#authentication","title":"Authentication","text":"<p>Most API calls require authentication. Credentials can be provided using a session cookie, an API key or directly using HTTP basic authentication (if this method is specifically enabled).</p> <p>Session cookies are better suited for browser authentication. Hence, we recommend authenticating with API keys when calling the Cortex APIs.</p>"},{"location":"cortex/api/api-guide/#generating-api-keys-with-an-orgadmin-account","title":"Generating API Keys with an orgAdmin Account","text":"<p>API keys can be generated using the Web UI. To do so, connect using an <code>orgAdmin</code> account then click on Organization and then on the <code>Create API Key</code> button in the row corresponding to the user you intend to use for API authentication. Once the API key has been created, click on <code>Reveal</code> to display the API key then click on the copy to clipboard button if you wish to copy the key to your system's clipboard.</p> <p>If the user is not yet created, start by clicking on <code>Add user</code> to create it then follow the steps mentioned above.</p>"},{"location":"cortex/api/api-guide/#generating-api-keys-with-a-superadmin-account","title":"Generating API Keys with a superAdmin Account","text":"<p>You can use a <code>superAdmin</code> account to achieve the same result as described above. Once authenticated, click on Users then on the <code>Create API Key</code> button in the row corresponding to the user you intend to use for API authentication. Please make sure the user is in the right organization by thoroughly reading its name, which is shown below the user name. Once the API key has been created, click on <code>Reveal</code> to display the API key then click on the copy to clipboard button if you wish to copy the key to your system's clipboard.</p>"},{"location":"cortex/api/api-guide/#authenticating-with-an-api-key","title":"Authenticating with an API Key","text":"<p>Once you have generated an API key you can use it, for example, to list the Cortex jobs thanks to the following <code>curl</code> command:</p> <p><pre><code># Using API key\ncurl -H 'Authorization: Bearer **API_KEY**' https://CORTEX_APP_URL:9001/api/job\n</code></pre> As you can see in the example above, we instructed <code>curl</code> to add the Authorization header to the request. The value of the header is <code>Bearer: **API_KEY**</code>. So if your API key is <code>GPX20GUAQWwpqnhA6JpOwNGPMfWuxsX3</code>, the <code>curl</code> command above would look like the following:</p> <pre><code># Using API key\ncurl -H 'Authorization: Bearer GPX20GUAQWwpqnhA6JpOwNGPMfWuxsX3' https://CORTEX_APP_URL:9001/api/job\n</code></pre>"},{"location":"cortex/api/api-guide/#using-basic-authentication","title":"Using Basic Authentication","text":"<p>Cortex also supports basic authentication but it is disabled by default for security reasons. If you absolutely need to use it, you can enable it by adding <code>auth.method.basic=true</code> to the configuration file (<code>/etc/cortex/application.conf</code> by default). Once you do, restart the Cortex service. You can then, for example, list the Cortex jobs using the following <code>curl</code> command:</p> <pre><code># Using basic authentication\ncurl -u mylogin:mypassword https://CORTEX_APP_URL:9001/api/job\n</code></pre>"},{"location":"cortex/api/api-guide/#organization-apis","title":"Organization APIs","text":"<p>Cortex offers a set of APIs to create, update and list organizations.</p>"},{"location":"cortex/api/api-guide/#organization-model","title":"Organization Model","text":"<p>An organization (org) is defined by the following attributes:</p> Attribute Description Type <code>id</code> Copy of the org's name (see next row) readonly <code>name</code> Name readonly <code>status</code> Status (<code>Active</code> or <code>Locked</code>) writable <code>description</code> Description writable <code>createdAt</code> Creation date computed <code>createdBy</code> User who created the org computed <code>updatedAt</code> Last update computed <code>updatedBy</code> User who last updated the org computed <p>Please note that <code>id</code> and <code>name</code> are essentially the same. Also, <code>createdAt</code> and <code>updatedAt</code> are in epoch.</p>"},{"location":"cortex/api/api-guide/#list","title":"List","text":"<p>It is possible to list all the organizations using the following API call, which requires the API key associated with a <code>superAdmin</code> account:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization'\n</code></pre> <p>You can also search/filter organizations using the following query:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/organization/_search' -d '{\n  \"query\": {\"status\": \"Active\"}\n}'\n</code></pre> <p>Both APIs supports the <code>range</code> and <code>sort</code> query parameters described in paging and sorting details.</p>"},{"location":"cortex/api/api-guide/#create","title":"Create","text":"<p>It is possible to create an organization using the following API call, which requires the API key associated with a <code>superAdmin</code> account:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/organization' -d '{\n  \"name\": \"demo\",\n  \"description\": \"Demo organization\",\n  \"status\": \"Active\"\n}'\n</code></pre>"},{"location":"cortex/api/api-guide/#update","title":"Update","text":"<p>You can update an organization's description and status (<code>Active</code> or <code>Locked</code>) using the following API call. This requires the API key associated with a <code>superAdmin</code> account:</p> <pre><code>curl -XPATCH -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID' -d '{\n  \"description\": \"New Demo organization\",\n}'\n</code></pre> <p>or</p> <pre><code>curl -XPATCH -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID' -d '{\n  \"status\": \"Active\",\n}'\n</code></pre>"},{"location":"cortex/api/api-guide/#delete","title":"Delete","text":"<p>Deleting an organization just marks it as <code>Locked</code> and doesn't remove the associated data from the DB. To \"delete\" an organization, you can use the API call shown below. It requires the API key associated with a <code>superAdmin</code> account.</p> <pre><code>curl -XDELETE -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID'\n</code></pre>"},{"location":"cortex/api/api-guide/#obtain-details","title":"Obtain Details","text":"<p>This API call returns the details of an organization as described in the Organization model section.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID'\n</code></pre> <p>Let's assume that the organization we are seeking to obtain details about is called demo. The <code>curl</code> command would be:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization/demo'\n</code></pre> <p>and it should return:</p> <pre><code>{\n\"id\": \"demo\",\n\"name\": \"demo\",\n\"status\": \"Active\",\n\"description\": \"Demo organization\",\n\"createdAt\": 1520258040437,\n\"createdBy\": \"superadmin\",\n\"updatedBy\": \"superadmin\",\n\"updatedAt\": 1522077420693\n}\n</code></pre>"},{"location":"cortex/api/api-guide/#list-users","title":"List Users","text":"<p>As mentioned above, you can use the API to return the list of all the users declared withing an organization. For that purpose, use the API call shown below with the API key of an <code>orgAdmin</code> or <code>superAdmin</code> account. It supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID/user'\n</code></pre> <p>and should return a list of users.</p> <p>If one wants to filter/search for some users (active ones for example), there is a search API to use as below:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/organization/ORG_ID/user/_search' -d '{\n  \"query\": {}\n}'\n</code></pre> <p>It also supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details.</p>"},{"location":"cortex/api/api-guide/#list-enabled-analyzers","title":"List Enabled Analyzers","text":"<p>To list the analyzers that have been enabled within an organization, use the following API call with the API key of an <code>orgAdmin</code> user:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/analyzer'\n</code></pre> <p>It should return a list of Analyzers.</p> <p>Please note that this API call does not display analyzers that are disabled. It supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details.</p>"},{"location":"cortex/api/api-guide/#user-apis","title":"User APIs","text":"<p>The following section describes the APIs that allow creating, updating and listing users within an organization.</p>"},{"location":"cortex/api/api-guide/#user-model","title":"User Model","text":"<p>A user is defined by the following attributes:</p> Attribute Description Type <code>id</code> ID/login readonly <code>name</code> Name writable <code>roles</code> Roles. Possible values are: <code>read</code>, <code>read,analyze</code>, <code>read,analyze,orgadmin</code> and <code>superadmin</code> writable <code>status</code> Status (<code>Active</code> or <code>Locked</code>) writable <code>organization</code> organization to which the user belongs (set upon account creation) readonly <code>createdAt</code> Creation date computed <code>createdBy</code> User who created the account computed <code>updatedAt</code> Last update date computed <code>updatedBy</code> User who last updated the account computed <code>hasKey</code> true when the user has an API key computed <code>hasPassword</code> true if the user has a password computed"},{"location":"cortex/api/api-guide/#list-all","title":"List All","text":"<p>This API call allows a <code>superAdmin</code> to list and search all the users of all defined organizations:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/user'\n</code></pre> <p>This call supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details.</p>"},{"location":"cortex/api/api-guide/#list-users-within-an-organization","title":"List Users within an Organization","text":"<p>This call is described in organization APIs.</p>"},{"location":"cortex/api/api-guide/#search","title":"Search","text":"<p>This API call allows a <code>superAdmin</code> to perform search on the user accounts created in a Cortex instance:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/user/_search' -d '{\n  \"query\": {}\n}'\n</code></pre> <p>This call supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details</p>"},{"location":"cortex/api/api-guide/#create_1","title":"Create","text":"<p>This API calls allows you to programmatically create user creation. If the call is made by a <code>superAdmin</code> user, the request must specify the organization to which the user belong in the <code>organization</code> field.</p> <p>If the call is made by an <code>orgAdmin</code> user, the value of <code>organization</code> field must be the same as the user who makes the call: <code>orgAdmin</code> users are allowed to create users only in their organization.</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/user' -d '{\n  \"name\": \"Demo org Admin\",\n  \"roles\": [\n    \"read\",\n    \"analyze\",\n    \"orgadmin\"\n  ],\n  \"organization\": \"demo\",\n  \"login\": \"demo\"\n}'\n</code></pre> <p>If successful, the call returns a JSON object representing the created user as described above.</p> <pre><code>{\n\"id\": \"demo\",\n\"organization\": \"demo\",\n\"name\": \"Demo org Admin\",\n\"roles\": [\n\"read\",\n\"analyze\",\n\"orgadmin\"\n],\n\"status\": \"Ok\",\n\"createdAt\": 1526050123286,\n\"createdBy\": \"superadmin\",\n\"hasKey\": false,\n\"hasPassword\": false\n}\n</code></pre>"},{"location":"cortex/api/api-guide/#update_1","title":"Update","text":"<p>This API call allows updating the writable attributed of a user account. It's available to users with <code>superAdmin</code> or <code>orgAdmin</code> roles. Any user can also use it to update their own information (but obviously not their roles).</p> <pre><code>curl -XPATCH -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN' -d '{\n  \"name\": \"John Doe\",\n  \"roles\": [\n    \"read\",\n    \"analyze\"\n  ],\n  \"status\": \"Locked\"\n}'\n</code></pre> <p>It returns a JSON object representing the updated user as described above.</p>"},{"location":"cortex/api/api-guide/#get-details","title":"Get Details","text":"<p>This call returns the user details. It's available to users with <code>superAdmin</code> roles and to users in the same organization. Every user can also use it to read their own details.</p> <p><pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN'\n</code></pre> It returns a JSON object representing the user as described previously.</p>"},{"location":"cortex/api/api-guide/#set-a-password","title":"Set a Password","text":"<p>This call sets the user's password. It's available to users with <code>superAdmin</code> or <code>orgAdmin</code> roles. Please note that the request needs to be made using HTTPS with a valid certificate on the server's end to prevent credential sniffing or other PITM (Person-In-The-Middle) attacks.</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN/password/set' -d '{\n  \"password\": \"SOMEPASSWORD\"\n}'\n</code></pre> <p>If successful, the call returns 204 (success / no content).</p>"},{"location":"cortex/api/api-guide/#change-a-password","title":"Change a password","text":"<p>This call allows a given user to change only their own existing password. It is available to all users including <code>superAdmin</code> and <code>orgAdmin</code> ones. Please note that if a <code>superAdmin</code> or an <code>orgAdmin</code> needs to update the password of another user, they must use the <code>/password/set</code> call described in the previous subsection.</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN/password/change' -d '{\n  \"currentPassword\": \"password\",\n  \"password\": \"new-password\"\n}'\n</code></pre> <p>If successful, the call returns 204 (success / no content).</p>"},{"location":"cortex/api/api-guide/#set-and-renew-an-api-key","title":"Set and Renew an API Key","text":"<p>This calls allows setting and renewing the API key of a user. It's available to users with <code>superAdmin</code> or <code>orgAdmin</code> roles. Any user can also use it to renew their own API key. Again, the request needs to be made using HTTPS with a valid certificate on the server's end to prevent credential sniffing or other PITM (Person-In-The-Middle) attacks. You know the drill ;-)</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN/key/renew'\n</code></pre> <p>If successful, it returns the generated API key in a <code>text/plain</code>response.</p>"},{"location":"cortex/api/api-guide/#get-an-api-key","title":"Get an API Key","text":"<p>This calls allows getting a user's API key. It's available to users with <code>superAdmin</code> or <code>orgAdmin</code> roles. Any user can also use it to obtain their own API key.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN/key'\n</code></pre> <p>If successful, the generated API key is returned in <code>text/plain</code>response</p>"},{"location":"cortex/api/api-guide/#revoke-an-api-key","title":"Revoke an API Key","text":"<p>This calls allow revoking a user's API key. This calls allow revoking a user's API key.</p> <pre><code>curl -XDELETE -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/user/USER_LOGIN/key'\n</code></pre> <p>A successful request returns nothing (HTTP 200 OK).</p>"},{"location":"cortex/api/api-guide/#job-apis","title":"Job APIs","text":"<p>The following section describes the APIs that allow manipulating jobs. Jobs are basically submissions made to analyzers and the resulting reports.</p>"},{"location":"cortex/api/api-guide/#job-model","title":"Job Model","text":"<p>A job is defined by the following attributes:</p> Attribute Description Type <code>id</code> Job ID computed <code>organization</code> The organization to which the job belongs readonly <code>analyzerDefinitionId</code> Analyzer definition name readonly <code>analyzerId</code> Instance ID of the analyzer to which the job is associated readonly <code>organization</code> Organization to which the user belongs (set upon account creation) readonly <code>analyzerName</code> Name of the analyzer to which the job is associated readonly <code>dataType</code> the datatype of the analyzed observable readonly <code>status</code> Status of the job (<code>Waiting</code>, <code>InProgress</code>, <code>Success</code>, <code>Failure</code>, <code>Deleted</code>) computed <code>data</code> Value of the analyzed observable (does not apply to <code>file</code> observables) readonly <code>attachment</code> JSON object representing <code>file</code> observables (does not apply to non-<code>file</code> observables). It  defines the<code>name</code>, <code>hashes</code>, <code>size</code>, <code>contentType</code> and <code>id</code> of the <code>file</code> observable readonly <code>parameters</code> JSON object of key/value pairs set during job creation readonly <code>message</code> A free text field to set additional text/context for a job readonly <code>tlp</code> The TLP of the analyzed observable readonly <code>startDate</code> Start date computed <code>endDate</code> End date computed <code>createdAt</code> Creation date. Please note that a job can be requested but not immediately honored. The actual time at which it is started is the value of <code>startDate</code> computed <code>createdBy</code> User who created the job computed <code>updatedAt</code> Last update date (only Cortex updates a job when it finishes) computed <code>updatedBy</code> User who submitted the job and which identity is used by Cortex to update the job once it is finished computed"},{"location":"cortex/api/api-guide/#list-and-search","title":"List and Search","text":"<p>This call allows a user with <code>read</code>,<code>analyze</code> or <code>orgAdmin</code> role to list and search all the analysis jobs made by their organization.</p> <p>If you want to list all the jobs: <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/_search?range=all'\n</code></pre></p> <p>If you want to list 10 jobs: <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/_search'\n</code></pre></p> <p>If you want to list 100 jobs: <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/_search?range=0-100'\n</code></pre></p> <p>If you want to search jobs according to various criteria: <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/job/_search' -d '{\n  \"query\": {\n    \"_and\": [\n      {\"status\": \"Success\"},\n      {\"dataType\": \"ip\"}\n    ]\n  }\n}'\n</code></pre></p> <p>This call supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details</p>"},{"location":"cortex/api/api-guide/#get-details_1","title":"Get Details","text":"<p>This call allows a user with <code>read</code>,<code>analyze</code> or <code>orgAdmin</code> role to get the details of a job. It does not fetch the job report.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/JOB_ID'\n</code></pre> <p>It returns a JSON response with the following structure:</p> <pre><code>{\n\"id\": \"AWNei4vH3rJ8unegCPB9\",\n\"analyzerDefinitionId\": \"Abuse_Finder_2_0\",\n\"analyzerId\": \"220483fde9608c580fb6a2508ff3d2d3\",\n\"analyzerName\": \"Abuse_Finder_2_0\",\n\"status\": \"Success\",\n\"data\": \"8.8.8.8\",\n\"parameters\": \"{}\",\n\"tlp\": 0,\n\"message\": \"\",\n\"dataType\": \"ip\",\n\"organization\": \"demo\",\n\"startDate\": 1526299593923,\n\"endDate\": 1526299597064,\n\"date\": 1526299593633,\n\"createdAt\": 1526299593633,\n\"createdBy\": \"demo\",\n\"updatedAt\": 1526299597066,\n\"updatedBy\": \"demo\"\n}\n</code></pre>"},{"location":"cortex/api/api-guide/#get-details-and-report","title":"Get Details and Report","text":"<p>This call allows a user with <code>read</code>,<code>analyze</code> or <code>orgAdmin</code> role to get the details of a job including its report.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/JOB_ID/report'\n</code></pre> <p>It returns a JSON response with the structure below. If the job is not yet completed, the <code>report</code> field contains a string representing the job status:</p> <pre><code>{\n\"id\": \"AWNei4vH3rJ8unegCPB9\",\n\"analyzerDefinitionId\": \"Abuse_Finder_2_0\",\n\"analyzerId\": \"220483fde9608c580fb6a2508ff3d2d3\",\n\"analyzerName\": \"Abuse_Finder_2_0\",\n\"status\": \"Success\",\n\"data\": \"8.8.8.8\",\n\"parameters\": \"{}\",\n\"tlp\": 0,\n\"message\": \"\",\n\"dataType\": \"ip\",\n\"organization\": \"demo\",\n\"startDate\": 1526299593923,\n\"endDate\": 1526299597064,\n\"date\": 1526299593633,\n\"createdAt\": 1526299593633,\n\"createdBy\": \"demo\",\n\"updatedAt\": 1526299597066,\n\"updatedBy\": \"demo\",\n\"report\": {\n\"summary\": {\n\"taxonomies\": [\n{\n\"predicate\": \"Address\",\n\"namespace\": \"Abuse_Finder\",\n\"value\": \"network-abuse@google.com\",\n\"level\": \"info\"\n}\n]\n},\n\"full\": {\n\"abuse_finder\": {\n\"raw\": \"...\",\n\"abuse\": [\n\"network-abuse@google.com\"\n],\n\"names\": [\n\"Google LLC\",\n\"Level 3 Parent, LLC\"\n],\n\"value\": \"8.8.8.8\"\n}\n},\n\"success\": true,\n\"artifacts\": []\n}\n}\n</code></pre>"},{"location":"cortex/api/api-guide/#wait-and-get-job-report","title":"Wait and Get Job Report","text":"<p>This call is similar the one described above but allows the user to provide a timeout to wait for the report in case it is not available at the time the query was made:</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/JOB_ID/waitreport?atMost=1minute'\n</code></pre> <p>The <code>atMost</code> is a duration using the format <code>Xhour</code>, <code>Xminute</code> or <code>Xsecond</code>.</p>"},{"location":"cortex/api/api-guide/#get-artifacts","title":"Get Artifacts","text":"<p>This call allows a user with <code>read</code>,<code>analyze</code> or <code>orgAdmin</code> role to get the extracted artifacts from a job if such extraction has been enabled in the corresponding analyzer configuration. Please note that extraction is imperfect and you might have inconsistent or incorrect data.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/JOB_ID/artifacts'\n</code></pre> <p>It returns a JSON array with the following structure:</p> <pre><code>[\n{\n\"dataType\": \"ip\",\n\"createdBy\": \"demo\",\n\"data\": \"8.8.8.8\",\n\"tlp\": 0,\n\"createdAt\": 1525432900553,\n\"id\": \"AWMq4tvLjidKq_asiwcl\"\n}\n]\n</code></pre>"},{"location":"cortex/api/api-guide/#delete_1","title":"Delete","text":"<p>This API allows a user with <code>analyze</code> or <code>orgAdmin</code> role to delete a job:</p> <pre><code>curl -XDELETE -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/job/JOB_ID'\n</code></pre> <p>This marks the job as <code>Deleted</code>. However the job's data is not removed from the  database.</p>"},{"location":"cortex/api/api-guide/#analyzer-apis","title":"Analyzer APIs","text":"<p>The following section describes the APIs that allow manipulating analyzers.</p>"},{"location":"cortex/api/api-guide/#analyzer-model","title":"Analyzer Model","text":"<p>An analyzer is defined by the following attributes:</p> Attribute Description Type <code>id</code> Analyzer ID once enabled within an organization readonly <code>analyzerDefinitionId</code> Analyzer definition name readonly <code>name</code> Name of the analyzer readonly <code>version</code> Version of the analyzer readonly <code>description</code> Description of the analyzer readonly <code>author</code> Author of the analyzer readonly <code>url</code> URL where the analyzer has been published readonly <code>license</code> License of the analyzer readonly <code>dataTypeList</code> Allowed datatypes readonly <code>baseConfig</code> Base configuration name. This identifies the shared set of configuration with all the analyzer's flavors readonly <code>jobCache</code> Report cache timeout in minutes, visible for <code>orgAdmin</code> users only writable <code>rate</code> Numeric amount of analyzer calls authorized for the specified <code>rateUnit</code>, visible for <code>orgAdmin</code> users only writable <code>rateUnit</code> Period of availability of the rate limite: <code>Day</code> or <code>Month</code>, visible for <code>orgAdmin</code> users only writable <code>configuration</code> A JSON object where key/value pairs represent the config names, and their values. It includes the default properties <code>proxy_http</code>, <code>proxy_https</code>, <code>auto_extract_artifacts</code>, <code>check_tlp</code>, and <code>max_tlp</code>, visible for <code>orgAdmin</code> users only writable <code>createdBy</code> User who enabled the analyzer computed <code>updatedAt</code> Last update date computed <code>updatedBy</code> User who last updated the analyzer computed"},{"location":"cortex/api/api-guide/#enable","title":"Enable","text":"<p>This call allows a user with an <code>orgAdmin</code> role to enable an analyzer.</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/organization/analyzer/:analyzerId' -d '{\n  \"name\": \"Censys_1_0\",\n  \"configuration\": {\n    \"uid\": \"XXXX\",\n    \"key\": \"XXXXXXXXXXXXXXXXXXXX\",\n    \"proxy_http\": \"http://proxy:9999\",\n    \"proxy_https\": \"http://proxy:9999\",\n    \"auto_extract_artifacts\": false,\n    \"check_tlp\": true,\n    \"max_tlp\": 2\n  },\n  \"rate\": 1000,\n  \"rateUnit\": \"Day\",\n  \"jobCache\": 5\n}'\n</code></pre>"},{"location":"cortex/api/api-guide/#list-and-search_1","title":"List and Search","text":"<p>These calls allow a user with a <code>analyze</code> or <code>orgAdmin</code> role to list and search all the enabled analyzers within the organization.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/analyzer'\n</code></pre> <p>or</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/analyzer/_search' -d '{\n  \"query\": {}\n}'\n</code></pre> <p>Both calls supports the <code>range</code> and <code>sort</code> query parameters declared in paging and sorting details, and both return a JSON array of analyzer objects as described in Analyzer Model section.</p> <p>If called by a user with only an <code>nalyzer</code> role, the <code>configuration</code> attribute is not included on the JSON objects.</p>"},{"location":"cortex/api/api-guide/#get-details_2","title":"Get Details","text":"<p>This call allows a user with a <code>analyze</code> or <code>orgAdmin</code> role to get an analyzer's details.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID'\n</code></pre> <p>It returns a analyzer JSON object as described in Analyzer Model section.</p> <p>If called by a user with only an <code>nalyzer</code> role, the <code>configuration</code> attribute is not included on the JSON objects.</p>"},{"location":"cortex/api/api-guide/#get-by-type","title":"Get By Type","text":"<p>This call is mostly used by TheHive and allows to quickly get the list of analyzers that can run on the given datatype. It requires an <code>analyze</code> or <code>orgAdmin</code> role.</p> <pre><code>curl -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/analyzer/type/DATA_TYPE'\n</code></pre> <p>It returns a JSON array of analyzer objects as described in Analyzer Model section without the <code>configuration</code> attribute, which could contain sensitive data.</p>"},{"location":"cortex/api/api-guide/#update_2","title":"Update","text":"<p>This call allows an <code>orgAdmin</code> user to update the <code>name</code>, <code>configuration</code> and <code>jobCache</code> of an enabled analyzer.</p> <pre><code>curl -XPATCH -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID' -d '{\n  \"configuration\": {\n    \"key\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n    \"polling_interval\": 60,\n    \"proxy_http\": \"http://localhost:8080\",\n    \"proxy_https\": \"http://localhost:8080\",\n    \"auto_extract_artifacts\": true,\n    \"check_tlp\": true,\n    \"max_tlp\": 1\n  },\n  \"name\": \"Shodan_Host_1_0\",\n  \"rate\": 1000,\n  \"rateUnit\": \"Day\",\n  \"jobCache\": null\n}'\n</code></pre> <p>It returns a JSON object describing the analyzer as defined in Analyzer Model section.</p>"},{"location":"cortex/api/api-guide/#run","title":"Run","text":"<p>This API allows a user with a <code>analyze</code> or <code>orgAdmin</code> role to run analyzers on observables of different datatypes.</p> <p>For <code>file</code> observables, the API call must be made as described below:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID/run' \\\n-F 'attachment=@/path/to/observable-file' \\\n-F '_json=&lt;-;type=application/json' &lt;&lt; _EOF_\n  {\n    \"dataType\":\"file\",\n    \"tlp\":0\n  }\n_EOF_\n</code></pre> <p>for all the other types of observerables, the request is:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID/run' -d '{\n  \"data\":\"8.8.8.8\",\n  \"dataType\":\"ip\",\n  \"tlp\":0,\n  \"message\": \"A message that can be accessed from the analyzer\",\n  \"parameters\": {\n    \"key1\": \"value1\",\n    \"key2\": \"value2\"\n  }\n}'\n</code></pre> <p>This call will fetch a similar job from the cache, and if it finds one, it returns it from the cache, based on the duration defined in <code>jobCache</code> attribute of the analyzer.</p> <p>To force bypassing the cache, one can add the following query parameter: <code>force=1</code></p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID/run?force=1' -d '{\n  \"data\":\"8.8.8.8\",\n  \"dataType\":\"ip\",\n  \"tlp\":0,\n  \"message\": \"A message that can be accessed from the analyzer\",\n  \"parameters\": {\n    \"key1\": \"value1\",\n    \"key2\": \"value2\"\n  }\n}'\n</code></pre>"},{"location":"cortex/api/api-guide/#disable","title":"Disable","text":"<p>This API allows an <code>orgAdmin</code> to disable an existing analyzer in their organization and delete the corresponding configuration.</p> <pre><code>curl -XDELETE -H 'Authorization: Bearer **API_KEY**' 'https://CORTEX_APP_URL:9001/api/analyzer/ANALYZER_ID'\n</code></pre>"},{"location":"cortex/api/api-guide/#miscellaneous-apis","title":"Miscellaneous APIs","text":""},{"location":"cortex/api/api-guide/#paging-and-sorting","title":"Paging and Sorting","text":"<p>All the <code>search</code> API calls allow sorting and paging parameters, in addition to a query in the request's body. These calls usually have URLs ending with the <code>_search</code> keyword but that's not always the case.</p> <p>The followings are query parameters:</p> <ul> <li><code>range</code>: <code>all</code> or <code>x-y</code> where <code>x</code> and <code>y</code> are numbers (ex: 0-10).</li> <li><code>sort</code>: you can provide multiple sort criteria such as: <code>-createdAt</code> or <code>+status</code>.</li> </ul> <p>Example:</p> <pre><code>curl -XPOST -H 'Authorization: Bearer **API_KEY**' -H 'Content-Type: application/json' 'http://CORTEX_APP_URL:9001/api/organization/ORG_ID/user?range=0-10&amp;sort=-createdAt&amp;sort=+status' -d '{\n  \"query\": {}\n}'\n</code></pre>"},{"location":"cortex/api/how-to-create-a-responder/","title":"How to Write and Submit a Responder","text":""},{"location":"cortex/api/how-to-create-a-responder/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Writing a Responder<ul> <li>The Program</li> <li>Service Interaction Files (Flavors)</li> <li>Python Requirements</li> <li>Example: Mailer Responder Files</li> <li>Input</li> <li>Service Interaction Configuration Items</li> <li>Responder Configuration in the Global Configuration File</li> <li>Output</li> <li>The Cortexutils Python Library</li> </ul> </li> <li>Submitting a Responder<ul> <li>Check Existing Issues</li> <li>Open an Issue</li> <li>Review your Service Interaction File(s)</li> <li>Provide the List of Requirements</li> <li>Verify Execution</li> <li>Create a Pull Request</li> </ul> </li> <li>Need Help?</li> </ul>"},{"location":"cortex/api/how-to-create-a-responder/#writing-a-responder","title":"Writing a Responder","text":"<p>A responder is a program that takes JSON input and do an action and produces a basic result of that action. Responders are very similar to analyzers though they have different purposes. Responders are made of at least 2 types of files:</p> <ul> <li>The program itself</li> <li>One or several service interaction files or flavors</li> <li>A Python requirements file, which is only necessary if the responder is written in Python.</li> </ul>"},{"location":"cortex/api/how-to-create-a-responder/#the-program","title":"The Program","text":"<p>The first type of files a responder is made of is the core program that performs actions. It can be written in any programming language that is supported by Linux.</p> <p>you can write your responders in Python, Ruby, Perl or even Scala. However, the very handy <code>Cortexutils</code> library described below is in Python. It greatly facilitates responder development and it also provides some methods to quickly format the output to make it compliant with the JSON schema expected by TheHive.</p>"},{"location":"cortex/api/how-to-create-a-responder/#service-interaction-files-flavors","title":"Service Interaction Files (Flavors)","text":"<p>A responder must have at least one service interaction file. Such files contain key configuration information such as the responder's author information, the datatypes (<code>thehive:case</code>, <code>thehive:alert</code>, ...) the responder accepts as input and to which it applies to if used from TheHive, the TLP and PAP (or Permissible Actions Protocol) above which it will refuse to execute to protect against data leakage and to enforce sane OPSEC practices and so on.</p> <p>A responder can have two or more service interaction files to allow it to perform different actions.  We speak then of flavors. For example, a Mailer responder can send message using several body templates.</p>"},{"location":"cortex/api/how-to-create-a-responder/#python-requirements","title":"Python Requirements","text":"<p>If the responder is written in Python, a <code>requirements.txt</code> must be provided with the list of all the dependencies.</p>"},{"location":"cortex/api/how-to-create-a-responder/#example-mailer-responder-files","title":"Example: Mailer Responder Files","text":"<p>Below is a directory listing of the files corresponding to a Mailer responder.</p> <pre><code>responders/Mailer\n|-- Mailer.json\n|-- requirements.txt\n`-- mailer.py\n</code></pre>"},{"location":"cortex/api/how-to-create-a-responder/#input","title":"Input","text":"<p>The input of a responder can be any JSON data, even a simple string. The submitter must send data with the structure expected by the program. The acceptable datatypes described in the Service Interaction files indicate what kind of data is expected. For example, if the program requires a <code>thehive:case</code> (i.e. it applies at the case level in TheHive), input must comply with TheHive case. Below an example of <code>thehive:case</code> input.</p> <pre><code>    {\n\"data\": {\n\"updatedAt\": 1606230814019,\n\"tlp\": 2,\n\"endDate\": 1606230814019,\n\"description\": \"Case Description\",\n\"tags\": [\n\"tag\"\n],\n\"caseId\": 157,\n\"customFields\": {},\n\"pap\": 2,\n\"status\": \"Open\",\n\"resolutionStatus\": \"Indeterminate\",\n\"createdAt\": 1606183201646,\n\"createdBy\": \"user\",\n\"flag\": false,\n\"severity\": 2,\n\"metrics\": {},\n\"owner\": \"user\",\n\"title\": \"Title\",\n\"updatedBy\": \"user\",\n\"startDate\": 1606183201000,\n\"impactStatus\": \"NotApplicable\",\n\"_type\": \"case\",\n\"_routing\": \"iwD693UBlJefU8pMrqOq\",\n\"_parent\": null,\n\"_id\": \"iwD693UBlJefU8pMrqOq\",\n\"_seqNo\": 4572,\n\"_primaryTerm\": 48,\n\"id\": \"iwD693UBlJefU8pMrqOq\"\n},\n\"dataType\": \"thehive:case\",\n\"tlp\": 2,\n\"pap\": 2,\n\"message\": \"\",\n\"parameters\": {\n\"user\": \"user\"\n},\n\"config\": {\n\"proxy_https\": null,\n\"cacerts\": null,\n\"max_pap\": 2,\n\"jobTimeout\": 30,\n\"api_key\": \"3bDBUb7EL409MHOmXBkqsysZ1vpTab1Q\",\n\"check_tlp\": true,\n\"proxy_http\": null,\n\"max_tlp\": 2,\n\"url\": \"configured_url\",\n\"check_pap\": true\n}\n}\n</code></pre> <p>In the addition to the input (<code>data</code> section) sent by the submitter, Cortex adds the <code>config</code> section which is the responder's specific configuration provided by an <code>orgAdmin</code> user when the responder is enabled in the Cortex UI. </p>"},{"location":"cortex/api/how-to-create-a-responder/#example-service-interaction-file-for-the-mailer-responder","title":"Example: Service Interaction File for the Mailer Responder","text":"<p>The <code>&lt;==</code> sign and anything after it are comments that do no appear in the original file. <pre><code>{\n\"name\": \"Mailer\",\n\"version\": \"1.0\",\n\"author\": \"CERT-BDF\",\n\"url\": \"https://github.com/TheHive-Project/Cortex-Analyzers\",\n\"license\": \"AGPL-V3\",\n\"description\": \"Send an email with information from a TheHive case or alert\",\n\"dataTypeList\": [\"thehive:case\", \"thehive:alert\", \"thehive:case_task\"],\n\"command\": \"Mailer/mailer.py\",\n\"baseConfig\": \"Mailer\",\n\"configurationItems\": [\n{\n\"name\": \"from\",\n\"description\": \"email address from which the mail is send\",\n\"type\": \"string\", &lt;== defines what kind of data type the configuration item is (string, number)\n\"multi\": false, &lt;== setting multi to true allows to pass a list of items\n\"required\": true\n},\n{\n\"name\": \"smtp_host\",\n\"description\": \"SMTP server used to send mail\",\n\"type\": \"string\",\n\"multi\": false,\n\"required\": true,\n\"defaultValue\": \"localhost\"\n},\n{\n\"name\": \"smtp_port\",\n\"description\": \"SMTP server port\",\n\"type\": \"number\",\n\"multi\": false,\n\"required\": true,\n\"defaultValue\": 25\n},\n{\n\"name\": \"smtp_user\",\n\"description\": \"SMTP server user\",\n\"type\": \"string\",\n\"multi\": false,\n\"required\": false,\n\"defaultValue\": \"user\"\n},\n{\n\"name\": \"smtp_pwd\",\n\"description\": \"SMTP server password\",\n\"type\": \"string\",\n\"multi\": false,\n\"required\": false,\n\"defaultValue\": \"pwd\"\n}\n]\n}\n</code></pre></p>"},{"location":"cortex/api/how-to-create-a-responder/#service-interaction-configuration-items","title":"Service Interaction Configuration Items","text":""},{"location":"cortex/api/how-to-create-a-responder/#name","title":"name","text":"<p>Name of the specific service (or flavor) of the responder.</p> <p>If your responder has only one service interaction (i.e. performs only one action), it is the name of the responder's directory.</p> <p>If your responder performs several actions (i.e. comes in several flavors), you have to give a specific and meaningful name to each flavor.</p> <p>Each flavor's name appear in TheHive's responder list and in MISP when you use Cortex for attribute enrichment.</p>"},{"location":"cortex/api/how-to-create-a-responder/#version","title":"version","text":"<p>The version of the responder.</p> <p>You must increase major version numbers when new features are added, modifications are made to take into account API changes, report output is modified or when report templates (more on this later) are updated.</p> <p>You must increase minor version numbers when bugs are fixed.</p>"},{"location":"cortex/api/how-to-create-a-responder/#author","title":"author","text":"<p>You must provide your full name and/or your organization/team name when submitting a responder. Pseudos are not accepted. If you'd rather remain anonymous, please contact us at support@thehive-project.org prior to submitting your responder.</p>"},{"location":"cortex/api/how-to-create-a-responder/#url","title":"url","text":"<p>The URL where the responder is stored. This should ideally be <code>https://github.com/TheHive-Project/Cortex-Analyzers</code></p>"},{"location":"cortex/api/how-to-create-a-responder/#license","title":"license","text":"<p>The license of the code. Ideally, we recommend using the AGPL-v3 license.</p> <p>Make sure your code's license is compatible with the license(s) of the various components and libraries you use if applicable.</p>"},{"location":"cortex/api/how-to-create-a-responder/#description","title":"description","text":"<p>Description of the responder. Please be concise and clear. The description is  shown in the Cortex UI and TheHive.</p>"},{"location":"cortex/api/how-to-create-a-responder/#datatypelist","title":"dataTypeList","text":"<p>The list of TheHive datatypes supported by the responder. Currently TheHive accepts the following datatypes:</p> <ul> <li><code>thehive:case</code></li> <li><code>thehive:case_artifact</code> (i.e. observable)</li> <li><code>thehive:alert</code></li> <li><code>thehive:case_task</code></li> <li><code>thehive:case_task_log</code> (i.e. task log)</li> </ul>"},{"location":"cortex/api/how-to-create-a-responder/#baseconfig","title":"baseConfig","text":"<p>Name used to group configuration items common to several responders. This prevent the user to enter the same API key for all responder flavors. The Cortex responder config page group configuration items by their <code>baseConfig</code>.</p>"},{"location":"cortex/api/how-to-create-a-responder/#config","title":"config","text":"<p>Configuration dedicated to the responder's flavor. This is where we  typically specify the TLP level of observables allowed to be analyzed with the  <code>check_tlp</code> and <code>max_tlp</code> parameters. For example, if <code>max_tlp</code> is set to <code>2</code> (TLP:AMBER), TLP:RED observables cannot be analyzed.</p>"},{"location":"cortex/api/how-to-create-a-responder/#max_tlp","title":"max_tlp","text":"<p>The TLP level above which the responder must not be executed.</p> TLP max_tlp value Unknown -1 WHITE 0 GREEN 1 AMBER 2 RED 3"},{"location":"cortex/api/how-to-create-a-responder/#check_tlp","title":"check_tlp","text":"<p>This is a boolean parameter. When <code>true</code>, <code>max_tlp</code> is checked. And if the input's TLP is above <code>max_tlp</code>, the responder is not executed.</p> <p>For consistency reasons, we do recommend setting both <code>check_tlp</code> and <code>max_tlp</code> even if <code>check_tlp</code> is set to <code>false</code>.</p>"},{"location":"cortex/api/how-to-create-a-responder/#max_pap","title":"max_pap","text":"<p>The PAP level above which the responder must not be executed.</p> TLP max_tlp value Unknown -1 WHITE 0 GREEN 1 AMBER 2 RED 3"},{"location":"cortex/api/how-to-create-a-responder/#check_pap","title":"check_pap","text":"<p>This is a boolean parameter. When <code>true</code>, <code>max_pap</code> is checked. And if the input's PAP is above <code>max_pap</code>, the responder is not executed.</p> <p>For consistency reasons, we do recommend setting both <code>check_pap</code> and <code>max_pap</code> even if <code>check_pap</code> is set to <code>false</code>.</p>"},{"location":"cortex/api/how-to-create-a-responder/#command","title":"command","text":"<p>The command used to run the responder. That's typically the full, absolute path to the main program file.</p>"},{"location":"cortex/api/how-to-create-a-responder/#configurationitems","title":"configurationItems","text":"<p>The list of configurationItems is necessary in order to be able to set all configuration variables for responders directly in the Cortex 2 user interface. As in the VirusTotal example above can be seen, every item is a json object that defines: - name (string) - description (string) - type (string) - multi (boolean) - required (boolean) - defaultValue (according to type, optional)</p> <p>The <code>multi</code> parameter allows to pass a list as configuration variable instead of a single string or number. This is used e.g. in the MISP responder that queries multiple servers in one run and needs different parameters for that.</p>"},{"location":"cortex/api/how-to-create-a-responder/#output","title":"Output","text":"<p>The output of a responder depends on the success or failure of its execution.</p> <p>If the responder fails to execute:</p> <pre><code>{\n\"success\": false,\n\"errorMessage\":\"..\"\n}\n</code></pre> <ul> <li>When <code>success</code> is set to <code>false</code>, it indicates that something went wrong     during the execution.</li> <li><code>errorMessage</code> is free text - typically the error output message.</li> </ul> <p>If the responder succeeds (i.e. it runs without any error):</p> <pre><code>{\n\"success\":true,\n\"full\":{ \"message\": \"..\" },\n\"operations\":[]\n}\n</code></pre> <ul> <li>When <code>success</code> is set to <code>true</code>, it indicates that the responder ran     successfully.</li> <li><code>full</code> is the full report of the responder. It must contain at least     a message.</li> <li><code>operations</code> is a list what the submitter system should execute.     As of version 3.1.0, TheHive accepts the following operations:<ul> <li><code>AddTagToArtifact</code> (<code>{ \"type\": \"AddTagToArtifact\", \"tag\": \"tag to add\" }</code>): add      a tag to the artifact related to the object</li> <li><code>AddTagToCase</code> (<code>{ \"type\": \"AddTagToCase\", \"tag\": \"tag to add\" }</code>): add      a tag to the case related to the object</li> <li><code>MarkAlertAsRead</code>: mark the alert related to the object as read</li> <li><code>AddCustomFields</code> (<code>{\"name\": \"key\", \"value\": \"value\", \"tpe\": \"type\"</code>): add a custom field to the case related to the object</li> </ul> </li> </ul> <p>The list of acceptable operations will increase in future releases of TheHive.</p>"},{"location":"cortex/api/how-to-create-a-responder/#the-cortexutils-python-library","title":"The Cortexutils Python Library","text":"<p>So far, all the published responders have been written in Python. We provide a Python library called <code>cortexutils</code> to help developers easily write their programs. Note though that Python is not mandatory for responder coding and any language that runs on Linux can be used, though you won't have the benefits of the CortexUtils library.</p> <p>Cortexutils can be used with Python 2 and 3. Due to the end of life from Python2 it is strongly advised to work as much with Python3 as possible. To install it :</p> <pre><code>pip install cortexutils\n</code></pre> <p>or</p> <pre><code>pip3 install cortexutils\n</code></pre> <p>This library is already used by all the responders published in our Github repository. Feel free to start reading the code of some of them before writing your own.</p>"},{"location":"cortex/api/how-to-create-a-responder/#submitting-a-responder","title":"Submitting a Responder","text":"<p>We highly encourage you to share your responders with the community through our Github repository. To do so, we invite you to follow a few steps before submitting a pull request.</p>"},{"location":"cortex/api/how-to-create-a-responder/#check-existing-issues","title":"Check Existing Issues","text":"<p>Start by checking if an issue already exists for the responder you'd like to write and contribute. Verify that nobody is working on it. If an issue exists and has the in progress, under review or pr-submitted label, it means somebody is already working on the code or has finished it.</p> <p>If you are short on ideas, check issues with a help wanted label. If one of those issues interest you, indicate that you are working on it.</p>"},{"location":"cortex/api/how-to-create-a-responder/#open-an-issue","title":"Open an Issue","text":"<p>If there's no issue open for the responder you'd like to contribute, open one. Indicate that you are working on it to avoid having someone start coding it.</p> <p>You have to create an issue for each responder you'd like to submit.</p>"},{"location":"cortex/api/how-to-create-a-responder/#review-your-service-interaction-files","title":"Review your Service Interaction File(s)","text":"<p>Review your service interaction files. For example, let's check the Mailer JSON responder configuration file(s):</p> <p><pre><code>{\n\"name\": \"Mailer\",\n\"version\": \"1.0\",\n\"author\": \"CERT-BDF\",\n\"url\": \"https://github.com/TheHive-Project/Cortex-Analyzers\",\n\"license\": \"AGPL-V3\",\n\"description\": \"Send an email with information from a TheHive case or alert\",\n\"dataTypeList\": [\"thehive:case\", \"thehive:alert\", \"thehive:case_task\"],\n\"command\": \"Mailer/mailer.py\",\n\"baseConfig\": \"Mailer\",\n\"configurationItems\": [\n{\n\"name\": \"from\",\n\"description\": \"email address from which the mail is send\",\n\"type\": \"string\", &lt;== defines what kind of data type the configuration item is (string, number)\n\"multi\": false, &lt;== setting multi to true allows to pass a list of items\n\"required\": true\n},\n{\n\"name\": \"smtp_host\",\n\"description\": \"SMTP server used to send mail\",\n\"type\": \"string\",\n\"multi\": false,\n\"required\": true,\n\"defaultValue\": \"localhost\"\n},\n{\n\"name\": \"smtp_port\",\n\"description\": \"SMTP server port\",\n\"type\": \"number\",\n\"multi\": false,\n\"required\": true,\n\"defaultValue\": 25\n},\n{\n\"name\": \"smtp_user\",\n\"description\": \"SMTP server user\",\n\"type\": \"string\",\n\"multi\": false,\n\"required\": false,\n\"defaultValue\": \"user\"\n},\n{\n\"name\": \"smtp_pwd\",\n\"description\": \"SMTP server password\",\n\"type\": \"string\",\n\"multi\": false,\n\"required\": false,\n\"defaultValue\": \"pwd\"\n}\n]\n}\n</code></pre> Ensure that all information is correct and particularly the <code>author</code> and <code>license</code> parameters.</p>"},{"location":"cortex/api/how-to-create-a-responder/#provide-the-list-of-requirements","title":"Provide the List of Requirements","text":"<p>If your responder is written in Python, make sure to complete the <code>requirements.txt</code> file with the list of all the external libraries that are needed to run the responder correctly.</p>"},{"location":"cortex/api/how-to-create-a-responder/#verify-execution","title":"Verify Execution","text":"<p>Use these three simple checks before submitting your responder:</p> <ul> <li>Ensure it works with the expected configuration, TLP, PAP or datatype.</li> <li>Ensure it works with missing configuration, PAP, datatype or TLP: your responder must generate an explicit error message.</li> </ul>"},{"location":"cortex/api/how-to-create-a-responder/#create-a-pull-request","title":"Create a Pull Request","text":"<p>Create one Pull Request per responder against the develop branch of the Cortex-Analyzers repository. Reference the issue you've created in your PR.</p> <p>We have to review your responders. Distinct PRs will allow us to review them more quickly and release them to the benefit of the whole community.</p>"},{"location":"cortex/api/how-to-create-a-responder/#need-help","title":"Need Help?","text":"<p>Something does not work as expected? No worries, we got you covered. Please join our user forum,  contact us on Gitter, or send us  an email at support@thehive-project.org. We are here to help.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/","title":"How to Write and Submit an Analyzer","text":""},{"location":"cortex/api/how-to-create-an-analyzer/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Writing an Analyzer<ul> <li>The Program</li> <li>Service Interaction Files (Flavors)</li> <li>Python Requirements</li> <li>Example: VirusTotal Analyzer Files</li> <li>Input</li> <li>Service Interaction Configuration Items</li> <li>Analyzer Configuration in the Global Configuration File</li> <li>Output</li> <li>The Cortexutils Python Library</li> <li>Report Templates</li> </ul> </li> <li>Submitting an Analyzer<ul> <li>Check Existing Issues</li> <li>Open an Issue</li> <li>Review your Service Interaction File(s)</li> <li>Provide the List of Requirements</li> <li>Check the Taxonomy</li> <li>Provide Global Configuration Parameters</li> <li>Verify Execution</li> <li>Create a Pull Request</li> </ul> </li> <li>Need Help?</li> </ul>"},{"location":"cortex/api/how-to-create-an-analyzer/#writing-an-analyzer","title":"Writing an Analyzer","text":"<p>An analyzer is a program that takes an observable and configuration information as raw input, analyze the observable and produces a result as raw output. It is made of at least 2 types of files:</p> <ul> <li>The program itself</li> <li>One or several service interaction files or flavors</li> <li>A Python requirements file, which is only necessary if the analyzer is written in Python.</li> </ul>"},{"location":"cortex/api/how-to-create-an-analyzer/#the-program","title":"The Program","text":"<p>The first type of files an analyzer is made of is the core program that performs actions. It can be written in any programming language that is supported by Linux.</p> <p>While many analyzers are written in Python (<code>*.py</code> files), you can write yours in Ruby, Perl or even Scala. However, the very handy <code>Cortexutils</code> library described below is in Python. It greatly facilitates analyzer development and it also provides some methods to quickly format the output to make it compliant with the JSON schema expected by TheHive.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#service-interaction-files-flavors","title":"Service Interaction Files (Flavors)","text":"<p>An analyzer must have at least one service interaction file. Such files contain key configuration information such as the analyzer's author information, the datatypes (IP, URL, hash, domain...) the analyzer accepts as input, the TLP and PAP (Permissible Actions Protocol) above which it will refuse to execute to protect against data leakage and to enforce sane OPSEC practices and so on.</p> <p>An analyzer can have two or more service interaction files to allow it to perform different actions.  We speak then of flavors. For example, a sandbox analyzer can analyze a file with or without an Internet connection. Another example could be an analyzer that can either send a file to VirusTotal for analysis or get the last report using its hash.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#python-requirements","title":"Python Requirements","text":"<p>If the analyzer is written in Python, a <code>requirements.txt</code> must be provided with the list of all the dependencies.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#example-virustotal-analyzer-files","title":"Example: VirusTotal Analyzer Files","text":"<p>Below is a directory listing of the files corresponding to the VirusTotal analyzer. You can see that the analyzer has two flavors: GetReport and Scan.</p> <pre><code>analyzers/VirusTotal\n|-- VirusTotal_GetReport.json\n|-- VirusTotal_Scan.json\n|-- requirements.txt\n|-- virustotal.py\n`-- virustotal_api.py\n</code></pre>"},{"location":"cortex/api/how-to-create-an-analyzer/#input","title":"Input","text":"<p>The input of an analyzer is a JSON structure with different pieces of information. For example, to use the VirusTotal analyzer's GetReport flavor in order to obtain the latest available report for hash <code>d41d8cd98f00b204e9800998ecf8427e</code>, you must submit input such as:</p> <pre><code>{\n\"data\":\"d41d8cd98f00b204e9800998ecf8427e\",\n\"dataType\":\"hash\",\n\"tlp\":0,\n\"config\":{\n\"key\":\"1234567890abcdef\",\n\"max_tlp\":3,\n\"check_tlp\":true,\n\"service\":\"GetReport\"\n[..]\n},\n\"proxy\":{\n\"http\":\"http://myproxy:8080\",\n\"https\":\"https://myproxy:8080\"\n}\n}\n</code></pre> <p><code>data</code>, <code>dataType</code> and <code>tlp</code> are the observable-related information generated by TheHive or any other program that is calling Cortex. <code>config</code> is the analyzer's specific configuration provided by an <code>orgAdmin</code> users when the analyzer is enabled in the Cortex UI.</p> <p>Let's take the GetReport flavor of the VirusTotal analyzer as an example again.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#example-virustotal-get-reports-input","title":"Example: VirusTotal Get Report's Input","text":"<pre><code>{\n\"data\":\"d41d8cd98f00b204e9800998ecf8427e\",\n\"dataType\":\"hash\",\n\"tlp\":0,\n[..]\n}\n</code></pre>"},{"location":"cortex/api/how-to-create-an-analyzer/#example-service-interaction-file-for-virustotal-getreport","title":"Example: Service Interaction File for VirusTotal GetReport","text":"<p>The <code>&lt;==</code> sign and anything after it are comments that do no appear in the original file. <pre><code>{\n\"name\": \"VirusTotal_GetReport\",\n\"version\": \"3.0\",\n\"author\": \"CERT-BDF\",\n\"url\": \"https://github.com/TheHive-Project/Cortex-Analyzers\",\n\"license\": \"AGPL-V3\",\n\"description\": \"Get the latest VirusTotal report for a file, hash, domain or an IP address.\",\n\"dataTypeList\": [\"file\", \"hash\", \"domain\", \"ip\"],\n\"command\": \"VirusTotal/virustotal.py\", &lt;== Program to run when invoking the analyzer\n\"baseConfig\": \"VirusTotal\", &lt;== name of base config in Cortex analyzer config page\n\"config\": {\n\"service\": \"get\"\n},\n\"configurationItems\": [ &lt;== list of configuration items the analyzer needs to operate (api key etc.)\n{\n\"name\": \"key\",\n\"description\": \"API key for Virustotal\",\n\"type\": \"string\", &lt;== defines what kind of data type the configuration item is (string, number)\n\"multi\": false, &lt;== setting multi to true allows to pass a list of items (e.g. MISP analyzer)\n\"required\": true },\n{\n\"name\": \"polling_interval\",\n\"description\": \"Define time interval between two requests attempts for the report\",\n\"type\": \"number\",\n\"multi\": false,\n\"required\": false,\n\"defaultValue\": 60\n}\n]\n}\n</code></pre></p>"},{"location":"cortex/api/how-to-create-an-analyzer/#service-interaction-configuration-items","title":"Service Interaction Configuration Items","text":""},{"location":"cortex/api/how-to-create-an-analyzer/#name","title":"name","text":"<p>Name of the specific service (or flavor) of the analyzer.</p> <p>If your analyzer has only one service interaction (i.e. performs only one action), it is the name of the analyzer's directory.</p> <p>If your analyzer performs several actions (i.e. comes in several flavors), you have to give a specific and meaningful name to each flavor.</p> <p>Each flavor's name appear in TheHive's analyzer list and in MISP when you use Cortex for attribute enrichment.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#version","title":"version","text":"<p>The version of the analyzer.</p> <p>You must increase major version numbers when new features are added, modifications are made to take into account API changes, report output is modified or when report templates (more on this later) are updated.</p> <p>You must increase minor version numbers when bugs are fixed.</p> <p>The version number is also used in the folder name of the associated report templates ; e.g. VirusTotal_GetReport and 3.0 on the JSON file should correspond a folder named VirusTotal_GetReport_3_0 for report templates.  Report templates are used by TheHive to display the analyzer's JSON output  in an analyst-friendly fashion.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#author","title":"author","text":"<p>You must provide your full name and/or your organization/team name when submitting an analyzer. Pseudos are not accepted. If you'd rather remain anonymous, please contact us at support@thehive-project.org prior to submitting your analyzer.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#url","title":"url","text":"<p>The URL where the analyzer is stored. This should ideally be <code>https://github.com/TheHive-Project/Cortex-Analyzers</code></p>"},{"location":"cortex/api/how-to-create-an-analyzer/#license","title":"license","text":"<p>The license of the code. Ideally, we recommend using the AGPL-v3 license.</p> <p>Make sure your code's license is compatible with the license(s) of the various components and libraries you use if applicable.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#description","title":"description","text":"<p>Description of the analyzer. Please be concise and clear. The description is  shown in the Cortex UI, TheHive and MISP.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#datatypelist","title":"dataTypeList","text":"<p>The list of TheHive datatypes supported by the analyzer. Currently TheHive accepts the following datatypes:</p> <ul> <li>domain</li> <li>file</li> <li>filename</li> <li>fqdn</li> <li>hash</li> <li>ip</li> <li>mail</li> <li>mail_subject</li> <li>other</li> <li>regexp</li> <li>registry</li> <li>uri_path</li> <li>url</li> <li>user-agent</li> </ul> <p>If you need additional datatypes for your analyzer, please let us know at support@thehive-project.org.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#baseconfig","title":"baseConfig","text":"<p>Name used to group configuration items common to several analyzer. This prevent the user to enter the same API key for all analyzer flavors. The Cortex analyzer config page group configuration items by their <code>baseConfig</code>.  </p>"},{"location":"cortex/api/how-to-create-an-analyzer/#config","title":"config","text":"<p>Configuration dedicated to the analyzer's flavor. This is where we  typically specify the TLP level of observables allowed to be analyzed with the  <code>check_tlp</code> and <code>max_tlp</code> parameters. For example, if <code>max_tlp</code> is set to <code>2</code> (TLP:AMBER),  TLP:RED observables cannot be analyzed.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#max_tlp","title":"max_tlp","text":"<p>The TLP level above which the analyzer must not be executed.</p> TLP max_tlp value Unknown -1 WHITE 0 GREEN 1 AMBER 2 RED 3"},{"location":"cortex/api/how-to-create-an-analyzer/#check_tlp","title":"check_tlp","text":"<p>This is a boolean parameter. When <code>true</code>, <code>max_tlp</code> is checked. And if the input's TLP is above <code>max_tlp</code>, the analyzer is not executed.</p> <p>For consistency reasons, we do recommend setting both <code>check_tlp</code> and <code>max_tlp</code> even if <code>check_tlp</code> is set to <code>false</code>.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#max_pap","title":"max_pap","text":"<p>The PAP level above which the analyzer must not be executed.</p> TLP max_tlp value Unknown -1 WHITE 0 GREEN 1 AMBER 2 RED 3"},{"location":"cortex/api/how-to-create-an-analyzer/#check_pap","title":"check_pap","text":"<p>This is a boolean parameter. When <code>true</code>, <code>max_pap</code> is checked. And if the input's PAP is above <code>max_pap</code>, the analyzer is not executed.</p> <p>For consistency reasons, we do recommend setting both <code>check_pap</code> and <code>max_pap</code> even if <code>check_pap</code> is set to <code>false</code>.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#command","title":"command","text":"<p>The command used to run the analyzer. That's typically the full, absolute path to the main program file.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#configurationitems","title":"configurationItems","text":"<p>The list of configurationItems is necessary in order to be able to set all configuration variables for analyzers directly in the Cortex 2 user interface. As in the VirusTotal example above can be seen, every item is a json object that defines: - name (string) - description (string) - type (string) - multi (boolean) - required (boolean) - defaultValue (according to type, optional)</p> <p>The <code>multi</code> parameter allows to pass a list as configuration variable instead of a single string or number. This is used e.g. in the MISP analyzer that queries multiple servers in one run and needs different parameters for that.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#output","title":"Output","text":"<p>The output of an analyzer depends on the success or failure of its execution.</p> <p>If the analyzer fails to execute:</p> <pre><code>{\n\"success\": false,\n\"errorMessage\":\"..\"\n}\n</code></pre> <ul> <li>When <code>success</code> is set to <code>false</code>, it indicates that something went wrong     during the execution.</li> <li><code>errorMessage</code> is free text - typically the error output message.</li> </ul> <p>If the analyzer succeeds (i.e. it runs without any error):</p> <pre><code>{\n\"success\":true,\n\"artifacts\":[..],\n\"summary\":{\n\"taxonomies\":[..]\n},\n\"full\":{..}\n}\n</code></pre> <ul> <li>When <code>success</code> is set to <code>true</code>, it indicates that the analyzer ran     successfully.</li> <li><code>artifacts</code> is a list of indicators extracted from the produced report.</li> <li><code>full</code> is the full report of the analyzer. It is free form, as long as it is JSON formatted.</li> <li> <p><code>summary</code> is used in TheHive for short reports displayed in the     observable list and in the detailed page of each observable. It     contains a list of taxonomies.</p> <ul> <li><code>taxonomies</code>:</li> </ul> <pre><code>\"taxonomies\":[\n{\n\"namespace\": \"NAME\",\n\"predicate\": \"PREDICATE\",\n\"value\": \"\\\"VALUE\\\"\",\n\"level\":\"info\"\n}\n]\n</code></pre> <ul> <li><code>namespace</code> and <code>predicate</code> are free values but they should be as  concise as possible. For example, the VirusTotal analyzer uses VT  as a namespace and Score as a predicate.</li> <li><code>level</code> intends to convey the maliciousness of the result:     :<ul> <li><code>info</code> : the analyzer produced an information, and the     short report is shown in blue color in TheHive.</li> <li><code>safe</code> : the analyzer did not find anything suspicious     or the analyzed observable is safe according to     the analyzer. TheHive displays the short report in green     color.</li> <li><code>suspicious</code> : the analyzer found that the observable is     either suspicious or warrants further investigation. The     short report has an orange color in TheHive.</li> <li><code>malicious</code> : the analyzer found that the observable     is malicious. The short report is red colored in TheHive.</li> </ul> </li> </ul> </li> </ul> <p>For more information refer to our blog.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#the-cortexutils-python-library","title":"The Cortexutils Python Library","text":"<p>So far, all the published analyzers have been written in Python. We released a special Python library called <code>cortexutils</code> to help developers easily write their programs. Note though that Python is not mandatory for analyzer coding and any language that runs on Linux can be used, though you won't have the benefits of the CortexUtils library.</p> <p>Cortexutils can be used with Python 2 and 3. To install it :</p> <pre><code>pip install cortexutils\n</code></pre> <p>or</p> <pre><code>pip3 install cortexutils\n</code></pre> <p>This library is already used by all the analyzers published in our Github repository. Feel free to start reading the code of some of them before writing your own.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#report-templates","title":"Report Templates","text":"<p>When using TheHive, analysts can submit an observable for analysis to one or several Cortex instances by a click of a button. Once finished, Cortex returns the result to TheHive. The TheHive displays that result using HTML templates for short and long reports.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#cortex-result-in-thehive","title":"Cortex Result in TheHive","text":"<p>TheHive receives the Cortex result which is simply the JSON formatted analyzer output described above:</p> <ul> <li>The <code>summary</code> section is read to display short reports in the observables list and in the detailed observable page. This is stored in a dict object named <code>content</code> within TheHive.</li> <li>The <code>full</code> section is read to display long reports when clicking the short     report in the observable list or when accessing a detailed observable     page. In TheHive application, it is stored in a dict object named     <code>content</code>.</li> </ul>"},{"location":"cortex/api/how-to-create-an-analyzer/#displayed-information","title":"Displayed Information","text":""},{"location":"cortex/api/how-to-create-an-analyzer/#when-no-template-is-imported","title":"When No Template is Imported","text":"<p>In the event that the analyzer report templates are not imported in TheHive (only administrators can do such an operation via the Admin &gt; Report Templates menu):</p> <ul> <li>In the observable list, TheHive is able to display the analyzer <code>summary</code>     results using a builtin style sheet associated with the previously     described taxonomy.</li> <li>In the detailed observable page:<ul> <li>the <code>full</code> result is displayed in raw format (the JSON output from   Cortex)</li> <li>the <code>summary</code> result is not displayed.</li> </ul> </li> </ul>"},{"location":"cortex/api/how-to-create-an-analyzer/#when-templates-are-imported","title":"When Templates are Imported","text":"<p>If templates are imported into TheHive:</p> <ul> <li>Short reports are displayed in the observable list and in the detailed observable page.</li> </ul> <p></p> <ul> <li>Long reports are displayed when clicking on the short reports or in the detailed observable page.</li> </ul> <p></p>"},{"location":"cortex/api/how-to-create-an-analyzer/#writing-templates","title":"Writing Templates","text":"<p>To display results nicely in TheHive, write two HTML templates:</p> <ul> <li>One for short reports</li> <li>One for long reports</li> </ul> <p>When TheHive users import them in the application, they will be definitely more efficient at reading the analyzer reports and do their job accordingly.</p> <p>If the analyzer is made of different flavors (i.e. has different service interaction files with a <code>json</code> extension), you should provide two HTML templates (short and long reports) for each flavor.</p> <p>For example, the VirusTotal analyzer comes in two flavors hence it has 4 HTML  templates:</p> <pre><code>thehive-templates/VirusTotal_GetReport_3_0\n|-- long.html\n`-- short.html\nthehive-templates/VirusTotal_Scan_3_0\n|-- long.html\n`-- short.html\n</code></pre> <p>The folder's name is the concatenation of the <code>name</code> and the <code>version</code> values found in the service interaction files.</p> <p>TheHive uses Bootstrap and AngularJS so you can leverage them in your templates.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#short-report-templates-shorthtml","title":"Short Report Templates (short.html)","text":"<p>The short report uses taxonomies and is built into the analyzers by the <code>summary()</code> function. Report templates read it as shown in the example below:</p> <pre><code>&lt;span class=\"label\" ng-repeat=\"t in content.taxonomies\"\n  ng-class=\"{'info': 'label-info', 'safe': 'label-success',\n  'suspicious': 'label-warning',\n  'malicious':'label-danger'}[t.level]\"&gt;\n    {{t.namespace}}:{{t.predicate}}={{t.value}}\n&lt;/span&gt;\n</code></pre> <p>If you want to change or add the information displayed in the short report in the detailed observable page, you have to update the <code>summary()</code> function in the analyzer's program and edit short.html as well. Basically, copy the code in your short.html template and it will do the job.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#long-report-templates-longhtml","title":"Long Report Templates (long.html)","text":"<p>Long report templates are more or less free form as long as it reads the content of the relevant section in the Cortex result (<code>full</code>). Feel free to check what has already been written for existing analyzers to write yours.</p> <p>A good start can be:</p> <pre><code>&lt;!-- Success --&gt;\n&lt;div class=\"panel panel-danger\" ng-if=\"success\"&gt;\n    &lt;div class=\"panel-heading\"&gt;\n        ANALYZERNAME Report\n    &lt;/div&gt;\n    &lt;div class=\"panel-body\"&gt;\n        [...]                      &lt;= code here\n    &lt;/div&gt;\n&lt;/div&gt;\n\n&lt;!-- General error  --&gt;\n&lt;div class=\"panel panel-danger\" ng-if=\"!success\"&gt;\n    &lt;div class=\"panel-heading\"&gt;\n        &lt;strong&gt;{{(artifact.data || artifact.attachment.name) | fang}}&lt;/strong&gt;\n    &lt;/div&gt;\n    &lt;div class=\"panel-body\"&gt;\n        &lt;dl class=\"dl-horizontal\" ng-if=\"content.errorMessage\"&gt;\n            &lt;dt&gt;&lt;i class=\"fa fa-warning\"&gt;&lt;/i&gt; ANALYZERNAME: &lt;/dt&gt;\n            &lt;dd class=\"wrap\"&gt;{{content.errorMessage}}&lt;/dd&gt;\n        &lt;/dl&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"cortex/api/how-to-create-an-analyzer/#submitting-an-analyzer","title":"Submitting an Analyzer","text":"<p>We highly encourage you to share your analyzers with the community through our Github repository. To do so, we invite you to follow a few steps before submitting a pull request.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#check-existing-issues","title":"Check Existing Issues","text":"<p>Start by checking if an issue already exists for the analyzer you'd like to write and contribute. Verify that nobody is working on it. If an issue exists and has the in progress, under review or pr-submitted label, it means somebody is already working on the code or has finished it.</p> <p>If you are short on ideas, check issues with a help wanted label. If one of those issues interest you, indicate that you are working on it.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#open-an-issue","title":"Open an Issue","text":"<p>If there's no issue open for the analyzer you'd like to contribute, open one. Indicate that you are working on it to avoid having someone start coding it.</p> <p>You have to create an issue for each analyzer you'd like to submit.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#review-your-service-interaction-files","title":"Review your Service Interaction File(s)","text":"<p>Review your service interaction files. For example, let's check the VirusTotal JSON analyzer configuration file(s):</p> <p><pre><code>{\n\"name\": \"VirusTotal_GetReport\",\n\"version\": \"3.0\",\n\"author\": \"CERT-BDF\",\n\"url\": \"https://github.com/TheHive-Project/Cortex-Analyzers\",\n\"license\": \"AGPL-V3\",\n\"description\": \"Get the latest VirusTotal report for a file, hash, domain or an IP address\",\n\"dataTypeList\": [\"file\", \"hash\", \"domain\", \"ip\"],\n\"baseConfig\": \"VirusTotal\",\n\"config\": {\n\"check_tlp\": true,\n\"max_tlp\": 3,\n\"service\": \"get\"\n},\n\"command\": \"VirusTotal/virustotal.py\"\n}\n</code></pre> Ensure that all information is correct and particularly the <code>author</code> and <code>license</code> parameters.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#provide-the-list-of-requirements","title":"Provide the List of Requirements","text":"<p>If your analyzer is written in Python, make sure to complete the <code>requirements.txt</code> file with the list of all the external libraries that are needed to run the analyzer correctly.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#check-the-taxonomy","title":"Check the Taxonomy","text":"<p>We chose to use a formatted summary report to match a taxonomy as described above. If you want your analyzer reports in the observable lists, ensure that your summary matches this format. If your analyzer is written in Python and you are using our <code>cortexutils</code> library, you can use the <code>summary()</code>and <code>build_taxonomy()</code> functions.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#provide-global-configuration-parameters","title":"Provide Global Configuration Parameters","text":"<p>When submitting your analyzer, please provide the necessary global configuration in <code>/etc/cortex/application.conf</code> if needed. You can provide this information in a <code>README</code> file.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#verify-execution","title":"Verify Execution","text":"<p>Use these three simple checks before submtting your analyzer:</p> <ul> <li>Ensure it works with the expected configuration, TLP or dataType.</li> <li>Ensure it works with missing configuration, dataType or TLP: your analyzer must generate an explicit error message.</li> <li>Ensure the long report template handles error messages correctly.</li> </ul>"},{"location":"cortex/api/how-to-create-an-analyzer/#create-a-pull-request","title":"Create a Pull Request","text":"<p>Create one Pull Request per analyzer against the develop branch of the Cortex-Analyzers repository. Reference the issue you've created in your PR.</p> <p>We have to review your analyzers. Distinct PRs will allow us to review them more quickly and release them to the benefit of the whole community.</p>"},{"location":"cortex/api/how-to-create-an-analyzer/#need-help","title":"Need Help?","text":"<p>Something does not work as expected? No worries, we got you covered. Please join our user forum,  contact us on Gitter, or send us  an email at support@thehive-project.org. We are here to help.</p>"},{"location":"cortex/download/","title":"Download Cortex","text":"<p>Cortex is published and available as many binary packages formats: </p>"},{"location":"cortex/download/#debian-ubuntu","title":"Debian /  Ubuntu","text":"<p>Import the GPG key :</p> <pre><code>curl https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY | sudo apt-key add -\nwget -qO- https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY |  sudo gpg --dearmor -o /usr/share/keyrings/thehive-project-archive-keyring.gpg\n</code></pre> /etc/apt/source.list.d/thehive-project.list<pre><code>deb [signed-by=/usr/share/keyrings/thehive-project-archive-keyring.gpg] https://deb.thehive-project.org release main\n</code></pre>"},{"location":"cortex/download/#red-hat-enterprise-linux-fedora","title":"Red Hat Enterprise Linux /  Fedora","text":"<p>Import the GPG key :</p> <pre><code>sudo rpm --import https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY\n</code></pre> /etc/yum.repos.d/thehive-project.repo<pre><code>[thehive-project]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=https://rpm.thehive-project.org/release/noarch\ngpgcheck=1\n</code></pre>"},{"location":"cortex/download/#zip-archive","title":"ZIP archive","text":"<p>Download it at: https://download.thehive-project.org/cortex-latest.zip</p>"},{"location":"cortex/download/#docker","title":"Docker","text":"<p>Docker images are published on Dockerhub here: https://hub.docker.com/r/thehiveproject/cortex</p>"},{"location":"cortex/download/#archives","title":"Archives","text":"<p>There is no archive available for Cortex.</p>"},{"location":"cortex/installation-and-configuration/","title":"Installation &amp; configuration guides","text":""},{"location":"cortex/installation-and-configuration/#overview","title":"Overview","text":"<p>Cortex relies on Elasticsearch to store its data. A basic setup to install Elasticsearch, then Cortex on a standalone and dedicated server (physical or virtual).</p>"},{"location":"cortex/installation-and-configuration/#hardware-requirements","title":"Hardware requirements","text":"<p>Hardware requirements depends on the usage of the system. We recommend starting with dedicated resources: </p> <ul> <li> 8 vCPU</li> <li> 16 GB of RAM</li> </ul>"},{"location":"cortex/installation-and-configuration/#operating-systems","title":"Operating systems","text":"<p>Cortex has been tested and is supported on the following operating systems: </p> <ul> <li> Ubuntu 20.04 LTS</li> <li> Debian 11 </li> <li> RHEL 8</li> <li> Fedora 35</li> </ul>"},{"location":"cortex/installation-and-configuration/#installation-guide","title":"Installation Guide","text":"<p>Too much in a hurry to read ? </p> <p>If you are using one of the supported operating systems, use our all-in-one installation script: </p> <pre><code>wget -q -O /tmp/install.sh https://archives.strangebee.com/scripts/install.sh ; sudo -v ; bash /tmp/install.sh\n</code></pre> <p>This script helps with the installation process on a fresh and supported OS ; the program also run successfully if the conditions in terms of hardware requirements are met.</p> <p></p> <p>Once executed, several options are available: </p> <ol> <li>Setup proxy settings ; will configure everything on the host to work with a HTTP proxy, and custom CA certificate.</li> <li>Install TheHive ; use this option to install TheHive 5 and its dependancies</li> <li>Install Cortex and all its dependencies to run Analyzers &amp; Responders as Docker Iiages</li> <li>Install Cortex and all its dependencies to run Analyzers &amp; Responders on the host (Debian and Ubuntu ONLY)</li> </ol> <p>For each release, DEB, RPM and ZIP binary packages are built and provided.</p> <p>The following Guide let you prepare, install and configure Cortex and its prerequisites for Debian and RPM packages based Operating Systems, as well as for other systems and using our binary packages. </p>"},{"location":"cortex/installation-and-configuration/#configuration-guides","title":"Configuration Guides","text":"<p>The configuration of Cortex is in files stored in the <code>/etc/cortex</code> folder:</p> <ul> <li><code>application.conf</code> contains all parameters and options</li> <li><code>logback.xml</code> is dedicated to log management</li> </ul> <pre><code>/etc/cortex\n\u251c\u2500\u2500 application.conf\n\u251c\u2500\u2500 logback.xml\n\u2514\u2500\u2500 secret.conf\n</code></pre> <p>A separate secret.conf file is automatically created by Debian or RPM packages. This file should contain a secret that should be used by one instance.</p> <p>Various aspects can configured in the <code>application.conf</code> file:</p> <ul> <li>database</li> <li>Authentication</li> <li>Analyzers &amp; Responders</li> </ul>"},{"location":"cortex/installation-and-configuration/#analyzers-responders","title":"Analyzers &amp; Responders","text":"<p>Before starting the installation of Cortex, this is important to know how Analyzers and Responders will be managed and run. 2 solutions are available to run them:</p>"},{"location":"cortex/installation-and-configuration/#run-locally","title":"Run locally","text":"<p>The programs are downloaded and installed on the system running Cortex. </p> <p>There are many disadvantages with this option:</p> <ul> <li>Some public Analyzers or Responders, or you own custom program might required specific applications installed on the system, </li> <li>All of the programs published are written in Python and come with dependancies. To run successfully, the dependancies of all programs should be installed on the same operating system ; so there is a high risk of incompatibilities (some program might require a specific version of a librarie with the latest is also required by another one)</li> <li>The goal of Analyzers is to extract or gather information or intelligence about observables ; and some of them might be malicious. Depending on the analysis, like a code analysis, you might want to ensure the Analyzer has not been compromised - and the host - by the observable itself</li> <li>You might want to ensure that when you run an Analyzer, there is no question about the integrity of its programs</li> <li>Updating them might be a pain regarding Operating System used and dependancies</li> </ul>"},{"location":"cortex/installation-and-configuration/#run-with-docker","title":"Run with Docker","text":"<p>Analyzers &amp; Responders we publish also have their own Docker images. </p> <p>There are several benefits to use Docker images of Analyzers &amp; Responders.</p> <ul> <li>No need to worry about applications required or libraries, it just work</li> <li>When requested, Cortex downloads the docker image of a program and instanciate a container running the program. When finished, the container is trashed and a new one is created the next time. No need to worry about the integrity of the program</li> <li>This is simple to use and maintain</li> </ul> <p>This is the recommended option. It requires installing Docker engine as well.</p> <p>This is not an exclusive choice, both solutions can be used by the same instance of Cortex.</p>"},{"location":"cortex/installation-and-configuration/advanced-configuration/","title":"Advanced configuration","text":""},{"location":"cortex/installation-and-configuration/advanced-configuration/#cache","title":"Cache","text":""},{"location":"cortex/installation-and-configuration/advanced-configuration/#performance","title":"Performance","text":"<p>In order to increase Cortex performance, a cache is configured to prevent repetitive database solicitation. Cache retention time can be configured for users and organizations (default is 5 minutes). If a user is updated, the cache is automatically invalidated.</p>"},{"location":"cortex/installation-and-configuration/advanced-configuration/#analyzer-results","title":"Analyzer Results","text":"<p>Analyzer results (job reports) can also be cached. If an analyzer is executed against the same observable, the previous report can be returned without re-executing the analyzer. The cache is used only if the second job occurs within <code>cache.job</code> (the default is 10 minutes).</p> <pre><code>cache {\n  job = 10 minutes\n  user = 5 minutes\n  organization = 5 minutes\n}\n</code></pre> <p>Notes</p> <ol> <li>The global <code>cache.job</code> value can be overridden for each analyzer in the analyzer configuration Web dialog</li> <li>it is possible to bypass the cache altogether (for example to get extra fresh results) through the API as explained in the API Guide or by setting the cache to Custom in the Cortex UI for each analyzer and specifying <code>0</code> as the number of minutes.</li> </ol>"},{"location":"cortex/installation-and-configuration/advanced-configuration/#streaming-aka-the-flow","title":"Streaming (a.k.a The Flow)","text":"<p>The user interface is automatically updated when data is changed in the back-end. To do this, the back-end sends events to all the connected front-ends. The mechanism used to notify the front-end is called long polling and its settings are:</p> <ul> <li><code>refresh</code> : when there is no notification, close the connection after this  duration (the default is 1 minute).</li> <li><code>cache</code> : before polling a session must be created, in order to make sure no  event is lost between two polls. If there is no poll during the cache setting,  the session is destroyed (the default is 15 minutes).</li> <li><code>nextItemMaxWait</code>, <code>globalMaxWait</code> : when an event occurs, it is not  immediately sent to the front-ends. The back-end waits nextItemMaxWait and up  to globalMaxWait in case another event can be included in the notification.  This mechanism saves many HTTP requests.</li> </ul> <p>The default values are:</p> <pre><code># Streaming\nstream.longpolling {\n  # Maximum time a stream request waits for new element\n  refresh = 1m\n  # Lifetime of the stream session without request\n  cache = 15m\n  nextItemMaxWait = 500ms\n  globalMaxWait = 1s\n}\n</code></pre>"},{"location":"cortex/installation-and-configuration/advanced-configuration/#entity-size-limit","title":"Entity Size Limit","text":"<p>The Play framework used by Cortex sets the HTTP body size limit to 100KB by default for textual content (json, xml, text, form data) and 10MB for file uploads. This could be too small in some cases so you may want to change it with the following settings in the <code>application.conf</code> file:</p> <pre><code># Max textual content length\nplay.http.parser.maxMemoryBuffer=1M\n# Max file size\nplay.http.parser.maxDiskBuffer=1G\n</code></pre> <p>Note</p> <p>if you are using a NGINX reverse proxy in front of Cortex, be aware that it doesn't distinguish between text data and a file upload. So, you should also set the <code>client_max_body_size</code> parameter in your NGINX server configuration to the highest value among the two: file upload and text size as defined in Cortex <code>application.conf</code> file.</p>"},{"location":"cortex/installation-and-configuration/analyzers-responders/","title":"Analyzers &amp; Responders","text":""},{"location":"cortex/installation-and-configuration/analyzers-responders/#run-with-docker","title":"Run with Docker","text":"<p>Ensure Cortex is authorized to run use Docker</p> <p>To run docker images of Analyzers &amp; Responders, Cortex should have permissions to use docker. </p> <pre><code>sudo usermod -G docker cortex\n</code></pre>"},{"location":"cortex/installation-and-configuration/analyzers-responders/#configure-cortex","title":"Configure Cortex","text":"<p>To run Analyzers&amp;Responders with Docker images, Cortex should be able have access to Internet: </p> <ul> <li>To download public catalogs from download.thehive-project.org </li> <li>To download Docker images from hub.docker.com  (https://hub.docker.com/search?q=cortexneurons).</li> </ul> /etc/cortex/application.conf<pre><code>[..]\nanalyzer {\n# Directory that holds analyzers\nurls = [\n\"https://download.thehive-project.org/analyzers.json\"\n]\n\nfork-join-executor {\n# Min number of threads available for analyze\nparallelism-min = 2\n# Parallelism (threads) ... ceil(available processors * factor)\nparallelism-factor = 2.0\n# Max number of threads available for analyze\nparallelism-max = 4\n}\n}\n\nresponder {\n# Directory that holds responders\nurls = [\n\"https://download.thehive-project.org/responders.json\"\n]\n\nfork-join-executor {\n# Min number of threads available for analyze\nparallelism-min = 2\n# Parallelism (threads) ... ceil(available processors * factor)\nparallelism-factor = 2.0\n# Max number of threads available for analyze\nparallelism-max = 4\n}\n}\n[..]\n</code></pre>"},{"location":"cortex/installation-and-configuration/analyzers-responders/#store-run-programs-on-the-host","title":"Store &amp; run programs on the host","text":""},{"location":"cortex/installation-and-configuration/analyzers-responders/#additionnal-packages","title":"Additionnal packages","text":"<p>Some system packages are required to run Analyzers&amp;Responders programs successfully: </p> Debian <pre><code>sudo apt install -y --no-install-recommends python3-pip python3-dev ssdeep libfuzzy-dev libfuzzy2 libimage-exiftool-perl libmagic1 build-essential git libssl-dev\n</code></pre> <p>You may need to install Python's <code>setuptools</code> and update pip/pip3:</p> <pre><code>sudo pip3 install -U pip setuptools\n</code></pre>"},{"location":"cortex/installation-and-configuration/analyzers-responders/#clone-the-repository","title":"Clone the repository","text":"<p>Once finished, clone the Cortex-analyzers repository in the directory of your choosing:</p> <pre><code>cd /opt\ngit clone https://github.com/TheHive-Project/Cortex-Analyzers\nchown -R cortex:cortex /opt/Cortex-Analyzers </code></pre>"},{"location":"cortex/installation-and-configuration/analyzers-responders/#install-dependencies","title":"Install dependencies","text":"<p>Each analyzer comes with its own, pip compatible <code>requirements.txt</code> file. You can install all requirements with the following commands:</p> <pre><code>cd /opt\nfor I in $(find Cortex-Analyzers -name 'requirements.txt'); do sudo -H pip3 install -r $I || true; done\n</code></pre>"},{"location":"cortex/installation-and-configuration/analyzers-responders/#configure-cortex_1","title":"Configure Cortex","text":"<p>Next, you'll need to tell Cortex where to find the analyzers. Analyzers may be in different directories as shown in this dummy example of the Cortex configuration file (<code>application.conf</code>):</p> /etc/cortex/application.conf<pre><code>[..]\nanalyzer {\n# Directory that holds analyzers\nurls = [\n\"/opt/Cortex-Analyzers/responders\",\n]\n\nfork-join-executor {\n# Min number of threads available for analyze\nparallelism-min = 2\n# Parallelism (threads) ... ceil(available processors * factor)\nparallelism-factor = 2.0\n# Max number of threads available for analyze\nparallelism-max = 4\n}\n}\n\nresponder {\n# Directory that holds responders\nurls = [\n\"/opt/Cortex-Analyzers/responders\"\n]\n\nfork-join-executor {\n# Min number of threads available for analyze\nparallelism-min = 2\n# Parallelism (threads) ... ceil(available processors * factor)\nparallelism-factor = 2.0\n# Max number of threads available for analyze\nparallelism-max = 4\n}\n}\n[..]\n</code></pre>"},{"location":"cortex/installation-and-configuration/analyzers-responders/#run-you-own-analyzers-responders","title":"Run you own Analyzers &amp; Responders","text":"<p>Either you run them from the host or with Docker images, you can also run your own custom Analyzers and Responders. </p>"},{"location":"cortex/installation-and-configuration/analyzers-responders/#dedicated-folder","title":"Dedicated folder","text":"<p>Create a dedicated folder to host your programs: </p> <pre><code>cd /opt\nmkdir -p Custom-Analyzers/{analyzers,responder}\nchown -R cortex:cortex /opt/Cortex-Analyzers </code></pre>"},{"location":"cortex/installation-and-configuration/analyzers-responders/#update-cortex-configuration","title":"Update Cortex configuration","text":"<p>Update <code>analyzer.urls</code> and <code>responders.urls</code> accordingly.</p> /etc/cortex/application.conf<pre><code>[..]\nanalyzer {\n# Directory that holds analyzers\nurls = [\n\"https://download.thehive-project.org/analyzers.json\",\n\"/opt/Custom-Analyzers/analyzers\" ]\n\nfork-join-executor {\n# Min number of threads available for analyze\nparallelism-min = 2\n# Parallelism (threads) ... ceil(available processors * factor)\nparallelism-factor = 2.0\n# Max number of threads available for analyze\nparallelism-max = 4\n}\n}\n\nresponder {\n# Directory that holds responders\nurls = [\n\"https://download.thehive-project.org/responders.json\",\n\"/opt/Custom-Analyzers/responders\" ]\n\nfork-join-executor {\n# Min number of threads available for analyze\nparallelism-min = 2\n# Parallelism (threads) ... ceil(available processors * factor)\nparallelism-factor = 2.0\n# Max number of threads available for analyze\nparallelism-max = 4\n}\n}\n[..]\n</code></pre> <p>Then restart Cortex for the changes to take effect.</p> <p>How to develop your own Analyzers or Responders ?</p> <p>Have a look at the dedicated documentation: https://thehive-project.github.io/Cortex-Analyzers/dev_guides/how-to-create-an-analyzer/</p>"},{"location":"cortex/installation-and-configuration/authentication/","title":"Authentication","text":"<p>Like TheHive, Cortex supports local, LDAP, Active Directory (AD), X.509 SSO and/or API keys for authentication and OAuth2.</p> <p>Please note that API keys can only be used to interact with the Cortex API (for example when TheHive is interfaced with a Cortex instance, it must use an API key to authenticate to it). API keys cannot be used to authenticate to the Web UI. By default, Cortex relies on local credentials stored in Elasticsearch.</p> <p>Authentication methods are stored in the <code>auth.provider</code> parameter, which is multi-valued. When a user logs in, each authentication method is tried in order until one succeeds. If no authentication method works, an error is returned and the user cannot log in.</p> <p>The default values within the configuration file are:</p> <pre><code>auth {\n  # \"provider\" parameter contains authentication provider. It can be multi-valued (useful for migration)\n  # available auth types are:\n  # services.LocalAuthSrv : passwords are stored in user entity (in Elasticsearch). No configuration is required.\n  # ad : use ActiveDirectory to authenticate users. Configuration is under \"auth.ad\" key\n  # ldap : use LDAP to authenticate users. Configuration is under \"auth.ldap\" key\n  # oauth2 : use OAuth/OIDC to authenticate users. Configuration is under \"auth.oauth2\" and \"auth.sso\" keys\n  provider = [local]\n\n  # By default, basic authentication is disabled. You can enable it by setting \"method.basic\" to true.\n  method.basic = false\n\n  ad {\n    # The name of the Microsoft Windows domain using the DNS format. This parameter is required.\n    #domainFQDN = \"mydomain.local\"\n\n    # Optionally you can specify the host names of the domain controllers. If not set, Cortex uses \"domainFQDN\".\n    #serverNames = [ad1.mydomain.local, ad2.mydomain.local]\n\n    # The Microsoft Windows domain name using the short format. This parameter is required.\n    #domainName = \"MYDOMAIN\"\n\n    # Use SSL to connect to the domain controller(s).\n    #useSSL = true\n  }\n\n  ldap {\n    # LDAP server name or address. Port can be specified (host:port). This parameter is required.\n    #serverName = \"ldap.mydomain.local:389\"\n\n    # If you have multiple ldap servers, use the multi-valued settings.\n    #serverNames = [ldap1.mydomain.local, ldap2.mydomain.local]\n\n    # Use SSL to connect to directory server\n    #useSSL = true\n\n    # Account to use to bind on LDAP server. This parameter is required.\n    #bindDN = \"cn=cortex,ou=services,dc=mydomain,dc=local\"\n\n    # Password of the binding account. This parameter is required.\n    #bindPW = \"***secret*password***\"\n\n    # Base DN to search users. This parameter is required.\n    #baseDN = \"ou=users,dc=mydomain,dc=local\"\n\n    # Filter to search user {0} is replaced by user name. This parameter is required.\n    #filter = \"(cn={0})\"\n  }\n\n  oauth2 {\n    # URL of the authorization server\n    #clientId = \"client-id\"\n    #clientSecret = \"client-secret\"\n    #redirectUri = \"https://my-cortex-instance.example/api/ssoLogin\"\n    #responseType = \"code\"\n    #grantType = \"authorization_code\"\n\n    # URL from where to get the access token\n    #authorizationUrl = \"https://auth-site.com/OAuth/Authorize\"\n    #tokenUrl = \"https://auth-site.com/OAuth/Token\"\n\n    # The endpoint from which to obtain user details using the OAuth token, after successful login\n    #userUrl = \"https://auth-site.com/api/User\"\n    #scope = [\"openid profile\"]\n  }\n\n  # Single-Sign On\n  sso {\n    # Autocreate user in database?\n    #autocreate = false\n\n    # Autoupdate its profile and roles?\n    #autoupdate = false\n\n    # Autologin user using SSO?\n    #autologin = false\n\n    # Name of mapping class from user resource to backend user ('simple' or 'group')\n    #mapper = group\n    #attributes {\n    #  login = \"user\"\n    #  name = \"name\"\n    #  groups = \"groups\"\n    #  organization = \"org\"\n    #}\n    #defaultRoles = [\"read\"]\n    #defaultOrganization = \"csirt\"\n    #groups {\n    #  # URL to retreive groups (leave empty if you are using OIDC)\n    #  #url = \"https://auth-site.com/api/Groups\"\n    #  # Group mappings, you can have multiple roles for each group: they are merged\n    #  mappings {\n    #    admin-profile-name = [\"admin\"]\n    #    editor-profile-name = [\"write\"]\n    #    reader-profile-name = [\"read\"]\n    #  }\n    #}\n\n    #mapper = simple\n    #attributes {\n    #  login = \"user\"\n    #  name = \"name\"\n    #  roles = \"roles\"\n    #  organization = \"org\"\n    #}\n    #defaultRoles = [\"read\"]\n    #defaultOrganization = \"csirt\"\n  }\n\n}\n\n# Maximum time between two requests without requesting authentication\nsession {\n  warning = 5m\n  inactivity = 1h\n}\n</code></pre>"},{"location":"cortex/installation-and-configuration/authentication/#oauth2openid-connect","title":"OAuth2/OpenID Connect","text":"<p>To enable authentication using OAuth2/OpenID Connect, edit the <code>application.conf</code> file and supply the values of <code>auth.oauth2</code> according to your environment. In addition, you need to supply:</p> <ul> <li><code>auth.sso.attributes.login</code>: name of the attribute containing the OAuth2 user's login in retreived user info (mandatory)</li> <li><code>auth.sso.attributes.name</code>: name of the attribute containing the OAuth2 user's name in retreived user info (mandatory)</li> <li><code>auth.sso.attributes.groups</code>: name of the attribute containing the OAuth2 user's groups (mandatory using groups mappings)</li> <li><code>auth.sso.attributes.roles</code>: name of the attribute containing the OAuth2 user's roles in retreived user info (mandatory using simple mapping)</li> </ul> <p>Important note</p> <p>Authenticate the user using an external OAuth2 authenticator server. The configuration is:</p> <ul> <li>clientId (string) client ID in the OAuth2 server.</li> <li>clientSecret (string) client secret in the OAuth2 server.</li> <li>redirectUri (string) the url of TheHive AOuth2 page (.../api/ssoLogin).</li> <li>responseType (string) type of the response. Currently only \"code\" is accepted.</li> <li>grantType (string) type of the grant. Currently only \"authorization_code\" is accepted.</li> <li>authorizationUrl (string) the url of the OAuth2 server.</li> <li>authorizationHeader (string) prefix of the authorization header to get user info: Bearer, token, ...</li> <li>tokenUrl (string) the token url of the OAuth2 server.</li> <li>userUrl (string) the url to get user information in OAuth2 server.</li> <li>scope (list of string) list of scope.</li> </ul> <p>Example configuration for SSO w/ Oauth2 &amp; Github</p> <pre><code>auth {\n\n  provider = [local, oauth2]\n\n  [..]\n\n  sso {\n    autocreate: false\n    autoupdate: false\n    mapper: \"simple\"\n    attributes {\n      login: \"login\"\n      name: \"name\"\n      roles: \"role\"\n    }\n    defaultRoles: [\"read\", \"analyze\"]\n    defaultOrganization: \"demo\"\n  }  \n  oauth2 {\n    name: oauth2\n    clientId: \"Client_ID\"\n    clientSecret: \"Client_ID\"\n    redirectUri: \"http://localhost:9001/api/ssoLogin\"\n    responseType: code\n    grantType: \"authorization_code\"\n    authorizationUrl: \"https://github.com/login/oauth/authorize\"\n    authorizationHeader: \"token\"\n    tokenUrl: \"https://github.com/login/oauth/access_token\"\n    userUrl: \"https://api.github.com/user\"\n    scope: [\"user\"]\n  }\n\n  [..]  \n}\n</code></pre>"},{"location":"cortex/installation-and-configuration/database/","title":"Database configuration","text":"/etc/cortex/application.conf<pre><code>[..]\n## ElasticSearch\nsearch {\nindex = cortex\n# For cluster, join address:port with ',': \"http://ip1:9200,ip2:9200,ip3:9200\"\nuri = \"http://127.0.0.1:9200\"\n\n## Advanced configuration\n# Scroll keepalive.\n#keepalive = 1m\n# Scroll page size.\n#pagesize = 50\n# Number of shards\n#nbshards = 5\n# Number of replicas\n#nbreplicas = 1\n# Arbitrary settings\n#settings {\n#  # Maximum number of nested fields\n#  mapping.nested_fields.limit = 100\n#}\n\n## Authentication configuration\n#username = \"\"\n#password = \"\"\n\n## SSL configuration\n#keyStore {\n#  path = \"/path/to/keystore\"\n#  type = \"JKS\" # or PKCS12\n#  password = \"keystore-password\"\n#}\n#trustStore {\n#  path = \"/path/to/trustStore\"\n#  type = \"JKS\" # or PKCS12\n#  password = \"trustStore-password\"\n#}\n}\n</code></pre>"},{"location":"cortex/installation-and-configuration/docker/","title":"Parameters for Docker","text":""},{"location":"cortex/installation-and-configuration/docker/#list-of-options","title":"list of options","text":"<ul> <li><code>docker.container.capAdd</code>: (array of string) Add Linux capabilities</li> <li><code>docker.container.capDrop</code>: (array of string) Drop Linux capabilities</li> <li><code>docker.container.cgroupParent</code>: (string) Cgroup to run a container in</li> <li><code>docker.container.cpuPeriod</code>: (integer) Limit the CPU CFS (Completely Fair Scheduler) period</li> <li><code>docker.container.cpuQuota</code>: (integer) Limit the CPU CFS (Completely Fair Scheduler) quota</li> <li><code>docker.container.dns</code>: (array of string) Set custom dns servers for the container</li> <li><code>docker.container.dnsSearch</code>: (array of string) Search list for host-name lookup.</li> <li><code>docker.container.extraHosts</code>: (array of string) Add a line to /etc/hosts (host:IP)</li> <li><code>docker.container.kernelMemory</code>: (integer) Kernel memory limit</li> <li><code>docker.container.memoryReservation</code>: (integer) Memory soft limit</li> <li><code>docker.container.memory</code>: (integer) Memory limit</li> <li><code>docker.container.memorySwap</code>: (integer) Total memory limit (memory + swap)</li> <li><code>docker.container.memorySwappiness</code>: (integer) Tune a container\u2019s memory swappiness behavior. Accepts an integer between 0 and 100</li> <li><code>docker.container.networkMode</code>: (string) name of the network</li> <li><code>docker.container.privileged</code>: (boolean) Give extended privileges to this container</li> <li><code>job.directory</code>: (string) Folder used by Cortex binary inside the container to share input and output data of Analyzers &amp; Responders</li> <li><code>job.dockerDirectory</code> = (string) Folder on the host used by Analyzers &amp; Responders to share input and output data with Cortex</li> </ul>"},{"location":"cortex/installation-and-configuration/docker/#dockerized-analyzers-responders","title":"Dockerized analyzers / responders","text":"<p>To run Analyzers&amp;Responders as docker images, use our available catalogs to register them.</p> <p>In Cortex configuration file, update <code>analyzer.urls</code> and <code>responder.urls</code> and tell Cortex how to find analyzers and responders. These settings accept:    - a path to a directory where workers are installed (like previous version of Cortex)    - a path or an url (http(s)) to a JSON file containing all worker definitions (merge of all JSON in one array)</p> <p>If you want to use dockerized analyzers, you can add the following urls:  - analyzers-stable.json (once used, analyzer is never updated)   - analyzers.json (updated when new version is released)  - analyzers-devel.json (updated at each commit, used for development)</p> <p>For responders urls are:   - responders-stable.json (once used, analyzer is never updated)   - responders.json (updated when new version is released)   - responders-devel.json (updated at each commit, used for development)</p>"},{"location":"cortex/installation-and-configuration/proxy-settings/","title":"Proxy settings","text":""},{"location":"cortex/installation-and-configuration/proxy-settings/#make-cortex-use-a-http-proxy-server","title":"Make Cortex use a HTTP proxy server","text":"<p>Basically, Cortex required to connect to Internet, especially to gather  catalogs of docker images of public Analyzers &amp; Responders.</p> /etc/cortex/application.conf<pre><code>[..]\nplay.ws.proxy {\nhost = http://PROXYSERVERADDRESS:PORT\nport = http://PROXYSERVERADDRESS:PORT\n}\n[..]\n</code></pre>"},{"location":"cortex/installation-and-configuration/proxy-settings/#operating-system","title":"Operating System","text":"/etc/environment<pre><code>export http_proxy=http://PROXYSERVERADDRESS:PORT\nexport https_proxy=http://PROXYSERVERADDRESS:PORT  \n</code></pre> <p>Specific configuration for Debian apt application</p> /etc/apt/apt.conf.d/80proxy<pre><code>  HTTP::proxy \"http://PROXYSERVERADDRESS:PORT\";\n  HTTPS::proxy \"http://PROXYSERVERADDRESS:PORT\";\n</code></pre>"},{"location":"cortex/installation-and-configuration/proxy-settings/#pip","title":"pip","text":"<p>If Analyzers and Responders requirements have to be installed on the host, and the host is behind a proxy server, configure the pip command to use the proxy server ; use the option <code>--proxy http://PROXYSERVERADDRESS:PORT\"</code>, and <code>--cert path/to/cacert.pem</code> if a custom certificate is used by the proxy.</p> <pre><code>pip3 install --proxy http://PROXYSERVERADDRESS:PORT\" -r analyzers/*/requirements.txt\n</code></pre> <p>or </p> <pre><code>pip3 install --proxy http://PROXYSERVERADDRESS:PORT\" --cert path/to/cacert.pem -r analyzers/*/requirements.txt\n</code></pre>"},{"location":"cortex/installation-and-configuration/proxy-settings/#git","title":"Git","text":"<pre><code>sudo git config --global http.proxy http://PROXYSERVERADDRESS:PORT\nsudo git config --global https.proxy http://PROXYSERVERADDRESS:PORT\n</code></pre>"},{"location":"cortex/installation-and-configuration/proxy-settings/#docker","title":"Docker","text":"<p>If using Analyzers &amp; Responders as docker images, setting up proxy parameters could be required to download images.</p> <p>Update Docker engine configuration by editing/creating the file <code>/etc/systemd/system/docker.service.d/http-proxy.conf</code>: </p> /etc/systemd/system/docker.service.d/http-proxy.conf<pre><code>[Service]\nEnvironment=http://PROXYSERVERADDRESS:PORT\"\nEnvironment=\"http://PROXYSERVERADDRESS:PORT\"\n</code></pre> <p>Then run: </p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl restart docker\n</code></pre>"},{"location":"cortex/installation-and-configuration/run-cortex-with-docker/","title":"Run Cortex with Docker","text":""},{"location":"cortex/installation-and-configuration/run-cortex-with-docker/#docker","title":"Docker","text":"<p>To use the Docker image, you must use Docker (courtesy of Captain Obvious). Alternatively, it's also possible to run the image using Podman.</p> <p>By default, the docker image generate a configuration file for Cortex with:  - the Elasticsearch uri is determined by resolving the host name \"elasticsearch\",  - the analyzers and responders official location,  - a generated secret (used to protect the user sessions). The behaviour of the Cortex Docker image can be customized using environment variables or parameters:</p> Parameter Env variable Description <code>--no-config</code> <code>no_config=1</code> Do not configure Cortex <code>--no-config-secret</code> <code>no_config_secret=1</code> Do not add the random secret to the configuration <code>--no-config-es</code> <code>no_config_es=1</code> do not add elasticsearch hosts to configuration <code>--es-uri &lt;uri&gt;</code> <code>es_uri=&lt;uri&gt;</code> use this string to configure elasticsearch hosts (format: http(s)://host:port,host:port(/prefix)?querystring) <code>--es-hostname &lt;host&gt;</code> <code>es_hostname=host</code> resolve this hostname to find elasticsearch instances <code>--secret &lt;secret&gt;</code> <code>secret=&lt;secret&gt;</code> secret to secure sessions <code>--show-secret</code> <code>show_secret=1</code> show the generated secret <code>--job-directory &lt;dir&gt;</code> <code>job_directory=&lt;dir&gt;</code> use this directory to store job files <code>--docker-job-directory &lt;dir&gt;</code> <code>docker_job_directory=&lt;dir&gt;</code> indicate the job directory in the host (not inside container) <code>--analyzer-url &lt;url&gt;</code> <code>analyzer_urls=&lt;url&gt;,&lt;url&gt;,...</code> where analyzers are located (url or path) <code>--responder-url &lt;url&gt;</code> <code>responder_urls=&lt;url&gt;,&lt;url&gt;,...</code> where responders are located (url or path) <code>--start-docker</code> <code>start_docker=1</code> start an internal docker (inside container) to run analyzers/responders <code>--daemon-user &lt;user&gt;</code> <code>daemon_user=&lt;user&gt;</code> run cortex using this user <p>At the end of the generated configuration, the file <code>/etc/cortex/application.conf</code> is included. Thus you can override any setting by binding your own <code>application.conf</code> into this file:</p> <pre><code>docker run --volume /path/to/my/application.conf:/etc/cortex/application.conf thehiveproject/cortex:3.1.0-1 --es-uri http://elasticsearch.local:9200\n</code></pre> <p>Cortex uses docker to run analyzers and responders. If you run Cortex inside a docker, you can:</p> <ul> <li>give Cortex access to docker service or podman service (recommended solution)</li> <li>start a docker service inside Cortex docker container</li> </ul>"},{"location":"cortex/installation-and-configuration/run-cortex-with-docker/#cortex-uses-main-docker-service","title":"Cortex uses main docker service","text":"<p>In order to use docker service the docker socket must be bound into Cortex container. Moreover, as Cortex shares files with analyzers, a folder must be bound between them.</p> <pre><code>docker run --volume /var/run/docker.sock:/var/run/docker.sock --volume /var/run/cortex/jobs:/tmp/cortex-jobs thehiveproject/cortex:3.1.0-1 --job-directory /tmp/cortex-jobs --docker-job-directory /var/run/cortex/jobs\n</code></pre> <p>Cortex can instantiate docker container by using the docker socket <code>/var/run/docker.sock</code>. The folder <code>/var/run/cortex/jobs</code> is used to store temporary file of jobs. The folder <code>/tmp/cortex-jobs</code> is job folder inside the docker. In order to make job file visible to analyzer docker, Cortex needs to know both folders (parameters <code>--job-directory</code> and <code>-docker-job-directory</code>). On most cases, job directories are the same and <code>--docker-job-directory</code> can be omitted.</p> <p>If you run Cortex in Windows, the docker service is accessible through the named pipe <code>\\\\.\\pipe\\docker_engine</code>. The command becomes</p> <pre><code>docker run --volume //./pipe/docker_engine://./pipe/docker_engine --volume C:\\\\CORTEX\\\\JOBS:/tmp/cortex-jobs thehiveproject/cortex:latest --job-directory /tmp/cortex-jobs --docker-job-directory C:\\\\CORTEX\\\\JOBS\n</code></pre>"},{"location":"cortex/installation-and-configuration/run-cortex-with-docker/#docker-in-docker-docker-ception","title":"Docker in docker (docker-ception)","text":"<p>You can also run docker service inside Cortex container, a docker in a docker with <code>--start-docker</code> parameter. The container must be run in privileged mode.</p> <pre><code>docker run --privileged thehiveproject/cortex:3.1.0-1 --start-docker\n</code></pre> <p>In this case you don't need to bind job directory.</p>"},{"location":"cortex/installation-and-configuration/run-cortex-with-docker/#use-docker-compose","title":"Use Docker-compose","text":"<p>Cortex requires Elasticsearch to run. You can use <code>docker-compose</code> to start them together in Docker or install and configure Elasticsearch manually. Docker-compose can start multiple dockers and link them together.</p> <p>The following docker-compose.yml file starts Elasticsearch and Cortex:</p> <pre><code>version: \"2\"\nservices:\n  elasticsearch:\n    image: elasticsearch:7.9.1\n    environment:\n      - http.host=0.0.0.0\n      - discovery.type=single-node\n      - script.allowed_types=inline\n      - thread_pool.search.queue_size=100000\n      - thread_pool.write.queue_size=10000\n    volumes:\n      - /path/to/data:/usr/share/elasticsearch/data\n  cortex:\n    image: thehiveproject/cortex:3.1.1\n    environment:\n      - job_directory=${job_directory}\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - ${job_directory}:${job_directory}\n    depends_on:\n      - elasticsearch\n    ports:\n      - \"0.0.0.0:9001:9001\"\n</code></pre> <p>Put this docker-compose file and .env in an empty folder and run <code>docker-compose up</code>. Cortex is exposed on 9001/tcp port. These ports can be changed by modifying the <code>docker-compose</code> file.</p> <p>For advanced configuration, visit our Docker Templates repository</p>"},{"location":"cortex/installation-and-configuration/run-cortex-with-docker/#cortex-with-podman","title":"Cortex with podman","text":"<p>Like docker, podman will be able to run the container image of cortex and of its analyzers. The examples below assume that the containers are run as rootful.</p> <p>For Cortex to interact with podman, it needs to use the podman socket. On some systems, podman will automatically install and enable this service. You can check this on your system with:</p> <pre><code>systemctl status podman.socket\n</code></pre> <p>Here we assume that the podman socket is accessible on <code>/run/podman/podman.sock</code>. This may change based on your system.</p> <p>Cortex uses podman service</p> <p>You need to mount the podman socket inside the container to <code>/var/run/docker.sock</code></p> <pre><code>podman run \\\n--rm \\\n--name cortex \\\n-p 9001:9001 \\\n-v /var/run/cortex/jobs:/tmp/cortex-jobs \\\n-v /run/podman/podman.sock:/var/run/docker.sock \\\ndocker.io/thehiveproject/cortex:3.1.7 \\\n--job-directory /tmp/cortex-jobs \\\n--docker-job-directory /var/run/cortex/jobs \\\n--es-uri http://$ES_IP:9200\n</code></pre> <p>With this configuration, Cortex analyzers will be run by podman.</p> <p>Image not found</p> <p>Podman may have trouble pulling cortex neurons images from the regular docker registry. You may have to add docker.io as an unqualified registry. To do this, add this line to your config <code>/etc/containers/registries.conf</code>:</p> <pre><code>unqualified-search-registries = ['docker.io']\n</code></pre> <p>Then restart the podman socket service too</p> <p>Docker in podman</p> <p>By running with the flag <code>--privileged</code>, it is possible to start docker inside a podman container</p> <pre><code>podman run \\\n--privileged \\\n--rm \\\n--name cortex \\\n-p 9001:9001 \\\ndocker.io/thehiveproject/cortex:3.1.7 \\\n--es-uri http://$ES_IP:9200\n  --start-docker\n</code></pre>"},{"location":"cortex/installation-and-configuration/secret/","title":"Secret key configuration","text":"<p>Setup a secret key for this instance: </p> <pre><code>cat &gt; /etc/cortex/secret.conf &lt;&lt; _EOF_\nplay.http.secret.key=\"$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 64 | head -n 1)\"\n_EOF_\n</code></pre> <p>Then, in the file <code>/etc/cortex/application.conf</code>, replace the line including <code>play.http.secret.key=</code> by:</p> /etc/cortex/application.conf<pre><code>[..]\ninclude /etc/cortex/secret.conf\n[..]\n</code></pre>"},{"location":"cortex/installation-and-configuration/ssl/","title":"Configure SSL","text":""},{"location":"cortex/installation-and-configuration/ssl/#connect-cortex-using-https","title":"Connect Cortex using HTTPS","text":"<p>We recommend using a reverse proxy to manage SSL layer; for example, Nginx. </p> Nginx <p>Reference: Configuring HTTPS servers on nginx.org</p> /etc/nginx/sites-available/cortex.conf<pre><code>server {\n  listen 443 ssl http2;\n  server_name cortex;\n\n  ssl on;\n  ssl_certificate       path-to/cortex-server-chained-cert.pem;\n  ssl_certificate_key   path-to/cortex-server-key.pem;\n\n  proxy_connect_timeout   600;\n  proxy_send_timeout      600;\n  proxy_read_timeout      600;\n  send_timeout            600;\n  client_max_body_size    2G;\n  proxy_buffering off;\n  client_header_buffer_size 8k;\n\n  location / {\n    add_header              Strict-Transport-Security \"max-age=31536000; includeSubDomains\";\n    proxy_pass              http://127.0.0.1:9001/;\n    proxy_http_version      1.1;\n  }\n}\n</code></pre>"},{"location":"cortex/installation-and-configuration/ssl/#certificate-manager","title":"Certificate manager","text":"<p>Certificate manager is used to store client certificates and certificate authorities.</p>"},{"location":"cortex/installation-and-configuration/ssl/#use-custom-certificate-authorities","title":"Use custom Certificate Authorities","text":"<p>The prefered way to use custom Certificate Authorities is to use the system configuration. </p> <p>If setting up a custom Certificate Authority (to connect web proxies, remote services like LPAPS server ...) is required globally in the application, the better solution consists of installing it on the OS and restarting Cortex. </p> DebianRPM <p>Ensure the package <code>ca-certificates-java</code> is installed , and copy the CA certificate in the right folder. Then run <code>dpkg-reconfigure ca-certificates</code> and restart Cortex service. </p> <pre><code>apt-get install -y ca-certificates-java\nmkdir /usr/share/ca-certificates/extra\ncp mycustomcert.crt /usr/share/ca-certificates/extra\ndpkg-reconfigure ca-certificates\nservice cortex restart\n</code></pre> <p>No additionnal packages is required on Fedora or RHEL. Copy the CA certificate in the right folder, run <code>update-ca-trust</code> and restart Cortex service.</p> <pre><code>cp mycustomcert.crt /etc/pki/ca-trust/source/anchors\nsudo update-ca-trust \nservice cortex restart\n</code></pre>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/","title":"Step-by-Step guide","text":"<p>This page is a step by step installation and configuration guide to get a Cortex instance up and running. This guide is illustrated with examples for Debian and RPM packages based systems and for installation from binary packages.</p>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/#required-packages","title":"Required packages","text":"DebianRPM <pre><code>apt install wget gnupg apt-transport-https git ca-certificates ca-certificates-java curl  software-properties-common python3-pip lsb_release\n</code></pre> <pre><code>yum install pkg-install gnupg chkconfig python3-pip git </code></pre>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/#java-virtual-machine","title":"Java Virtual Machine","text":"<p>Install Java</p> DebianRPMOther <pre><code>apt install -y openjdk-8-jre-headless\necho JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\" &gt;&gt; /etc/environment\nexport JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n</code></pre> <pre><code>sudo yum install -y java-1.8.0-openjdk-headless.x86_64\necho JAVA_HOME=\"/usr/lib/jvm/jre-1.8.0\" | sudo tee -a /etc/environment\nexport JAVA_HOME=\"/usr/lib/jvm/jre-1.8.0\"\n</code></pre> <p>The installation requires Java 8, so refer to your system documentation to install it.</p>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/#elasticsearch","title":"Elasticsearch","text":"DebianRPM <pre><code>wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch |  sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg\necho \"deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/7.x/apt stable main\" |  sudo tee /etc/apt/sources.list.d/elastic-7.x.list \nsudo apt install elasticsearch   </code></pre> /etc/yum.repos.d/elasticsearch.repo<pre><code>[elasticsearch]\nname=Elasticsearch repository for 7.x packages\nbaseurl=https://artifacts.elastic.co/packages/7.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=0\nautorefresh=1\ntype=rpm-md\n</code></pre> <pre><code>sudo yum install --enablerepo=elasticsearch elasticsearch\n</code></pre>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/#configuration","title":"Configuration","text":"/etc/elasticsearch/elasticsearch.yml<pre><code>http.host: 127.0.0.1\ntransport.host: 127.0.0.1\ncluster.name: hive\nthread_pool.search.queue_size: 100000\npath.logs: \"/var/log/elasticsearch\"\npath.data: \"/var/lib/elasticsearch\"\nxpack.security.enabled: false\nscript.allowed_types: \"inline,stored\"\n</code></pre> <p>Adjust this file according to the amount of RAM available on your server: </p> /etc/elasticsearch/jvm.options.d/jvm.options<pre><code>-Dlog4j2.formatMsgNoLookups=true\n-Xms4g\n-Xmx4g\n</code></pre>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/#docker","title":"Docker","text":"<p>If using Docker images of Analyzers and Responders, Docker engine is required on the Operating System: </p> DebianRPM <pre><code>curl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\\n$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list\napt install docker-ce\n</code></pre> <pre><code>sudo yum remove -yq docker \\\ndocker-client \\\ndocker-client-latest \\\ndocker-common \\\ndocker-latest \\\ndocker-latest-logrotate \\\ndocker-logrotate \\\ndocker-engine\nsudo dnf -yq install dnf-plugins-core\nsudo dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo\nsudo dnf install -yq docker-ce docker-ce-cli containerd.io docker-compose-plugin\n</code></pre>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/#cortex","title":"Cortex","text":"<p>This part contains instructions to install Cortex and then configure it.</p>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/#installation","title":"Installation","text":"<p>All packages are published on our packages repository. We support Debian and RPM packages as well as binary packages (zip archive). All packages are signed using our GPG key 562CBC1C. Its fingerprint is <code>0CD5 AC59 DE5C 5A8E 0EE1  3849 3D99 BB18 562C BC1C</code>.</p> DebianRPM <pre><code>wget -O- \"https://raw.githubusercontent.com/TheHive-Project/Cortex/master/PGP-PUBLIC-KEY\"  | sudo apt-key add -\nwget -qO- https://raw.githubusercontent.com/TheHive-Project/Cortex/master/PGP-PUBLIC-KEY |  sudo gpg --dearmor -o /usr/share/keyrings/thehive-project.gpg\necho 'deb https://deb.thehive-project.org release main' | sudo tee -a /etc/apt/sources.list.d/thehive-project.list\napt install cortex\n</code></pre> /etc/yum.repos.d/thehive-project.repo<pre><code>[cortex]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=https://rpm.thehive-project.org/release/noarch\ngpgkey=https://raw.githubusercontent.com/TheHive-Project/Cortex/master/PGP-PUBLIC-KEY\ngpgcheck=1\n</code></pre> <pre><code>yum install cortex\n</code></pre>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/#configuration_1","title":"Configuration","text":"<p>Following settings are required to start Cortex successfully:</p> <ul> <li>Secret key configuration</li> <li>Database configuration</li> <li>Authentication</li> <li>Analyzers &amp; Responders configuration</li> </ul> <p>Advanced configuration settings might be added to run the application successfully: </p> <ul> <li>Specific Docker parameters</li> <li>Proxy settings</li> <li>SSL configuration</li> </ul>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/#start-cortex-service","title":"Start Cortex service","text":"<p>Warning</p> <p>Before starting the service, ensure to have configured accordingly the application. Start by setting up the secret key.</p> <p>Save configuration file and run the service:</p> <pre><code>systemctl start cortex\n</code></pre> <p>Please note that the service may take some time to start. Once it is started, you may launch your browser and connect to <code>http://YOUR_SERVER_ADDRESS:9001/</code>. </p>"},{"location":"cortex/installation-and-configuration/step-by-step-guide/#first-start","title":"First start","text":"<p>Refer to the First start guide for the next steps.</p>"},{"location":"cortex/operations/backup-restore/","title":"Backup and restore data","text":"<p>All persistent data is stored in an Elasticsearch database. The backup and restore procedures are the ones that are detailed in Elasticsearch documentation.</p> <p>Note: you may have to adapt your indices in the examples below. To find the right index, use the following command :</p> <pre><code>curl 'localhost:9200/_cat/indices?v'\n</code></pre> <p>To save all your data you only need to backup the last indice. For example, if the previous command gives you the following results, all your data belongs to cortex_1.</p> <p>In the rest of this document, ensure to change  to your own last index in order to backup or restore all your data."},{"location":"cortex/operations/backup-restore/#1-create-a-backup-repository","title":"1. Create a backup repository","text":"<p>First you must define a location in local filesystem (where Elasticsearch instance runs) where the backup will be written. This repository must be declared in the Elasticsearch configuration. Edit elasticsearch.yml file by adding:</p> <pre><code>path.repo: [\"/absolute/path/to/backup/directory\"]\n</code></pre> <p>Then, restart the Elasticsearch service.</p> <p>Note: Be careful if you run Elasticsearch in Docker, the directory must be mapped in host filesystem using <code>--volume</code> parameter (cf. Docker documentation).</p>"},{"location":"cortex/operations/backup-restore/#2-register-a-snapshot-repository","title":"2. Register a snapshot repository","text":"<p>Create an Elasticsearch snapshot point named cortex_backup with the following command (set the same path in the location setting as the one set in the configuration file):</p> <pre><code>$ curl -XPUT 'http://localhost:9200/_snapshot/cortex_backup' -d '{\n    \"type\": \"fs\",\n    \"settings\": {\n        \"location\": \"/absolute/path/to/backup/directory\",\n        \"compress\": true\n    }\n}'\n</code></pre> <p>The result of the command should look like this :</p> <pre><code>{\"acknowledged\":true}\n</code></pre> <p>Since, everything is fine to backup and restore data.</p>"},{"location":"cortex/operations/backup-restore/#3-backup-your-data","title":"3. Backup your data","text":"<p>Create a backup named snapshot_1 of all your data by executing the following command :</p> <p><pre><code>$ curl -XPUT 'http://localhost:9200/_snapshot/cortex_backup/snapshot_1?wait_for_completion=true&amp;pretty' -d '{\n  \"indices\": \"&lt;INDEX&gt;\"\n}'\n</code></pre> This command terminates only when the backup is complete and the result of the command should look like this:</p> <pre><code>{\n  \"snapshots\": [{\n    \"snapshot\": \"snapshot_1\",\n    \"uuid\": \"ZQ3kv5-FQoeN3NFIhfKgMg\",\n    \"version_id\": 5060099,\n    \"version\": \"5.6.0\",\n    \"indices\": [\"cortex_1\"],\n    \"state\": \"SUCCESS\",\n    \"start_time\": \"2018-01-29T14:41:51.580Z\",\n    \"start_time_in_millis\": 1517236911580,\n    \"end_time\": \"2018-01-29T14:42:05.216Z\",\n    \"end_time_in_millis\": 1517236925216,\n    \"duration_in_millis\": 13636,\n    \"failures\": [],\n    \"shards\": {\n      \"total\": 41,\n      \"failed\": 0,\n      \"successful\": 41\n    }\n  }]\n}\n</code></pre> <p>Note: You can backup the last index of Cortex (you can list indices in your Elasticsearch cluster with <code>curl -s http://localhost:9200/_cat/indices | cut -d ' '  -f3</code> ) or all indices with <code>_all</code> value.</p>"},{"location":"cortex/operations/backup-restore/#4-restore-data","title":"4. Restore data","text":"<p>Restore will do the reverse actions : it reads the backup in your snapshot directory and loads indices into the Elasticsearch cluster. This operation is done with the following command : <pre><code>$ curl -XPOST 'http://localhost:9200/_snapshot/cortex_backup/snapshot_1/_restore' -d '\n{\n  \"indices\": \"&lt;INDEX&gt;\"\n}'\n</code></pre></p> <p>The result of the command should look like this :</p> <pre><code>{\"accepted\":true}\n</code></pre> <p>Note: be sure to restore data from the same version of Elasticsearch.</p>"},{"location":"cortex/operations/backup-restore/#5-moving-data-from-one-server-to-another","title":"5. Moving data from one server to another","text":"<p>If you want to move your data from one server from another: - Create your backup on the origin server (steps 1, 2, 3) - copy your backup directory from the origin server to the destination server - On the destination server :     - Register your backup repository in the Elasticsearch configuration (step 1)     - Register your snapshot repository with the same snapshot name (step 2)     - Restore your data (step 4)</p>"},{"location":"cortex/operations/input-output/","title":"Analyzers/Responders input and output","text":""},{"location":"cortex/operations/input-output/#analyzers-responders-communication","title":"Analyzers / Responders communication","text":"<p>From version 3, cortexutils 2.x is required because communication between Cortex and the analyzers/responders has changed. Analyzers and responders doesn't need to be rewritten if they use cortexutils. Cortex 2 send data using stdin and receive result from stdout.</p> <p>Cortex 3 uses files: a job is stored in a folder with the following structure:</p> <pre><code>job_folder\n  \\_ input\n   |    \\_ input.json    &lt;- input data, equivalent to stdin with Cortex 2.x\n   |    |_ attachment    &lt;- optional extra file when analysis concerns a file\n   |_ output\n        \\_ output.json   &lt;- report of the analysis (generated by analyzer or responder)\n        |_ extra_file(s) &lt;- optional extra files linked to report (generated by analyzer)\n</code></pre> <p>Job folder is provided to analyzer/responder as argument. Currently, only one job is acceptable but in future release, analyzer/responder will accept several job at a time (bulk mode) in order to increase performance.</p>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/","title":"Migration from Elasticsearch 6.8.2 to ES 7.x","text":"<p>\u26a0\ufe0f IMPORTANT NOTE</p> <ul> <li>This migration process is intended for single node of Elasticsearch database</li> <li>The current version of this document is provided for testing purpose ONLY! </li> <li>This guide has been written and tested to migrate data from ES 6.8.2 to ES 7.8.1, and Cortex 3.0.1 to Cortex 3.1.0 only!</li> <li>This guide starts with Elasticsearch version 6.8.2  up and running, indexes and data. To test this guide, we recommend using a backup of you production server. (see Backup and Restore page for more information)</li> <li>This guide is illustrated with Cortex index. The process is identical for Cortex, you just have to adjust index names.</li> </ul>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#prerequisite","title":"Prerequisite","text":"<p>The software <code>jq</code> is required to manipulate JSON and create new indexes. More information at https://stedolan.github.io/jq/. </p>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#identify-if-your-index-should-be-reindexed","title":"Identify if your index should be reindexed","text":"<p>You can easily identify if indexes should be reindexed or not. On the index named <code>cortex_4</code> run the following command: </p> <pre><code>curl -s http://127.0.0.1:9200/cortex_4?human | jq '.cortex_4.settings.index.version.created'\n</code></pre> <p>if the output is similar to <code>\"5xxxxxx\"</code>  then reindexing is required, you should follow this guide. </p> <p>If it is   <code>\"6xxxxxx\"</code> then the index can be read by Elasticsearch 7.8.x. Upgrade Elasticsearch, and Cortex 3.1.0.</p>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#migration-guide","title":"Migration guide","text":""},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#current-status","title":"Current status","text":"<p>Current context is:  - Elasticsearch 6.8.2 - Cortex 3.0.1</p> <p>All up and running. </p> <p>Start by identifying indices on you Elasticsearch instance.</p> <pre><code>curl  http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   cortex_4    Y5rDTO23RBC_n6pjFP0-Qw   5   0       8531            8       13mb           13mb \n</code></pre> <p>The index name is <code>cortex_4</code>. Record this somewhere.</p>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#stop-services","title":"Stop services","text":"<p>Before starting updating the database, lets stop applications:</p> <pre><code>sudo service cortex stop \n</code></pre>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#create-a-new-index","title":"Create a new index","text":"<p>The First operation lies in creating a new index named <code>new_cortex_4</code> with settings from current index <code>cortex_4</code> (ensure to keep index version, needed for future upgrade).</p> <pre><code>curl -XPUT 'http://localhost:9200/new_cortex_4' \\\n-H 'Content-Type: application/json' \\\n-d \"$(curl http://localhost:9200/cortex_4 |\\\njq '.cortex_4 |\n   del(.settings.index.provided_name,\n    .settings.index.creation_date,\n    .settings.index.uuid,\n    .settings.index.version,\n    .settings.index.mapping.single_type,\n    .mappings.doc._all)'\n)\"\n</code></pre> <p>Check the new index is well created: </p> <pre><code>curl -XGET http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   new_cortex_4    wRX6rhzXTuW_F2wLNxqVyg   5   0          0            0      1.1kb          1.1kb\ngreen  open   cortex_4        Y5rDTO23RBC_n6pjFP0-Qw   5   0       8531            8       13mb           13mb\n</code></pre>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#proceed-to-reindex","title":"Proceed to Reindex","text":"<p>Next operation lies in running the reindex command in the newly created index:</p> <pre><code>curl -XPOST -H 'Content-Type: application/json' http://localhost:9200/_reindex -d '{\n  \"conflicts\": \"proceed\",\n  \"source\": {\n    \"index\": \"cortex_4\"\n  },\n  \"dest\": {\n    \"index\": \"new_cortex_4\"\n  }\n}'\n</code></pre> <p>After a moment, you should get a similar output:  </p> <pre><code>{\n\"took\": 5119,\n\"timed_out\": false,\n\"total\": 5889,\n\"updated\": 0,\n\"created\": 5889,\n\"deleted\": 0,\n\"batches\": 6,\n\"version_conflicts\": 0,\n\"noops\": 0,\n\"retries\": {\n\"bulk\": 0,\n\"search\": 0\n},\n\"throttled_millis\": 0,\n\"requests_per_second\": -1.0,\n\"throttled_until_millis\": 0,\n\"failures\": []\n}\n</code></pre>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#ensure-new-index-has-been-created","title":"Ensure new index has been created","text":"<p>Run the following command, and ensure the new index is like the current one (size can vary):</p> <pre><code>curl -XGET http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   new_cortex_4    wRX6rhzXTuW_F2wLNxqVyg   5   0       8531            0     12.6mb         12.6mb\ngreen  open   cortex_4        Y5rDTO23RBC_n6pjFP0-Qw   5   0       8531            8       13mb           13mb\n</code></pre>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#delete-old-indices","title":"Delete old indices","text":"<p>This is the thrilling part.  Now the new index <code>new_cortex_4</code> is created and similar to <code>cortex_4</code>,  older indexes should be completely deleted from the database. To delete index named <code>cortex_4</code>, run the following command:  </p> <pre><code>curl -XDELETE http://localhost:9200/cortex_4\n</code></pre> <p>Run the same command for older indexes if exist (cortex_3, cortex_2....). Elasticsearch 7.x cannot run with index created with Elasticsearch 5.x.</p>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#create-an-alias","title":"Create an alias","text":"<p>Before stopping Elasticsearch service, let\u2019s create an alias to keep index names in the future.  </p> <pre><code>curl -XPOST -H 'Content-Type: application/json'  'http://localhost:9200/_aliases' -d '{\n    \"actions\": [\n        {\n            \"add\": {\n                \"index\": \"new_cortex_4\",\n                \"alias\": \"cortex_4\"\n            }\n        }\n    ]\n}'\n</code></pre> <p>Doing so will allow Cortex 3.1.0  to find the index without updating the configuration file. </p> <p>Check the alias has been well created by running the following command</p> <pre><code>curl -XGET http://localhost:9200/_alias?pretty\n</code></pre> <p>The output should look like:</p> <pre><code>{\n\"new_cortex_4\" : {\n\"aliases\" : {\n\"cortex_4\" : { }\n}\n}\n}\n</code></pre>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#stop-elasticsearch-version-682","title":"Stop Elasticsearch version 6.8.2","text":"<pre><code>sudo service elasticsearch stop </code></pre>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#update-elasticsearch","title":"Update Elasticsearch","text":"<p>Update the configuration of Elastisearch. Configuration file should look like this:</p> <pre><code>[..]\nhttp.host: 127.0.0.1\ndiscovery.type: single-node\ncluster.name: hive\nscript.allowed_types: inline\nthread_pool.search.queue_size: 100000\nthread_pool.write.queue_size: 10000    \n</code></pre> <p>Now, upgrade Elasticsearch to version 7.x following the documentation for your Operating System, and ensure the service start successfully.</p>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#install-or-update-to-cortex-310","title":"Install or update to Cortex 3.1.0","text":""},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#deb-package","title":"DEB package","text":"<p>If using Debian based Linux operating system, configure it to follow our beta repository:</p> <p><pre><code>curl https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY | sudo apt-key add -\necho 'deb https://deb.thehive-project.org release main' | sudo tee -a /etc/apt/sources.list.d/thehive-project.list\nsudo apt-get update\n</code></pre> Then install it by running:</p> <pre><code>sudo apt install cortex\n</code></pre> <p>or</p> <pre><code>sudo apt install cortex=3.1.0-1\n</code></pre>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#rpm","title":"RPM","text":"<p>Setup your system to connect the RPM repository. Create and edit the file  <code>/etc/yum.repos.d/thehive-project.repo</code> :</p> <pre><code>[thehive-project]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=http://rpm.thehive-project.org/release/noarch\ngpgcheck=1\n</code></pre> <p>Then install it by running:</p> <pre><code>sudo yum install cortex\n</code></pre> <p>or </p> <pre><code>sudo yum install cortex-3.1.0-1\n</code></pre>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#install-binaries","title":"Install binaries","text":"<pre><code>cd /opt\nwget https://download.thehive-project.org/cortex-3.1.0-1.zip\nunzip cortex-3.1.0-1.zip\nln -s cortex-3.1.0-1 cortex\n</code></pre>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#docker-images","title":"Docker images","text":"<p>Docker images are also provided on Dockerhub. </p> <pre><code>docker pull thehiveproject/cortex:3.1.0-1\n</code></pre> <p>\u26a0\ufe0f  Starting from this version, docker image doesn't contain analyzers anymore. Analyzers__/__Responders and Cortex have different life-cycles, their update including their dependencies should not be correlated to Cortex update. </p> <p>It is recommended to use docker version of analyzers : this can be done by binding docker service docket inside cortex container (run with <code>-v /var/run/docker.sock:/var/run/docker.sock</code>).</p>"},{"location":"cortex/operations/upgrade_to_cortex_3_1_and_es7_x/#update-database","title":"Update Database","text":"<p>Connect to TheHive (and Cortex), the maintenance page should ask to update. </p> <p></p> <p>Once updated, ensure a new index named <code>cortex_5</code> has been created.</p> <pre><code>curl -XGET http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   new_cortex_4 GV-3Y8QjTjWw0F-p2sjW6Q   5   0      30977            0       26mb           26mb\nyellow open   cortex_5     Nz0vCKqhRK2xkx1t_WF-0g   5   1      30977            0     26.1mb         26.1mb\n</code></pre>"},{"location":"cortex/user-guides/first-start/","title":"Quick Start Guide","text":"<p>This is the Quick Start guide for Cortex 3. It assumes that Cortex has been installed, and that the analyzers have been installed as well.</p>"},{"location":"cortex/user-guides/first-start/#step-1-connect-to-cortex","title":"Step 1: Connect to Cortex","text":"<p>One Cortex is installed and configured, open your web browser and connect to http://cortexaddress:9001. </p>"},{"location":"cortex/user-guides/first-start/#step-2-update-the-database","title":"Step 2: Update the Database","text":"<p>Cortex uses ElasticSearch to store users, organizations and analyzers configuration. The first time you connect to the Web UI (<code>http://&lt;CORTEX_IP&gt;:9001</code> by default), you have to create the database by clicking the <code>Update Database</code> button.</p> <p></p>"},{"location":"cortex/user-guides/first-start/#step-3-create-the-cortex-super-administrator","title":"Step 3: Create the Cortex Super Administrator","text":"<p>You are then invited to create the first user. This is a Cortex global administration user or <code>superAdmin</code>. This user account will be able to create Cortex organizations and users.</p> <p></p> <p>You will then be able to log in using this user account. You will note that the default <code>cortex</code> organization has been created and that it includes your user account, a Cortex global admininistrator.</p> <p></p>"},{"location":"cortex/user-guides/first-start/#step-4-create-an-organization","title":"Step 4: Create an Organization","text":"<p>The default <code>cortex</code> organization cannot be used for any other purpose than managing global administrators (users with the <code>superAdmin</code> role), organizations and their associated users. It cannot be used to enable/disable or configure analyzers. To do so, you need to create your own organization inside Cortex by clicking on the <code>Add organization</code>  button.</p> <p></p>"},{"location":"cortex/user-guides/first-start/#step-5-create-a-organization-administrator","title":"Step 5: Create a Organization Administrator","text":"<p>Create the organization administrator account (user with an <code>orgAdmin</code> role).</p> <p></p> <p>Then, specify a password for this user. After doing so,  log out and log in with that new user account.</p>"},{"location":"cortex/user-guides/first-start/#step-6-enable-and-configure-analyzers","title":"Step 6: Enable and Configure Analyzers","text":"<p>Enable the analyzers you need, configure them using the Organization &gt; Configuration and Organization &gt; Analyzers tabs. All analyzer configuration is done using the Web UI, including adding API keys and configuring rate limits.</p>"},{"location":"cortex/user-guides/first-start/#step-7-optional-create-an-account-for-thehive-integration","title":"Step 7 (Optional): Create an Account for TheHive integration","text":"<p>If you are using TheHive, create a new account inside your organisation with the <code>read, analyze</code> role and generate an API key that you will need to add to TheHive's configuration.</p> <p></p>"},{"location":"cortex/user-guides/roles/","title":"User Roles","text":"<p>Cortex defines four roles:</p> <ul> <li><code>read</code>: the user can access all the jobs that have been performed by the Cortex 2 instance, including their results. However, this role cannot submit jobs. Moreover, this role cannot be used in the default <code>cortex</code> organization. This organization can only contain super administrators.</li> <li><code>analyze</code>: the <code>analyze</code> role implies the <code>read</code> role, described above. A user who has a <code>analyze</code> role can submit a new job using one of the configured analyzers for their organization. This role cannot be used in the default <code>cortex</code> organization. This organization can only contain super administrators.</li> <li><code>orgAdmin</code>: the <code>orgAdmin</code> role implies the <code>analyze</code> role. A user who has an <code>analyze</code> role can manage users within their organization. They can add users and give them <code>read</code>, <code>analyze</code> and/or <code>orgAdmin</code> roles. This role also permits to configure analyzers for the organization. This role cannot be used in the default  <code>cortex</code> organization. This organization can only contain super administrators.</li> <li><code>superAdmin</code>: this role is incompatible with all the other roles listed above (see chart below for examples). It can be used solely for managing organizations and their associated users. When you install Cortex, the first user that is created will have this role. Several users can have it as well but only in the default <code>cortex</code> organization, which is automatically created during installation.</li> </ul> <p>The chart below lists the roles and what they can and cannot do:</p> Actions read analyze orgAdmin superAdmin Read reports X X X Run jobs X X Enable/Disable analyzer X Configure analyzer X Create org analyst X X Delete org analyst X X Create org admin X X Delete org admin X X Create Org X Delete Org X Create Cortex admin user X"},{"location":"resources/Keynotes/list/","title":"Additional Resources","text":"<p>The following page lists additional resources that should help you get more acquainted with TheHive, Cortex &amp; other tools.</p>"},{"location":"resources/Keynotes/list/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Presentations</li> <li>Workshops and Trainings<ul> <li>Hack.lu 2019</li> <li>Botconf 2018</li> </ul> </li> <li>User Contributions</li> </ul>"},{"location":"resources/Keynotes/list/#presentations","title":"Presentations","text":"<p>We make several presentations throughout the year during conferences and various events. Please find below some of the latest presentation material we produced:</p> <ul> <li>Cruising Ocean Threat without Sinking Using TheHive, Cortex &amp; MISP. BSidesLisbon 2018. November 29, 2018. (PDF)</li> <li>TheHive &amp; Cortex UYBHYS 2018. November 17, 2018. ( PDF)</li> <li>MISP, TheHive &amp; Cortex: better, faster, happier. MISP Summit 04. October 16, 2018. (PDF)</li> </ul>"},{"location":"resources/Keynotes/list/#workshops-and-trainings","title":"Workshops and Trainings","text":"<p>We frequently organize workshops and trainings, often with our friends from the MISP Project. We do not publish all the materials because we often leverage MISP instances containing training-specific events and Cortex servers configured with commercial analyzers that supporting partners such as DomainTools and Onyphe kindly give us access to for the duration of the workshops and trainings.</p> <p>If you'd like to attend a future workshop or training, please follow us on https://twitter.com/thehive_project or regularly visit our blog. </p> <p>However, if you'd like to do the training at your own pace, you can find below the materials used for some of the workshops and trainings we gave in the past. Please note that you might have some difficulties completing the case studies without access to the commercial analyzers highlighted above.</p>"},{"location":"resources/Keynotes/list/#hacklu-2019","title":"Hack.lu 2019","text":"<p>We gave a workshop during Hack.lu on Thu Oct 24, 2019. We prepared a MISP and Cortex instance on the cloud as well as a custom built training VM containing TheHive 3.4.0 which took advantage of those cloud instances.The VM was shared with the attendees during the workshop but will not be posted online. Indeed, the above-mentioned cloud instances were turned off after the workshop.</p> <p>That being said, you can still get a look at the slides we used to set the stage for the workshop. They contain some valuable information if you are considering installing TheHive, Cortex &amp; MISP or just beginning with the trio.</p>"},{"location":"resources/Keynotes/list/#botconf-2018","title":"Botconf 2018","text":"<p>We gave a workshop during Botconf on Tue Dec 4, 2018. If you'd like to give it a try on your own, you will need: - familiarity with TCP/IP, Linux (including editing configuration files), SSH &amp; incident response - the joint MISP, TheHive &amp; Cortex training VM (SHA256 checksum) - a powerful laptop with virtualization software (either VMware Workstation, VMware Fusion or VirtualBox) - the ability to give the training VM 6GB of RAM and 2 processor cores. If that's not possible, we consider 4GB and 1 processor core the bare minimum - the training instructions and cheatsheet - Case Study 1 - Case Study 2</p> <p>Before undertaking the workshop, we highly recommend reading the following slides in the specified order: - Threat Intelligence and Information Sharing with MISP - Detect, Investigate &amp; Respond with MISP, TheHive &amp; Cortex</p> <p>Important Note: you won't be able to do case study 3 as it requires access to the instructors' MISP instance which is only available during the workshops and trainings. You must also skip the steps which ask you to synchronize your MISP instance with the instructors' (unless you have access to an instance pre-populated with events) or configure TheHive to leverage the instructors' Cortex instance.</p>"},{"location":"resources/Keynotes/list/#user-contributions","title":"User Contributions","text":"<p>The resources below have been contributed by our user community. Please note that the fact that they are listed here does not mean that they have been checked, validated or endorsed in any way by TheHive Project. Use your own judgment if you decide to read them.</p> <ul> <li>TheHive Scripting: Task Imports, Matt B. Last accessed on March 26, 2019.</li> </ul>"},{"location":"resources/Virtual%20Machine/demo/","title":"Demo VM","text":"<p>A ready-to-use virtual machine can be downloaded at https://www.strangebee.com/tryit. This VM is prepared and updated by StrangeBee and is powered by the latest versions of:</p> <ul> <li>TheHive: Security Incident Response and Case management platform</li> <li>Cortex: Extendable Analysis, Enrichment and Response automation framework</li> </ul> <p>Warning</p> <p>The VM is built for testing purposes and is NOT RECOMMENDED for production.</p>"},{"location":"thehive/","title":"Home","text":"TheHive : Installation, operation and user guides    <p>The new version of TheHive is available! Learn more on the dedicated documentation site: https://docs.strangebee.com</p>"},{"location":"thehive/#thehive-by-strangebee","title":"TheHive  by \u00a9StrangeBee","text":"<p>The version 5 of TheHive is available! Technical documentation is hosted by StrangeBee. Learn how to download, install and configure it at https://docs.strangebee.com.</p> <p>More information available at https://www.strangebee.com. </p>"},{"location":"thehive/#thehive-4","title":"TheHive 4","text":"<p>Source Code: https://github.com/thehive-project/TheHive/</p> <p>Website: https://www.thehive-project.org</p> <p>TheHive is a scalable, open source and free Security Incident Response Platform designed to make life easier for SOCs, CSIRTs, CERTs and any information security practitioner dealing with security incidents that need to be investigated and acted upon swiftly.</p> <p>TheHive supports different methods to store data, files, and indexes according to your needs. However, even for a standalone, production server, we  strongly recommend using Apache Cassandra as a scalable and fault-tolerant database. Files and indexes storage can vary, depending on your target setup ; for standalone server, the local filesystem is suitable, while sereval options are possible in the case of a cluster configuration. </p>"},{"location":"thehive/#installation-and-configuration-guides","title":"Installation and configuration guides","text":"<p>This documentation contains step-by-step installation instructions for TheHive for different operating systems as well as corresponding binary archives. </p> <p>All aspects of the configuration are aslo detailled in a dedicated section.</p>"},{"location":"thehive/#user-guides","title":"User guides","text":"<p>TheHive supports differents roles for users. Depending on if you are an administrator of the plateform, an administrator of an organisation or an analyst you can have access and run differents actions in the plateform. </p> <p>The user guides aims at describing all major howtos for users according to their roles and permissions.</p>"},{"location":"thehive/#operations","title":"Operations","text":"<p>Discover how to migration from TheHive 3.x to TheHive 4.x with our migration guide.</p> <p>Several other operational guides are provided to the community.</p> <ul> <li>Setup HTTPS with nginx or haproxy</li> <li>Backup and restore: example on how to backup and restore data stored in Apache Cassandra</li> <li>Adding security in Apache Cassandra</li> <li>Using Fail2Ban and block unwanted connections to the plateform </li> </ul>"},{"location":"thehive/#license","title":"License","text":"<p>TheHive 4 is an open source and free software released under the AGPL (Affero General Public License). </p>"},{"location":"thehive/#updates-and-community-discussions","title":"Updates and community discussions","text":"<p>Information, news and updates are regularly posted on several communication channels:</p> <p> TheHive Project Twitter account</p> <p> TheHive Project blog</p> <p> TheHive Project Discord</p> <p> Users forum on Google Groups. Request an access:</p> <ul> <li>using a Gmail address</li> <li>or without it.</li> </ul>"},{"location":"thehive/#contributing","title":"Contributing","text":"<p>We welcome your contributions. Please feel free to fork the code, play with it, make some patches and send us pull requests using issues.</p> <p>We do have a Code of conduct. Make sure to check it out before contributing.</p>"},{"location":"thehive/#community-support","title":"Community support","text":"<p>Please open an issue on GitHub if you'd like to report a bug or request a feature. We are also available on Discord to help you out.</p> <p>If you need to contact the Project's team, send an email to support@thehive-project.org.</p> <p>Note</p> <ul> <li>If you have problems with TheHive4py, please open an issue on its dedicated repository.</li> <li>If you encounter an issue with Cortex or would like to request a Cortex-related feature, please open an issue on its dedicated GitHub repository.</li> <li>If you have troubles with a Cortex analyzer or would like to request a new one or an improvement to an existing analyzer, please open an issue on the analyzers' dedicated GitHub repository.</li> </ul>"},{"location":"thehive/#professional-support","title":"Professional support","text":"<p> TheHive is fully developped and maintained by StrangeBee. Should you need specific assistance, be aware that StrangeBee also provides professional services and support. </p>"},{"location":"thehive/code-of-conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"thehive/code-of-conduct/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"thehive/code-of-conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or   advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic   address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"thehive/code-of-conduct/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior, in compliance with the licensing terms applying to the Project developments.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. However, these actions shall respect the licensing terms of the Project Developments that will always supersede such Code of Conduct.</p>"},{"location":"thehive/code-of-conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"thehive/code-of-conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at support@thehive-project.org. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"thehive/code-of-conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at http://contributor-covenant.org/version/1/4</p> <p>This version includes a clarification to ensure that the code of conduct is in compliance with the free software licensing terms of the project.</p>"},{"location":"thehive/api/","title":"Introduction","text":""},{"location":"thehive/api/#apis","title":"APIs","text":""},{"location":"thehive/api/#administration-apis","title":"Administration APIs","text":"<ul> <li>Manage Organisations</li> <li>Manage Users</li> <li>Manage Custom fields</li> </ul>"},{"location":"thehive/api/#organisation-apis","title":"Organisation APIs","text":"<ul> <li>Manage Case Templates</li> </ul>"},{"location":"thehive/api/#case-management-apis","title":"Case Management APIs","text":"<ul> <li>Alert APIs</li> <li>Case APIs</li> <li>Task APIs</li> <li>Observable APIs</li> <li>TTP APIs</li> </ul>"},{"location":"thehive/api/#library","title":"Library","text":"<p>StrangeBee provides an official library for integrating with the remote API of TheHive: </p> <ul> <li>TheHive4py</li> </ul>"},{"location":"thehive/api/alert/","title":"Alert APIs","text":""},{"location":"thehive/api/alert/#alert-operations","title":"Alert operations","text":"<ul> <li>List alerts</li> <li>Create alert</li> <li>Delete alert</li> <li>Update alert</li> <li>Merge alert in case</li> <li>Promote alert into a case</li> <li>Mark alert as read</li> <li>Run responder on alert</li> <li>List responder jobs</li> <li>Get alerts' similar cases</li> </ul>"},{"location":"thehive/api/alert/#alert-observable-operations","title":"Alert observable operations","text":"<ul> <li>Add alert observable</li> <li>Update alert observable</li> <li>Delete alert observable</li> <li>List alert observables</li> </ul>"},{"location":"thehive/api/alert/add-observable/","title":"Add observables","text":"<p>Add Observable to an Alert.</p>"},{"location":"thehive/api/alert/add-observable/#query","title":"Query","text":"<pre><code>POST /api/alert/{id}/artifact\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Alert identifier</li> </ul>"},{"location":"thehive/api/alert/add-observable/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"dataType\":\"ip\",\n\"ioc\":True,\n\"sighted\":True,\n\"ignoreSimilarity\":False,\n\"tlp\":2,\n\"message\":\"sample description\",\n\"tags\":[\"test\",\"Another Test Tag\"],\n\"data\":[\"1.2.3.4\"]\n}\n</code></pre>"},{"location":"thehive/api/alert/add-observable/#response","title":"Response","text":""},{"location":"thehive/api/alert/add-observable/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if Alert is created successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/alert/add-observable/#responsebody-example","title":"ResponseBody Example","text":"201401403 <pre><code>[\n{\n\"_id\":\"~1564784\",\n\"id\":\"~1564784\",\n\"createdBy\":\"analyst@soc\",\n\"createdAt\":1637091448338,\n\"_type\":\"case_artifact\",\n\"dataType\":\"ip\",\n\"data\":\"1.2.3.4\",\n\"startDate\":1637091448338,\n\"tlp\":2,\n\"tags\":[\"test\",\"Another Test Tag\"],\n\"ioc\":true,\n\"sighted\":true,\n\"message\":\"sample description\",\n\"reports\":{},\n\"stats\":{},\n\"ignoreSimilarity\":false\n}\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create custom field, you haven't the permission manageCustomField\"\n}\n</code></pre>"},{"location":"thehive/api/alert/create/","title":"Create","text":"<p>Create an Alert.</p>"},{"location":"thehive/api/alert/create/#query","title":"Query","text":"<pre><code>POST /api/alert\n</code></pre>"},{"location":"thehive/api/alert/create/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"artifacts\": [],\n\"description\": \"Imported from MISP Event #1311.\",\n\"severity\": 0,\n\"source\": \"misp server\",\n\"sourceRef\": \"1311\",\n\"tags\": [\n\"tlp:white\",\n\"type:OSINT\"\n],\n\"title\": \"CISA.gov - AA21-062A Mitigate Microsoft Exchange Server Vulnerabilities\",\n\"tlp\": 0,\n\"type\": \"MISP Event\"\n}\n</code></pre> <p>The following fields are required: </p> <ul> <li><code>title</code>: (String)</li> <li><code>source</code>: (String)</li> <li><code>sourceRef</code>:  (String)</li> <li><code>type</code>:  (String)</li> </ul>"},{"location":"thehive/api/alert/create/#response","title":"Response","text":""},{"location":"thehive/api/alert/create/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if Alert is created successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/create/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>{\n\"_id\": \"~987889880\",\n\"id\": \"~987889880\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"updatedBy\": null,\n\"createdAt\": 1630323713949,\n\"updatedAt\": null,\n\"_type\": \"alert\",\n\"type\": \"misp event\",\n\"source\": \"misp server\",\n\"sourceRef\": \"1311-2\",\n\"externalLink\": null,\n\"case\": null,\n\"title\": \"CISA.gov - AA21-062A Mitigate Microsoft Exchange Server Vulnerabilities\",\n\"description\": \"Imported from MISP Event #1311.\",\n\"severity\": 0,\n\"date\": 1630323713937,\n\"tags\": [\n\"tlp:pwhite\",\n\"type:OSINT\",\n],\n\"tlp\": 0,\n\"pap\": 2,\n\"status\": \"New\",\n\"follow\": true,\n\"customFields\": {},\n\"caseTemplate\": null,\n\"artifacts\": [],\n\"similarCases\": []\n}\n</code></pre>"},{"location":"thehive/api/alert/delete-observable/","title":"Add observables","text":"<p>Delete an Observable from an Alert.</p>"},{"location":"thehive/api/alert/delete-observable/#query","title":"Query","text":"<pre><code>DELETE /api/alert/artifact/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Observable identifier</li> </ul>"},{"location":"thehive/api/alert/delete-observable/#response","title":"Response","text":""},{"location":"thehive/api/alert/delete-observable/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if Observable is deleted successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/delete/","title":"Delete","text":"<p>Delete an Alert.</p>"},{"location":"thehive/api/alert/delete/#query","title":"Query","text":"<pre><code>DELETE /api/alert/{id}?force=1\n</code></pre>"},{"location":"thehive/api/alert/delete/#response","title":"Response","text":""},{"location":"thehive/api/alert/delete/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if Alert is deleted successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/list-observables/","title":"List Observables","text":"<p>List observables of an Alerts.</p>"},{"location":"thehive/api/alert/list-observables/#query","title":"Query","text":"<pre><code>POST /api/v0/query?name\n</code></pre>"},{"location":"thehive/api/alert/list-observables/#request-body-example","title":"Request Body Example","text":"<p>List last 15 added observables:</p> <pre><code>{\n\"query\": [\n{\n\"_name\": \"getAlert\",\n\"idOrName\": \"{id}\"\n},\n{\n\"_name\": \"observables\"\n},\n{\n\"_name\": \"sort\",\n\"_fields\": [\n{\n\"startDate\": \"desc\"\n}\n]\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 15,\n\"extraData\": [\n\"seen\"\n]\n}\n]\n}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: id of the Alert</li> </ul>"},{"location":"thehive/api/alert/list-observables/#response","title":"Response","text":""},{"location":"thehive/api/alert/list-observables/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/list-observables/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>[\n...\n{\n\"_id\": \"~11111462234\",\n\"id\": \"~11111462234\",\n\"_type\": \"Observable\",\n\"_createdBy\": \"system@thehive.local\",\n\"_createdAt\": 1629309258431,\n\"dataType\": \"other\",\n\"data\": \"1.2.3.4\",\n\"startDate\": 1629309258431,\n\"tlp\": 0,\n\"ioc\": false,\n\"sighted\": false,\n\"reports\": {},\n\"stats\": {}\n}\n...\n]\n</code></pre>"},{"location":"thehive/api/alert/list-responder-jobs/","title":"List responder actions","text":"<p>List actions run on an Alert.</p>"},{"location":"thehive/api/alert/list-responder-jobs/#query","title":"Query","text":"<pre><code>GET /api/connector/cortex/action/responder/alert/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Alert identifier</li> </ul>"},{"location":"thehive/api/alert/list-responder-jobs/#response","title":"Response","text":""},{"location":"thehive/api/alert/list-responder-jobs/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/list-responder-jobs/#response-body-example","title":"Response Body Example","text":"200401 <pre><code>  [\n{\n\"responderId\": \"25dcbbb69d50dd5a5ae4bd55f4ca5903\",\n\"responderName\": \"reponderName_1_0\",\n\"responderDefinition\": \"reponderName_1_0\",\n\"cortexId\": \"local-cortex\",\n\"cortexJobId\": \"408-unsB3SwW9-eEPXXW\",\n\"objectType\": \"Alert\",\n\"objectId\": \"~25313328\",\n\"status\": \"Success\",\n\"startDate\": 1630917246993,\n\"endDate\": 1630917254406,\n\"operations\": \"[]\",\n\"report\": \"{\\\"summary\\\":{\\\"taxonomies\\\":[]},\\\"full\\\":null,\\\"success\\\":true,\\\"artifacts\\\":[],\\\"operations\\\":[],\\\\\\\"message\\\\\\\":\\\\\\\"Ok\\\\\\\",\\\\\\\"parameters\\\\\\\":{\\\\\\\"organisation\\\\\\\":\\\\\\\"StrangeBee\\\\\\\",\\\\\\\"user\\\\\\\":\\\\\\\"user@thehive.local\\\\\\\"},\\\\\\\"config\\\\\\\":{\\\\\\\"proxy_https\\\\\\\":null,\\\\\\\"cacerts\\\\\\\":null,\\\\\\\"check_tlp\\\\\\\":false,\\\\\\\"max_tlp\\\\\\\":2,\\\\\\\"check_pap\\\\\\\":false,\\\\\\\"max_pap\\\\\\\":2,\\\\\\\"jobTimeout\\\\\\\":30,\\\\\\\"proxy_http\\\\\\\":null}}\\\"}\"\n}\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/alert/list-responder-jobs/#list-available-responders","title":"List available Responders","text":""},{"location":"thehive/api/alert/list-responder-jobs/#request","title":"Request","text":"<p>To get the list of Responders available for an Alert, based on its TLP and PAP, you can call the following API:</p> <pre><code>GET /api/connector/cortex/responder/alert/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Alert identifier</li> </ul>"},{"location":"thehive/api/alert/list-responder-jobs/#response_1","title":"Response","text":"200401 <pre><code>[\n{\n\"id\": \"e33d63082066c739c07d2bbc199bfe7e\",\n\"name\": \"MALSPAM_Reply_to_user_1_0\",\n\"version\": \"1.0\",\n\"description\": \"Reply to user with an email. Applies on tasks\",\n\"dataTypeList\": [\n\"thehive:Alert\"\n],\n\"cortexIds\": [\n\"Demo\"\n]\n}\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/alert/list/","title":"List / Search","text":"<p>List Alerts.</p>"},{"location":"thehive/api/alert/list/#query","title":"Query","text":"<pre><code>POST /api/v1/query?name=alerts\n</code></pre>"},{"location":"thehive/api/alert/list/#request-body-example","title":"Request Body Example","text":"<p>List last 15 alerts:</p> <pre><code>{\n\"query\": [\n{\n\"_name\": \"listAlert\"\n},\n{\n\"_name\": \"filter\",\n\"_field\": \"imported\",\n\"_value\": false\n},\n{\n\"_name\": \"sort\",\n\"_fields\": [\n{\n\"date\": \"desc\"\n}\n]\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 15,\n\"extraData\": [\n\"importDate\",\n\"caseNumber\"\n]\n}\n]\n}\n</code></pre>"},{"location":"thehive/api/alert/list/#response","title":"Response","text":""},{"location":"thehive/api/alert/list/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/list/#responsebody-example","title":"ResponseBody Example","text":"<p>```json [   ...   {     \"_id\": \"~789196976\",     \"_type\": \"Alert\",     \"_createdBy\": \"florian@strangebee.com\",     \"_createdAt\": 1620393156944,     \"status\": \"New\",     \"type\": \"external\",     \"source\": \"MISP server\",     \"sourceRef\": \"event_1576\",     \"externalLink\": null,     \"title\": \"Phishing list update 7.5.2021\",     \"description\": \"A curated list of phishing IOCs\",     \"severity\": 2,     \"date\": 1620393156000,     \"tags\": [       \"source:MISP\",       \"origin:CIRCL_LU\"     ],     \"tlp\": 3,     \"pap\": 2,     \"read\": false,     \"follow\": true,     \"customFields\": [],     \"caseTemplate\": null,     \"artifacts\": [],     \"similarCases\": []</p> <p>}     ...     ]     ```</p>"},{"location":"thehive/api/alert/merge/","title":"Merge","text":"<p>Merge an Alert into an existing Case.</p>"},{"location":"thehive/api/alert/merge/#query","title":"Query","text":"<pre><code>POST /api/alert/{id1}/merge/{id2}\n</code></pre> <p>With:</p> <ul> <li><code>id1</code>: id of the Alert to merge</li> <li><code>id2</code>: id of the destination Case</li> </ul>"},{"location":"thehive/api/alert/merge/#response","title":"Response","text":""},{"location":"thehive/api/alert/merge/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if Alert is successfully merged</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/merge/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>{\n\"_id\": \"~6658533455\",\n\"id\": \"~6658533455\",\n\"createdBy\": \"florian@strangebee.com\",\n\"updatedBy\": \"florian@strangebee.com\",\n\"createdAt\": 1620397519028,\n\"updatedAt\": 1624373852175,\n\"_type\": \"case\",\n\"caseId\": 114,\n\"title\": \"User connected to known malicious IP over Telnet / Malicious payload detected\",\n\"description\": \"EDR automated alert: the user robb@training.org has connected to known malicious IP over Telnet\\n\\nEDR automated alert: malicious payload detected on computer PC-Robb\\n  \\n#### Merged with alert #90e044 User posted information on known phishing URL\\n\\nSIEM automated alert: the user robb@training.org has posted information on a known phishing url\",\n\"severity\": 2,\n\"startDate\": 1620396059728,\n\"endDate\": null,\n\"impactStatus\": null,\n\"resolutionStatus\": null,\n\"tags\": [\n\"log-source:proxy\",\n\"source:edr\",\n\"log-source:endpoint-protection\",\n\"source:siem\",\n\"protocol: telnet\",\n\"ex2\"\n],\n\"flag\": false,\n\"tlp\": 3,\n\"pap\": 2,\n\"status\": \"Open\",\n\"summary\": null,\n\"owner\": \"florian@strangebee.com\",\n\"customFields\": {\n\"businessUnit\": {\n\"string\": \"Finance\",\n\"order\": 0\n},\n\"location\": {\n\"string\": \"Sydney\",\n\"order\": 1\n}\n},\n\"stats\": {},\n\"permissions\": [\n\"manageShare\",\n\"manageAnalyse\",\n\"manageTask\",\n\"manageCaseTemplate\",\n\"manageCase\",\n\"manageUser\",\n\"manageProcedure\",\n\"managePage\",\n\"manageObservable\",\n\"manageTag\",\n\"manageConfig\",\n\"manageAlert\",\n\"accessTheHiveFS\",\n\"manageAction\"\n]\n}\n</code></pre>"},{"location":"thehive/api/alert/promote-as-case/","title":"Promote","text":"<p>Promote an Alert as a new Case.</p>"},{"location":"thehive/api/alert/promote-as-case/#query","title":"Query","text":"<pre><code>POST /api/alert/{id}/createCase\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: id of the Alert to promote</li> </ul>"},{"location":"thehive/api/alert/promote-as-case/#request-body-example","title":"Request Body example","text":"<p>Specify a Case template applied with Case creation:</p> <pre><code>{\n\"caseTemplate\": \"SIEM_Alert\"\n}\n</code></pre> <p>The following fields are optional: </p> <ul> <li><code>caseTemplate</code>: (String)</li> </ul>"},{"location":"thehive/api/alert/promote-as-case/#response","title":"Response","text":""},{"location":"thehive/api/alert/promote-as-case/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if Case is successfully created</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/promote-as-case/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>{\n\"_id\": \"~907709843\",\n\"id\": \"~907709843\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"updatedBy\": null,\n\"createdAt\": 1630416621805,\n\"updatedAt\": null,\n\"_type\": \"case\",\n\"caseId\": 126,\n\"title\": \"User posted information on known phishing URL\",\n\"description\": \"SIEM automated alert: the user robb@training.org has posted information on a known phishing url. \",\n\"severity\": 2,\n\"startDate\": 1630416621797,\n\"endDate\": null,\n\"impactStatus\": null,\n\"resolutionStatus\": null,\n\"tags\": [\n\"source:siem\",\n\"log-source:proxy\"\n],\n\"flag\": false,\n\"tlp\": 3,\n\"pap\": 2,\n\"status\": \"Open\",\n\"summary\": null,\n\"owner\": \"jerome@strangebee.com\",\n\"customFields\": {\n\"businessUnit\": {\n\"string\": \"Finance\",\n\"order\": 0\n},\n\"location\": {\n\"string\": \"Sydney\",\n\"order\": 1\n}\n},\n\"stats\": {},\n\"permissions\": [\n\"manageShare\",\n\"manageAnalyse\",\n\"manageTask\",\n\"manageCaseTemplate\",\n\"manageCase\",\n\"manageUser\",\n\"manageProcedure\",\n\"managePage\",\n\"manageObservable\",\n\"manageTag\",\n\"manageConfig\",\n\"manageAlert\",\n\"accessTheHiveFS\",\n\"manageAction\"\n]\n}\n</code></pre>"},{"location":"thehive/api/alert/read/","title":"Mark as Read/Unread","text":"<p>Mark an Alert as read</p>"},{"location":"thehive/api/alert/read/#query","title":"Query","text":""},{"location":"thehive/api/alert/read/#mark-as-read","title":"Mark as read","text":"<pre><code>POST /api/alert/{id}/markAsRead\n</code></pre> <p>with:</p> <ul> <li><code>id</code>: id of the Alert</li> </ul>"},{"location":"thehive/api/alert/read/#mark-as-unread","title":"Mark as unread","text":"<pre><code>POST /api/alert/{id}/markAsUnead\n</code></pre> <p>with:</p> <ul> <li><code>id</code>: id of the Alert</li> </ul>"},{"location":"thehive/api/alert/read/#response","title":"Response","text":""},{"location":"thehive/api/alert/read/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if Alert is updated successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/read/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>{\n\"_id\": \"~911601872\",\n\"id\": \"~911601872\",\n\"createdBy\": \"florian@strangebee.com\",\n\"updatedBy\": null,\n\"createdAt\": 1620333017135,\n\"updatedAt\": null,\n\"_type\": \"alert\",\n\"type\": \"external\",\n\"source\": \"SIEM\",\n\"sourceRef\": \"8257b4\",\n\"externalLink\": null,\n\"case\": null,\n\"title\": \"User posted information on known phishing URL\",\n\"description\": \"SIEM automated alert: the user robb@training.org has posted information on a known phishing url\",\n\"severity\": 2,\n\"date\": 1620333017000,\n\"tags\": [\n\"source:siem\",\n\"log-source:proxy\"\n],\n\"tlp\": 3,\n\"pap\": 2,\n\"status\": \"Ignored\",\n\"follow\": true,\n\"customFields\": {\n\"businessUnit\": {\n\"string\": \"Finance\"\n},\n\"location\": {\n\"string\": \"Sydney\"\n}\n},\n\"caseTemplate\": null,\n\"artifacts\": [\n{\n\"_id\": \"~624226312\",\n\"id\": \"~624226312\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1620333017175,\n\"_type\": \"case_artifact\",\n\"dataType\": \"mail\",\n\"data\": \"robb@training.org\",\n\"startDate\": 1620333017175,\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": false,\n\"sighted\": false,\n\"reports\": {},\n\"stats\": {}\n},\n{\n\"_id\": \"~788742360\",\n\"id\": \"~788742360\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1620333017168,\n\"_type\": \"case_artifact\",\n\"dataType\": \"url\",\n\"data\": \"https://moneyfornothing.pl-getbuys.icu/\",\n\"startDate\": 1620333017168,\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": false,\n\"sighted\": false,\n\"message\": \"http method: POST\",\n\"reports\": {},\n\"stats\": {}\n},\n{\n\"_id\": \"~870416536\",\n\"id\": \"~870416536\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1620333017157,\n\"_type\": \"case_artifact\",\n\"dataType\": \"ip\",\n\"data\": \"94.154.129.50\",\n\"startDate\": 1620333017157,\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": false,\n\"sighted\": false,\n\"reports\": {},\n\"stats\": {}\n}\n],\n\"similarCases\": []\n}\n</code></pre>"},{"location":"thehive/api/alert/run-responder/","title":"Run Responder","text":"<p>Run a Responder on an Alert.</p>"},{"location":"thehive/api/alert/run-responder/#query","title":"Query","text":"<pre><code>POST /api/connector/cortex/action\n</code></pre>"},{"location":"thehive/api/alert/run-responder/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"responderId\": \"05521ec727f75d69e828604dc5ae4c03\",\n\"objectType\": \"alert\",\n\"objectId\": \"~947478656\"\n}\n</code></pre> <p>The following fields are required: </p> <ul> <li><code>responderId</code>: (String)</li> <li><code>objectType</code>: \"alert\"</li> <li><code>objectId</code>:  (String)</li> </ul>"},{"location":"thehive/api/alert/run-responder/#response","title":"Response","text":""},{"location":"thehive/api/alert/run-responder/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if Responder is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/run-responder/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>{\n\"responderId\": \"05521ec727f75d69e828604dc5ae4bed\",\n\"responderName\": \"JIRA_Create_Ticket_1_0\",\n\"responderDefinition\": \"JIRA_Create_Ticket_1_0\",\n\"cortexId\": \"CORTEX_INTERNAL\",\n\"cortexJobId\": \"_v2EnHsB8Pn57ilsukA3\",\n\"objectType\": \"Alert\",\n\"objectId\": \"~947478656\",\n\"status\": \"Waiting\",\n\"startDate\": 1630418550145,\n\"operations\": \"[]\",\n\"report\": \"{}\"\n}\n</code></pre>"},{"location":"thehive/api/alert/similar-cases/","title":"List similar Cases","text":"<p>List similar Cases.</p>"},{"location":"thehive/api/alert/similar-cases/#query","title":"Query","text":"<pre><code>POST /api/v1/query?name=alert-similar-cases\n</code></pre>"},{"location":"thehive/api/alert/similar-cases/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"query\": [\n{\n\"_name\": \"getAlert\",\n\"idOrName\": \"{id}\"\n},\n{\n\"_name\": \"similarCases\",\n\"caseFilter\": {\n\"_field\": \"status\",\n\"_value\": \"Open\"\n}\n}\n]\n}\n</code></pre> <p>with: </p> <ul> <li><code>id</code>: id of the Alert.</li> </ul>"},{"location":"thehive/api/alert/similar-cases/#response","title":"Response","text":""},{"location":"thehive/api/alert/similar-cases/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is successful</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/similar-cases/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>[\n{\n\"case\": {\n\"_id\": \"~665851112\",\n\"_type\": \"Case\",\n\"_createdBy\": \"florian@strangebee.com\",\n\"_updatedBy\": \"florian@strangebee.com\",\n\"_createdAt\": 1620397519028,\n\"_updatedAt\": 1624373852175,\n\"number\": 114,\n\"title\": \"User connected to known malicious IP over Telnet / Malicious payload detected\",\n\"description\": \"EDR automated alert: the user robb@training.org has connected to known malicious IP over Telnet\\n\\nEDR automated alert: malicious payload detected on computer PC-Robb\",\n\"severity\": 2,\n\"startDate\": 1620396059728,\n\"tags\": [\n\"source:edr\",\n\"protocol: telnet\",\n\"log-source:endpoint-protection\"\n],\n\"flag\": false,\n\"tlp\": 3,\n\"pap\": 2,\n\"status\": \"Open\",\n\"assignee\": \"florian@strangebee.com\",\n\"customFields\": [],\n\"extraData\": {}\n},\n\"similarObservableCount\": 1,\n\"observableCount\": 6,\n\"similarIocCount\": 0,\n\"iocCount\": 0,\n\"observableTypes\": {\n\"username\": 1\n}\n},\n{\n\"case\": {\n\"_id\": \"~789202345\",\n\"_type\": \"Case\",\n\"_createdBy\": \"florian@strangebee.com\",\n\"_createdAt\": 1620393185339,\n\"number\": 111,\n\"title\": \"Phishing -User posted information on known phishing URL\",\n\"description\": \"SIEM automated alert: the user robb@training.org has posted information on a known phishing url\",\n\"severity\": 2,\n\"startDate\": 1620393185257,\n\"tags\": [\n\"source:siem\",\n\"log-source:proxy\",\n\"category:Phishing\"\n],\n\"flag\": false,\n\"tlp\": 3,\n\"pap\": 2,\n\"status\": \"Open\",\n\"assignee\": \"florian@strangebee.com\",\n\"customFields\": [],\n\"extraData\": {}\n},\n\"similarObservableCount\": 2,\n\"observableCount\": 4,\n\"similarIocCount\": 0,\n\"iocCount\": 1,\n\"observableTypes\": {\n\"username\": 1,\n\"mail\": 1\n}\n}\n]\n</code></pre>"},{"location":"thehive/api/alert/update-observable/","title":"Update observable","text":"<p>update an Alert Observable.</p>"},{"location":"thehive/api/alert/update-observable/#query","title":"Query","text":"<pre><code>PATCH /api/alert/artifact/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Alert identifier</li> </ul> <p>Updatable fields are: <code>tlp</code>, <code>ioc</code>, <code>sighted</code>, <code>tags</code>, <code>message</code>, <code>ignoreSimilarity</code></p>"},{"location":"thehive/api/alert/update-observable/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"ioc\": True,\n\"tags\":[\"malicious\"]\n}\n</code></pre>"},{"location":"thehive/api/alert/update-observable/#response","title":"Response","text":""},{"location":"thehive/api/alert/update-observable/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if Alert observable is updated successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/alert/update-observable/#responsebody-example","title":"ResponseBody Example","text":"200401403 <pre><code>{\n\"_id\":\"~1564784\",\n\"id\":\"~1564784\",\n\"createdBy\":\"analyst@soc\",\n\"updatedBy\":\"analyst@soc\",\n\"createdAt\":1637091448338,\n\"updatedAt\":1637092980667,\n\"_type\":\"case_artifact\",\n\"dataType\":\"ip\",\n\"data\":\"1.2.3.4\",\n\"startDate\":1637091448338,\n\"tlp\":2,\n\"tags\":[\"malicious\"],\n\"ioc\":true,\n\"sighted\":true,\n\"message\":\"sample description\",\n\"reports\":{},\n\"stats\":{},\n\"ignoreSimilarity\":false\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create custom field, you haven't the permission manageCustomField\"\n}\n</code></pre>"},{"location":"thehive/api/alert/update/","title":"Update","text":"<p>Update an Alert.</p>"},{"location":"thehive/api/alert/update/#query","title":"Query","text":"<pre><code>PATCH /api/alert/{id}\n</code></pre> <p>with:</p> <ul> <li><code>id</code>: id of the Alert</li> </ul>"},{"location":"thehive/api/alert/update/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"description\": \"SIEM automated alert: the user robb@training.org has posted information on a known phishing url. \"\n}\n</code></pre>"},{"location":"thehive/api/alert/update/#response","title":"Response","text":""},{"location":"thehive/api/alert/update/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if Alert is updated successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/alert/update/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>  {\n\"_id\": \"~624443400\",\n\"id\": \"~624443400\",\n\"createdBy\": \"florian@strangebee.com\",\n\"updatedBy\": null,\n\"createdAt\": 1620373264377,\n\"updatedAt\": null,\n\"_type\": \"alert\",\n\"type\": \"external\",\n\"source\": \"SIEM\",\n\"sourceRef\": \"47e379\",\n\"externalLink\": null,\n\"case\": null,\n\"title\": \"User posted information on known phishing URL\",\n\"description\": \"SIEM automated alert: the user robb@training.org has posted information on a known phishing url. \",\n\"severity\": 2,\n\"date\": 1620373264000,\n\"tags\": [\n\"source:siem\",\n\"log-source:proxy\"\n],\n\"tlp\": 3,\n\"pap\": 2,\n\"status\": \"Ignored\",\n\"follow\": true,\n\"customFields\": {\n\"businessUnit\": {\n\"string\": \"Finance\"\n},\n\"location\": {\n\"string\": \"Sydney\"\n}\n},\n\"caseTemplate\": null,\n\"artifacts\": [\n{\n\"_id\": \"~665772152\",\n\"id\": \"~665772152\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1620373264410,\n\"_type\": \"case_artifact\",\n\"dataType\": \"username\",\n\"data\": \"robb@training.org\",\n\"startDate\": 1620373264410,\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": false,\n\"sighted\": false,\n\"reports\": {},\n\"stats\": {}\n},\n{\n\"_id\": \"~677015568\",\n\"id\": \"~677015568\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1620373264398,\n\"_type\": \"case_artifact\",\n\"dataType\": \"domain\",\n\"data\": \"pl-getbuys.icu\",\n\"startDate\": 1620373264398,\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": false,\n\"sighted\": false,\n\"reports\": {},\n\"stats\": {}\n},\n{\n\"_id\": \"~677019664\",\n\"id\": \"~677019664\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1620373264405,\n\"_type\": \"case_artifact\",\n\"dataType\": \"mail\",\n\"data\": \"robb@training.org\",\n\"startDate\": 1620373264405,\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": false,\n\"sighted\": false,\n\"reports\": {},\n\"stats\": {}\n},\n{\n\"_id\": \"~706650224\",\n\"id\": \"~706650224\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1620373264391,\n\"_type\": \"case_artifact\",\n\"dataType\": \"url\",\n\"data\": \"https://poczta.pl-getbuys.icu/\",\n\"startDate\": 1620373264391,\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": false,\n\"sighted\": false,\n\"message\": \"http method: POST\",\n\"reports\": {},\n\"stats\": {}\n}\n],\n\"similarCases\": []\n}\n</code></pre>"},{"location":"thehive/api/case/","title":"Case APIs","text":"<ul> <li>Create case</li> <li>Update case</li> <li>Delete case</li> <li>Merge cases</li> <li>Export case to MISP</li> <li>List related case</li> <li>List related alerts</li> <li>List attachments</li> <li>Run responder</li> <li>List responder jobs</li> </ul>"},{"location":"thehive/api/case/attachments/","title":"List related Alerts","text":"<p>List attachments added to task logs of a Case.</p>"},{"location":"thehive/api/case/attachments/#query","title":"Query","text":"<pre><code>POST /api/v0/query\n</code></pre>"},{"location":"thehive/api/case/attachments/#request-body-example","title":"Request Body Example","text":"<p>List attachments added to task logs or a Case identified by <code>{id}</code>:</p> <pre><code>  {\n\"query\": [\n{\n\"_name\": \"getCase\",\n\"idOrName\": \"{id}\"\n},\n{\n\"_name\": \"tasks\"\n},\n{\n\"_name\": \"filter\",\n\"_ne\": {\n\"_field\": \"status\",\n\"_value\": \"Cancel\"\n}\n},\n{\n\"_name\": \"logs\"\n},\n{\n\"_contains\": \"attachment.id\",\n\"_name\": \"filter\"\n},\n{\n\"_name\": \"page\",\n\"extraData\": [\n\"taskId\"\n],\n\"from\": 0,\n\"to\": 100\n}\n]\n}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: id of the Case</li> </ul>"},{"location":"thehive/api/case/attachments/#response","title":"Response","text":""},{"location":"thehive/api/case/attachments/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> <li><code>404</code>: if the Case is not found</li> </ul>"},{"location":"thehive/api/case/attachments/#response-body-example","title":"Response Body Example","text":"<pre><code>  [\n...\n{\n\"_id\": \"~122892472\",\n\"id\": \"~122892472\",\n\"createdBy\": \"user@thehive.local\",\n\"createdAt\": 1632124353194,\n\"_type\": \"case_task_log\",\n\"message\": \"message\",\n\"startDate\": 1632124353194,\n\"attachment\": {\n\"name\": \"filename.png\",\n\"hashes\": [\n\"0b62003cb73578d9e738a70aa7a81e89d3683282ac393856a96ef364cd1038cb\",\n\"caa75ff1e33ee8bfba764c9a6139fb72e7f4e20a\",\n\"a3e41c32ff817fc759bafeb1a106a433\"\n],\n\"size\": 42213,\n\"contentType\": \"image/png\",\n\"id\": \"0b62003cb73578d9e738a70aa7a81e89d3683282ac393856a96ef364cd1038cb\"\n},\n\"status\": \"Ok\",\n\"owner\": \"user@thehive.local\"\n}\n...\n]\n</code></pre>"},{"location":"thehive/api/case/create/","title":"Create","text":"<p>Create a Case</p>"},{"location":"thehive/api/case/create/#query","title":"Query","text":"<pre><code>POST /api/case\n</code></pre> <p>With mandatory fields:</p> <ul> <li><code>title</code>: (String) title of the Case</li> <li><code>description</code>: (String) description of the Case</li> </ul>"},{"location":"thehive/api/case/create/#request-body-example","title":"Request Body Example","text":""},{"location":"thehive/api/case/create/#basic-request","title":"Basic request","text":"<pre><code>{\n\"title\": \"my first case\",\n\"description\": \"my first case description\"\n}\n</code></pre>"},{"location":"thehive/api/case/create/#request-with-more-details-customfields-and-tasks","title":"Request with more details, customFields and tasks","text":"<pre><code>{\n\"title\": \"my first case\",\n\"description\": \"my first case description\",\n\"Severity\": 3,\n\"tlp\": 2,\n\"pap\": 2,\n\"startDate\": 1635876967233,\n\"tags\": [\"Test Tag\", \"Another Test Tag\"],\n\"flag\": false,\n\"owner\": \"username@org\",\n\"tasks\": [{\n\"title\": \"mytask\",\n\"description\": \"description of my task\"\n}],\n\"customFields\":{\n\"cvss\": {\n\"integer\": 9\n},\n\"businessUnit\": {\n\"string\": \"Sales\"\n}\n}\n}\n</code></pre>"},{"location":"thehive/api/case/create/#response","title":"Response","text":""},{"location":"thehive/api/case/create/#status-code","title":"Status code","text":"<ul> <li><code>201</code>: if Case is created successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/case/create/#response-body-example","title":"Response Body Example","text":"201401403 <pre><code>{\n\"_id\":\"~41644112\",\n\"id\":\"~41644112\",\n\"createdBy\":\"user@org\",\n\"updatedBy\":null,\n\"createdAt\":1635876967235,\n\"updatedAt\":null,\n\"_type\":\"case\",\n\"caseId\":4,\n\"title\":\"my first case\",\n\"description\":\"my first case description\",\n\"severity\":2,\n\"startDate\":1635876967233,\n\"endDate\":null,\n\"impactStatus\":null,\n\"resolutionStatus\":null,\n\"tags\":[],\n\"flag\":false,\n\"tlp\":2,\n\"pap\":2,\n\"status\":\"Open\",\n\"summary\":null,\n\"owner\":\"user@org\",\n\"customFields\":{},\n\"stats\":{},\n\"permissions\":[\"manageShare\",\"manageAnalyse\",\"manageTask\",\"manageCaseTemplate\",\"manageCase\",\"manageUser\",\"manageProcedure\",\"managePage\",\"manageObservable\",\"manageTag\",\"manageConfig\",\"manageAlert\",\"accessTheHiveFS\",\"manageAction\"]\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create custom field, you haven't the permission manageCustomField\"\n}\n</code></pre>"},{"location":"thehive/api/case/delete/","title":"Delete","text":"<p>Permanently delete a Case.</p>"},{"location":"thehive/api/case/delete/#query","title":"Query","text":"<pre><code>DELETE /api/case/{id}?force=1\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: id of the Case</li> </ul>"},{"location":"thehive/api/case/delete/#response","title":"Response","text":""},{"location":"thehive/api/case/delete/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if Case is deleted successfully</li> <li><code>401</code>: Authentication error</li> <li><code>404</code>: if Case is not found</li> </ul>"},{"location":"thehive/api/case/export/","title":"Export Case to MISP","text":"<p>Export Case to a MISP server to create an event including the Case observables marked as IOC.</p>"},{"location":"thehive/api/case/export/#query","title":"Query","text":"<pre><code>POST /api/connector/misp/export/{id}/{misp-server}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: id of the Case</li> <li><code>misp-server</code>: name of the MISP server as defined in the configuration</li> </ul> <p>Note</p> <p>Only MISP servers with <code>purpose</code> equals to <code>ExportOnly</code> or <code>ImportAndExport</code> can recieve Case exports</p>"},{"location":"thehive/api/case/export/#response","title":"Response","text":""},{"location":"thehive/api/case/export/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if Case is successfully exported</li> <li><code>401</code>: Authentication error</li> <li><code>404</code>: if Case or MISP server is not found.</li> </ul>"},{"location":"thehive/api/case/merge/","title":"Merge","text":"<p>Merge two Cases in a single Case. This APIs permanently removes the source Cases and creates a Case by merging all the data from the sources.</p>"},{"location":"thehive/api/case/merge/#query","title":"Query","text":"<pre><code>POST /api/v0/case/{id1}/_merge/{id2}\n</code></pre> <p>with:</p> <ul> <li><code>id1</code>: id of the first Case</li> <li><code>id2</code>: id of the second Case</li> </ul>"},{"location":"thehive/api/case/merge/#response","title":"Response","text":""},{"location":"thehive/api/case/merge/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if the Cases are merged successfully</li> <li><code>401</code>: Authentication error</li> <li><code>404</code>: if at least one of the Cases is not found</li> </ul>"},{"location":"thehive/api/case/merge/#response-body-example","title":"Response Body Example","text":"<pre><code>  {\n\"_id\": \"~81928240\",\n\"id\": \"~81928240\",\n\"createdBy\": \"user@thehive.local\",\n\"updatedBy\": null,\n\"createdAt\": 1632132365250,\n\"updatedAt\": null,\n\"_type\": \"case\",\n\"caseId\": 87,\n\"title\": \"Case 1 / Case 2\",\n\"description\": \"test\\n\\ntest\",\n\"severity\": 2,\n\"startDate\": 1632124020000,\n\"endDate\": null,\n\"impactStatus\": null,\n\"resolutionStatus\": null,\n\"tags\": [],\n\"flag\": false,\n\"tlp\": 2,\n\"pap\": 2,\n\"status\": \"Open\",\n\"summary\": null,\n\"owner\": \"user@thehive.local\",\n\"customFields\": {},\n\"stats\": {},\n\"permissions\": [\n\"manageShare\",\n\"manageAnalyse\",\n\"manageTask\",\n\"manageCaseTemplate\",\n\"manageCase\",\n\"manageUser\",\n\"manageProcedure\",\n\"managePage\",\n\"manageObservable\",\n\"manageTag\",\n\"manageConfig\",\n\"manageAlert\",\n\"accessTheHiveFS\",\n\"manageAction\"\n]\n}\n</code></pre>"},{"location":"thehive/api/case/related-alerts/","title":"List related Alerts","text":"<p>List alerts merged in a Case.</p>"},{"location":"thehive/api/case/related-alerts/#query","title":"Query","text":"<pre><code>POST /api/v0/query\n</code></pre>"},{"location":"thehive/api/case/related-alerts/#request-body-example","title":"Request Body Example","text":"<p>List last 5 merged alerts in a Case identified by <code>{id}</code>:</p> <pre><code>{\n\"query\": [\n{\n\"_name\": \"getCase\",\n\"idOrName\": \"{id}\"\n},\n{\n\"_name\": \"alerts\"\n},\n{\n\"_name\": \"sort\",\n\"_fields\": [\n{\n\"startDate\": \"desc\"\n}\n]\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 5\n}\n]\n}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: id of the Case</li> </ul>"},{"location":"thehive/api/case/related-alerts/#response","title":"Response","text":""},{"location":"thehive/api/case/related-alerts/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/case/related-alerts/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>[\n...\n[\n{\n\"_id\": \"~43618512\",\n\"id\": \"~43618512\",\n\"createdBy\": \"demo@thehive.local\",\n\"updatedBy\": null,\n\"createdAt\": 1618344277475,\n\"updatedAt\": null,\n\"_type\": \"alert\",\n\"type\": \"testing\",\n\"source\": \"create-alert.py\",\n\"sourceRef\": \"85a766ec\",\n\"externalLink\": null,\n\"case\": \"~122884120\",\n\"title\": \"Alert 85a766ec-060a-49a0-bc82-c672b6e51e6c\",\n\"description\": \"N/A\",\n\"severity\": 1,\n\"date\": 1618344277000,\n\"tags\": [\n\"sample\"\n],\n\"tlp\": 3,\n\"pap\": 2,\n\"status\": \"Imported\",\n\"follow\": true,\n\"customFields\": {\n\"company\": {\n\"string\": \"Customer 1\"\n}\n},\n\"caseTemplate\": null,\n\"artifacts\": [],\n\"similarCases\": []\n}\n]\n...\n]\n</code></pre>"},{"location":"thehive/api/case/related-cases/","title":"List related Cases","text":"<p>List similar Cases of a given Case. This API uses observable based similarity to find related Cases</p>"},{"location":"thehive/api/case/related-cases/#query","title":"Query","text":"<pre><code>GET /api/case/{id}/links\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: id of the Case</li> </ul>"},{"location":"thehive/api/case/related-cases/#response","title":"Response","text":""},{"location":"thehive/api/case/related-cases/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> <li><code>404</code>: if the case doesn't exist</li> </ul>"},{"location":"thehive/api/case/related-cases/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>  [\n{\n\"_id\": \"~48144448\",\n\"_type\": \"case\",\n\"caseId\": 66,\n\"createdAt\": 1618344529302,\n\"createdBy\": \"user@thehive.local\",\n\"customFields\": {},\n\"description\": \"N/A\",\n\"endDate\": null,\n\"flag\": false,\n\"id\": \"~48144448\",\n\"impactStatus\": null,\n\"linkedWith\": [\n{\n\"_id\": \"~122888216\",\n\"_type\": \"case_artifact\",\n\"createdAt\": 1632114988895,\n\"createdBy\": \"user@strangebee.com\",\n\"data\": \"google.com\",\n\"dataType\": \"domain\",\n\"id\": \"~122888216\",\n\"ignoreSimilarity\": false,\n\"ioc\": false,\n\"message\": \"test\",\n\"reports\": {},\n\"sighted\": false,\n\"startDate\": 1632114988895,\n\"stats\": {},\n\"tags\": [],\n\"tlp\": 2\n}\n],\n\"linksCount\": 1,\n\"owner\": \"nabil@thehive.local\",\n\"pap\": 1,\n\"permissions\": [\n\"manageShare\",\n\"manageAnalyse\",\n\"manageTask\",\n\"manageCaseTemplate\",\n\"manageCase\",\n\"manageUser\",\n\"manageProcedure\",\n\"managePage\",\n\"manageObservable\",\n\"manageTag\",\n\"manageConfig\",\n\"manageAlert\",\n\"accessTheHiveFS\",\n\"manageAction\"\n],\n\"resolutionStatus\": null,\n\"severity\": 4,\n\"startDate\": 1618344529000,\n\"stats\": {},\n\"status\": \"Open\",\n\"summary\": null,\n\"tags\": [\n\"sample\"\n],\n\"title\": \"Case a31acfad-8368-4395-bf1d-6d5c1675c0ba\",\n\"tlp\": 1,\n\"updatedAt\": null,\n\"updatedBy\": null\n}\n]\n</code></pre>"},{"location":"thehive/api/case/responder-jobs/","title":"List responder actions","text":"<p>List actions run on a Case.</p>"},{"location":"thehive/api/case/responder-jobs/#query","title":"Query","text":"<pre><code>GET /api/connector/cortex/action/case/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Case identifier</li> </ul>"},{"location":"thehive/api/case/responder-jobs/#response","title":"Response","text":""},{"location":"thehive/api/case/responder-jobs/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/case/responder-jobs/#response-body-example","title":"Response Body Example","text":"200401 <pre><code>  [\n{\n\"responderId\": \"25dcbbb69d50dd5a5ae4bd55f4ca5903\",\n\"responderName\": \"reponderName_1_0\",\n\"responderDefinition\": \"reponderName_1_0\",\n\"cortexId\": \"local-cortex\",\n\"cortexJobId\": \"408-unsB3SwW9-eEPXXW\",\n\"objectType\": \"Case\",\n\"objectId\": \"~25313328\",\n\"status\": \"Success\",\n\"startDate\": 1630917246993,\n\"endDate\": 1630917254406,\n\"operations\": \"[]\",\n\"report\": \"{\\\"summary\\\":{\\\"taxonomies\\\":[]},\\\"full\\\":null,\\\"success\\\":true,\\\"artifacts\\\":[],\\\"operations\\\":[],\\\\\\\"message\\\\\\\":\\\\\\\"Ok\\\\\\\",\\\\\\\"parameters\\\\\\\":{\\\\\\\"organisation\\\\\\\":\\\\\\\"StrangeBee\\\\\\\",\\\\\\\"user\\\\\\\":\\\\\\\"user@thehive.local\\\\\\\"},\\\\\\\"config\\\\\\\":{\\\\\\\"proxy_https\\\\\\\":null,\\\\\\\"cacerts\\\\\\\":null,\\\\\\\"check_tlp\\\\\\\":false,\\\\\\\"max_tlp\\\\\\\":2,\\\\\\\"check_pap\\\\\\\":false,\\\\\\\"max_pap\\\\\\\":2,\\\\\\\"jobTimeout\\\\\\\":30,\\\\\\\"proxy_http\\\\\\\":null}}\\\"}\"\n}\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/case/responder-jobs/#list-available-responders","title":"List available Responders","text":""},{"location":"thehive/api/case/responder-jobs/#request","title":"Request","text":"<p>To get the list of Responders available for a Case, based on its TLP and PAP, you can call the following API:</p> <pre><code>GET /api/connector/cortex/responder/case/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Case identifier</li> </ul>"},{"location":"thehive/api/case/responder-jobs/#response_1","title":"Response","text":"200401 <pre><code>[\n{\n\"id\": \"e33d63082066c739c07d2bbc199bfe7e\",\n\"name\": \"MALSPAM_Reply_to_user_1_0\",\n\"version\": \"1.0\",\n\"description\": \"Reply to user with an email. Applies on tasks\",\n\"dataTypeList\": [\n\"thehive:case\",\n\"thehive:case_task\",\n\"thehive:case_task_log\"\n],\n\"cortexIds\": [\n\"Demo\"\n]\n}\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/case/run-responder/","title":"Run responder","text":"<p>Run a responder on a Case (requires <code>manageAction</code> permission).</p>"},{"location":"thehive/api/case/run-responder/#query","title":"Query","text":"<pre><code>POST /api/connector/cortex/action\n</code></pre>"},{"location":"thehive/api/case/run-responder/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"responderId\": \"25dcbbb69d50dd5a5ae4bd55f4ca5903\",\n\"cortexId\": \"local-cortex\",\n\"objectType\": \"case\",\n\"objectId\": \"{id}\"\n}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Case identifier</li> </ul> <p>The required fields are <code>responderId</code>, <code>objectType</code> and <code>objectId</code>.</p>"},{"location":"thehive/api/case/run-responder/#response","title":"Response","text":""},{"location":"thehive/api/case/run-responder/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if responder is started successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> <li><code>404</code>: Case is not found</li> </ul>"},{"location":"thehive/api/case/run-responder/#response-body-example","title":"Response Body Example","text":"201401404 <pre><code>  {\n\"responderId\": \"25dcbbb69d50dd5a5ae4bd55f4ca5903\",\n\"responderName\": \"reponderName_1_0\",\n\"responderDefinition\": \"reponderName_1_0\",\n\"cortexId\": \"local-cortex\",\n\"cortexJobId\": \"408-unsB3SwW9-eEPXXW\",\n\"objectType\": \"Case\",\n\"objectId\": \"~25313328\",\n\"status\": \"Waiting\",\n\"startDate\": 1630917246993,\n\"operations\": \"[]\",\n\"report\": \"{}\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Task not found\"\n}\n</code></pre>"},{"location":"thehive/api/case/update/","title":"Update","text":"<p>Update a Case</p>"},{"location":"thehive/api/case/update/#query","title":"Query","text":"<pre><code>PATCH /api/case/{id}\n</code></pre>"},{"location":"thehive/api/case/update/#request-body-example","title":"Request Body Example","text":""},{"location":"thehive/api/case/update/#case-details-update","title":"Case details update","text":"<pre><code>{\n\"severity\":3,\n\"tags\": [\"updated\"]\n}\n</code></pre>"},{"location":"thehive/api/case/update/#case-customfields-update","title":"Case customFields update","text":"<p>To update specific customFields:</p> <pre><code>{\n\"customFields.business-unit.string\": \"VIP\",\n\"customFields.cvss.integer\": 3\n}\n</code></pre> <p>To patch Case customFields:</p> <pre><code>  \"customFields\": {\n\"business-unit\": {\n\"string\": \"VIP\"\n}\n}\n</code></pre> <p>Danger</p> <p>Case customFields not mentionned in this request will be erased.</p>"},{"location":"thehive/api/case/update/#response","title":"Response","text":""},{"location":"thehive/api/case/update/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: Case has been updated successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/case/update/#response-body-example","title":"Response Body Example","text":"201401403 <pre><code>{\n\"_id\":\"~311352\",\n\"id\":\"~311352\",\n\"createdBy\":\"analyst@soc\",\n\"updatedBy\":\"analyst@soc\",\n\"createdAt\":1635879111239,\n\"updatedAt\":1637083041511,\n\"_type\":\"case\",\n\"caseId\":6,\n\"title\":\"my first case\",\n\"description\":\"my first case description\",\n\"severity\":3,\n\"startDate\":1635876967233,\n\"endDate\":null,\n\"impactStatus\":null,\n\"resolutionStatus\":null,\n\"tags\":[\"updated\"],\n\"flag\":false,\n\"tlp\":2,\n\"pap\":2,\n\"status\":\"Open\",\n\"summary\":null,\n\"owner\":\"analyst@soc\",\n\"customFields\":{\n\"business-unit\":{\n\"string\":\"Sales\",\n\"order\":1\n},\n\"cvss\":{\n\"integer\":9,\n\"order\":0\n}\n},\n\"stats\":{},\n\"permissions\":[\"manageShare\",\"manageAnalyse\",\"manageTask\",\"manageCaseTemplate\",\"manageCase\",\"manageUser\",\"manageProcedure\",\"managePage\",\"manageObservable\",\"manageTag\",\"manageConfig\",\"manageAlert\",\"accessTheHiveFS\",\"manageAction\"]\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create custom field, you haven't the permission manageCustomField\"\n}\n</code></pre>"},{"location":"thehive/api/case-template/","title":"Case template APIs","text":"<ul> <li>List case templates</li> <li>Create case template</li> <li>Delete case template</li> <li>Update case template</li> </ul>"},{"location":"thehive/api/case-template/create/","title":"Create","text":"<p>Create a Case Templates.</p>"},{"location":"thehive/api/case-template/create/#query","title":"Query","text":"<pre><code>POST /api/case/template\n</code></pre>"},{"location":"thehive/api/case-template/create/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"name\": \"MISPEvent\",\n\"titlePrefix\": \"\",\n\"severity\": 2,\n\"tlp\": 2,\n\"pap\": 2,\n\"tags\": [\n\"hunting\"\n],\n\"tasks\": [\n{\n\"order\": 0,\n\"title\": \"Search for IOCs on Mail gateway logs\",\n\"group\": \"default\",\n\"description\": \"Run queries in Mail gateway logs and look for IOcs of type IP, email addresses, hostnames, free text. \"\n},\n{\n\"order\": 1,\n\"title\": \"Search for IOCs on Firewall logs\",\n\"group\": \"default\",\n\"description\": \"Run queries in firewall logs and look for IOcs of type IP, port\"\n},\n{\n\"order\": 2,\n\"title\": \"Search for IOCs on Web proxy logs\",\n\"group\": \"default\",\n\"description\": \"Run queries in web proxy logs and look for IOcs of type IP, domain, hostname, user-agent\"\n}\n],\n\"customFields\": {\n\"hits\": {\n\"integer\": null,\n\"order\": 1\n}\n},\n\"description\": \"Check if IOCs shared by the community have been seen on the network\",\n\"displayName\": \"MISP\"\n}\n</code></pre> <p><code>name</code> should be unique. Otherwise an error <code>400 Bad Request</code> is returned</p>"},{"location":"thehive/api/case-template/create/#response","title":"Response","text":""},{"location":"thehive/api/case-template/create/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if template was created successfully</li> <li><code>400</code>: in case of error in input</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/case-template/create/#responsebody-example","title":"ResponseBody Example","text":"201400401 <pre><code>{\n\"_id\": \"~910319824\",\n\"id\": \"~910319824\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1630675267739,\n\"_type\": \"caseTemplate\",\n\"name\": \"MISPEvent\",\n\"displayName\": \"MISP\",\n\"titlePrefix\": \"[MISP]\",\n\"description\": \"Check if IOCs shared by the community have been seen on the network\",\n\"severity\": 2,\n\"tags\": [\n\"hunting\"\n],\n\"flag\": false,\n\"tlp\": 2,\n\"pap\": 2,\n\"tasks\": [\n{\n\"id\": \"~122896536\",\n\"_id\": \"~122896536\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1630675267741,\n\"_type\": \"case_task\",\n\"title\": \"Search for IOCs on Mail gateway logs\",\n\"group\": \"default\",\n\"description\": \"Run queries in Mail gateway logs and look for IOcs of type IP, email addresses, hostnames, free text. \",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 0\n},\n{\n\"id\": \"~81932320\",\n\"_id\": \"~81932320\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1630675267743,\n\"_type\": \"case_task\",\n\"title\": \"Search for IOCs on Firewall logs\",\n\"group\": \"default\",\n\"description\": \"Run queries in firewall logs and look for IOcs of type IP, port\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 1\n},\n{\n\"id\": \"~81928376\",\n\"_id\": \"~81928376\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1630675267750,\n\"_type\": \"case_task\",\n\"title\": \"Search for IOCs on Web proxy logs\",\n\"group\": \"default\",\n\"description\": \"Run queries in web proxy logs and look for IOcs of type IP, domain, hostname, user-agent\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 2\n}\n],\n\"status\": \"Ok\",\n\"customFields\": {\n\"hits\": {\n\"integer\": null,\n\"order\": 1,\n\"_id\": \"~122900632\"\n}\n},\n\"metrics\": {}\n}\n</code></pre> <pre><code>{\n\"type\": \"CreateError\",\n\"message\": \"The case template \\\"MISPEvent\\\" already exists\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/case-template/delete/","title":"Delete","text":"<p>Delete a Case Template by its id.</p>"},{"location":"thehive/api/case-template/delete/#query","title":"Query","text":"<pre><code>DELETE /api/case/template/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Case template identifier</li> </ul>"},{"location":"thehive/api/case-template/delete/#response","title":"Response","text":""},{"location":"thehive/api/case-template/delete/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if Case Template is deleted successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> <li><code>404</code>: Case template does not exists (or was already deleted)</li> </ul>"},{"location":"thehive/api/case-template/list/","title":"Get / List","text":"<p>List Case Templates of a given organisation.</p>"},{"location":"thehive/api/case-template/list/#query","title":"Query","text":"<pre><code>POST /api/v1/query\n</code></pre>"},{"location":"thehive/api/case-template/list/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"query\": [\n{\n\"_name\": \"getOrganisation\",\n\"idOrName\": \"{id}\"\n},\n{\n\"_name\": \"caseTemplates\"\n},\n{\n\"_name\": \"sort\",\n\"_fields\": [\n{\n\"displayName\": \"asc\"\n}\n]\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 15\n}\n]\n}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Organisation identifier of Name</li> </ul>"},{"location":"thehive/api/case-template/list/#response","title":"Response","text":""},{"location":"thehive/api/case-template/list/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/case-template/list/#responsebody-example","title":"ResponseBody Example","text":"200401403 <pre><code>[\n...\n{\n\"_id\": \"~910319824\",\n\"_type\": \"CaseTemplate\",\n\"_createdBy\": \"florian@strangebee.com\",\n\"_updatedBy\": \"florian@strangebee.com\",\n\"_createdAt\": 1620297081745,\n\"_updatedAt\": 1620389292177,\n\"name\": \"Phishing\",\n\"displayName\": \"Phishing\",\n\"titlePrefix\": \"Phishing -\",\n\"description\": \"Phishing attempt has succeed.\",\n\"severity\": 2,\n\"tags\": [\n\"category:Phishing\"\n],\n\"flag\": false,\n\"tlp\": 2,\n\"pap\": 2,\n\"customFields\": [],\n\"tasks\": [\n{\n\"_id\": \"~677056528\",\n\"_type\": \"Task\",\n\"_createdBy\": \"florian@strangebee.com\",\n\"_createdAt\": 1620389292172,\n\"title\": \"Initial alert\",\n\"group\": \"default\",\n\"description\": \"-What happened?\\n-When does it happened?\\n-How did it happened?\\n-How did we detected the anomaly/alert/incident?\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 0,\n\"extraData\": {}\n},\n{\n\"_id\": \"~677060624\",\n\"_type\": \"Task\",\n\"_createdBy\": \"florian@strangebee.com\",\n\"_createdAt\": 1620389292173,\n\"title\": \"Remediation\",\n\"group\": \"default\",\n\"description\": \"Explain here all the actions performed to contain and remediate the threat.\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 3,\n\"extraData\": {}\n},\n{\n\"_id\": \"~677064720\",\n\"_type\": \"Task\",\n\"_createdBy\": \"florian@strangebee.com\",\n\"_createdAt\": 1620389292174,\n\"title\": \"Lessons learnt\",\n\"group\": \"default\",\n\"description\": \"Write here the lessons learnt for the case.\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 4,\n\"extraData\": {}\n},\n{\n\"_id\": \"~706662512\",\n\"_type\": \"Task\",\n\"_createdBy\": \"florian@strangebee.com\",\n\"_createdAt\": 1620389292171,\n\"title\": \"Notification / Communication\",\n\"group\": \"default\",\n\"description\": \"Write here all the communications related to this case\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 2,\n\"extraData\": {}\n},\n{\n\"_id\": \"~789033176\",\n\"_type\": \"Task\",\n\"_createdBy\": \"florian@strangebee.com\",\n\"_createdAt\": 1620389292174,\n\"title\": \"Analysis\",\n\"group\": \"default\",\n\"description\": \"-Technical analysis of the incident\\n-Current impact\\n-Potential damages due to the incident\\n-...\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 1,\n\"extraData\": {}\n}\n]\n}\n...\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create custom field, you haven't the permission manageCustomField\"\n}\n</code></pre>"},{"location":"thehive/api/case-template/update/","title":"Update","text":"<p>Update a Case Template by its id.</p>"},{"location":"thehive/api/case-template/update/#query","title":"Query","text":"<pre><code>PATCH /api/case/template/{id}\n</code></pre>"},{"location":"thehive/api/case-template/update/#request-body-example","title":"Request Body Example","text":"<p>Example</p> <pre><code>{\n\"displayName\": \"New Display name\",\n\"tlp\": 4,\n\"tasks\": [\n{\n\"order\": 0,\n\"title\": \"Search for IOCs on Mail gateway logs\",\n\"group\": \"default\",\n\"description\": \"Run queries in Mail gateway logs and look for IOcs of type IP, email addresses, hostnames, free text. \"\n}\n]\n}\n</code></pre> <p>Fields that can be updated:</p> <ul> <li><code>name</code></li> <li><code>displayName</code></li> <li><code>titlePrefix</code></li> <li><code>description</code></li> <li><code>severity</code></li> <li><code>tags</code></li> <li><code>flag</code></li> <li><code>tlp</code></li> <li><code>pap</code></li> <li><code>summary</code></li> <li><code>customFields</code></li> <li><code>tasks</code></li> </ul>"},{"location":"thehive/api/case-template/update/#responsebody-example","title":"ResponseBody Example","text":"<p>Example</p> <pre><code>{\n\"_id\": \"~910319824\",\n\"id\": \"~910319824\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1630675267739,\n\"_type\": \"caseTemplate\",\n\"name\": \"MISPEvent\",\n\"displayName\": \"New Display name\",\n\"titlePrefix\": \"[MISP]\",\n\"description\": \"Check if IOCs shared by the community have been seen on the network\",\n\"severity\": 2,\n\"tags\": [\n\"hunting\"\n],\n\"flag\": false,\n\"tlp\": 2,\n\"pap\": 2,\n\"tasks\": [\n{\n\"id\": \"~122896536\",\n\"_id\": \"~122896536\",\n\"createdBy\": \"florian@strangebee.com\",\n\"createdAt\": 1630675267741,\n\"_type\": \"case_task\",\n\"title\": \"Search for IOCs on Mail gateway logs\",\n\"group\": \"default\",\n\"description\": \"Run queries in Mail gateway logs and look for IOcs of type IP, email addresses, hostnames, free text. \",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 0\n}\n],\n\"status\": \"Ok\",\n\"customFields\": {\n\"hits\": {\n\"integer\": null,\n\"order\": 1,\n\"_id\": \"~122900632\"\n}\n},\n\"metrics\": {}\n}\n</code></pre>"},{"location":"thehive/api/custom-field/","title":"Custom Field APIs","text":"<ul> <li>List custom fields</li> <li>Create a custom field</li> <li>Update custom field</li> <li>Delete a custom field</li> <li>Get a custom field</li> <li>Get custom field useage</li> </ul>"},{"location":"thehive/api/custom-field/create/","title":"Create","text":"<p>Create a Custom Field (requires <code>manageCustomField</code> permission).</p>"},{"location":"thehive/api/custom-field/create/#query","title":"Query","text":"<pre><code>POST /api/customField\n</code></pre>"},{"location":"thehive/api/custom-field/create/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"name\": \"BusinesUnit\",\n\"reference\": \"businessunit\",\n\"description\": \"Targeted business unit\",\n\"type\": \"string\",\n\"mandatory\": false,\n\"options\": [\n\"VIP\",\n\"HR\",\n\"Security\",\n\"Sys Administrators\",\n\"Developers\",\n\"Sales\",\n\"Marketing\",\n\"Procurement\",\n\"Legal\"\n]\n}\n</code></pre> <p>The following fields are required: </p> <ul> <li><code>name</code>: (String)</li> <li><code>reference</code>: (String)</li> <li><code>description</code>: (String)</li> <li><code>type</code>: [string|integer|boolean|date|float]</li> </ul>"},{"location":"thehive/api/custom-field/create/#response","title":"Response","text":""},{"location":"thehive/api/custom-field/create/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if Custom Fields is created successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/custom-field/create/#responsebody-example","title":"ResponseBody Example","text":"201401403 <pre><code>{\n\"id\": \"~32912\",\n\"name\": \"Business Unit\",\n\"reference\": \"businessUnit\",\n\"description\": \"Targetted business unit\",\n\"type\": \"string\",\n\"options\": [\n\"Sales\",\n\"Marketing\",\n\"VIP\",\n\"Security\",\n\"Sys admins\",\n\"HR\",\n\"Procurement\",\n\"Legal\"\n],\n\"mandatory\": false\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create custom field, you haven't the permission manageCustomField\"\n}\n</code></pre>"},{"location":"thehive/api/custom-field/delete/","title":"Delete","text":"<p>Delete a Custom Field (requires <code>manageCustomField</code> permission).</p>"},{"location":"thehive/api/custom-field/delete/#query","title":"Query","text":"<pre><code>DELETE /api/customField/{id}\n</code></pre> <p>with:</p> <ul> <li><code>id</code>: id or name of the Custom Field.</li> </ul>"},{"location":"thehive/api/custom-field/delete/#response","title":"Response","text":""},{"location":"thehive/api/custom-field/delete/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if Custom Fields is successfully deleted</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/custom-field/get/","title":"Get","text":"<p>Get Custom Field by id;</p>"},{"location":"thehive/api/custom-field/get/#query","title":"Query","text":"<pre><code>GET /api/customField/{id}\n</code></pre> <p>with:</p> <ul> <li><code>id</code>: id or name of the custom field.</li> </ul>"},{"location":"thehive/api/custom-field/get/#response","title":"Response","text":""},{"location":"thehive/api/custom-field/get/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/custom-field/get/#responsebody-example","title":"ResponseBody Example","text":"200401403 <pre><code>{\n\"id\": \"~28672\",\n\"name\": \"Number of Accounts\",\n\"reference\": \"Number of Accounts\",\n\"description\": \"Number of accounts leaked\",\n\"type\": \"integer\",\n\"options\": [],\n\"mandatory\": true\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create custom field, you haven't the permission manageCustomField\"\n}\n</code></pre>"},{"location":"thehive/api/custom-field/getUse/","title":"Use count","text":"<p>Get Custom Field use count by id.</p>"},{"location":"thehive/api/custom-field/getUse/#query","title":"Query","text":"<pre><code>GET /api/customField/{id}/use\n</code></pre> <p>with: </p> <ul> <li><code>id</code>: id or name of the custom field.</li> </ul>"},{"location":"thehive/api/custom-field/getUse/#response","title":"Response","text":""},{"location":"thehive/api/custom-field/getUse/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/custom-field/getUse/#responsebody-example","title":"ResponseBody Example","text":"200401403 <pre><code>{\n\"case\": 12,\n\"alert\": 1,\n\"case_artifact\": 9,\n\"total\": 22\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create custom field, you haven't the permission manageCustomField\"\n}\n</code></pre>"},{"location":"thehive/api/custom-field/list/","title":"List","text":"<p>List Custom Fields.</p>"},{"location":"thehive/api/custom-field/list/#query","title":"Query","text":"<pre><code>GET /api/customField\n</code></pre>"},{"location":"thehive/api/custom-field/list/#response","title":"Response","text":""},{"location":"thehive/api/custom-field/list/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/custom-field/list/#responsebody-example","title":"ResponseBody Example","text":"200401403 <pre><code>[\n{\n\"id\": \"~28672\",\n\"name\": \"Number of Accounts\",\n\"reference\": \"Number of Accounts\",\n\"description\": \"Number of accounts leaked\",\n\"type\": \"integer\",\n\"options\": [],\n\"mandatory\": true\n},\n{\n\"id\": \"~53440\",\n\"name\": \"Nb of emails delivered\",\n\"reference\": \"Nb of emails delivered\",\n\"description\": \"Nb of emails delivered\",\n\"type\": \"integer\",\n\"options\": [],\n\"mandatory\": true\n}\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create custom field, you haven't the permission manageCustomField\"\n}\n</code></pre>"},{"location":"thehive/api/custom-field/update/","title":"Update","text":"<p>Update a Custom Field (requires <code>manageCustomField</code> permission).</p>"},{"location":"thehive/api/custom-field/update/#query","title":"Query","text":"<pre><code>PATCH /api/customField/{id}\n</code></pre> <p>with: </p> <ul> <li><code>id</code>: id or name of the custom field.</li> </ul>"},{"location":"thehive/api/custom-field/update/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"name\": \"Business Unit\",\n\"reference\": \"businessUnit\",\n\"description\": \"Targetted business unit\",\n\"type\": \"string\",\n\"options\": [\n\"Sales\",\n\"Marketing\",\n\"VIP\",\n\"Security\",\n\"Sys admins\",\n\"HR\",\n\"Procurement\",\n\"Legal\"\n],\n\"mandatory\": false\n}\n</code></pre> <p>No fields are required.</p>"},{"location":"thehive/api/custom-field/update/#response","title":"Response","text":""},{"location":"thehive/api/custom-field/update/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if Custom Fields is updated successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/custom-field/update/#responsebody-example","title":"ResponseBody Example","text":"201401403 <pre><code>{\n\"id\": \"~32912\",\n\"name\": \"Business Unit\",\n\"reference\": \"businessUnit\",\n\"description\": \"Targetted business unit\",\n\"type\": \"string\",\n\"options\": [\n\"HR\",\n\"Legal\",\n\"Marketing\",\n\"Procurement\",\n\"Sales\",\n\"Security\",\n\"Sys admins\",\n\"VIP\"\n],\n\"mandatory\": false\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to update custom field, you haven't the permission manageCustomField\"\n}\n</code></pre>"},{"location":"thehive/api/dashboard/update/","title":"Update","text":""},{"location":"thehive/api/dashboard/update/#query","title":"Query","text":""},{"location":"thehive/api/dashboard/update/#request-body-example","title":"Request Body Example","text":""},{"location":"thehive/api/dashboard/update/#responsebody-example","title":"ResponseBody Example","text":""},{"location":"thehive/api/observable/","title":"Observable APIs","text":"<ul> <li>List observables</li> <li>Create observable</li> <li>Update observable</li> <li>Delete observable</li> <li>Run analyzer in observable</li> <li>Run responder in observable</li> </ul>"},{"location":"thehive/api/observable/analyzer/","title":"Analyzer","text":"<p>You need to connect TheHive to a cortex server in order to enable analyzers.</p> <p>Attention</p> <p>Analyzer can only be run on an observable of a case.</p>"},{"location":"thehive/api/observable/analyzer/#run-an-analyzer-on-an-observable","title":"Run an analyzer on an observable","text":"<pre><code>POST /api/connector/cortex/job\n</code></pre>"},{"location":"thehive/api/observable/analyzer/#request-example","title":"Request example","text":"<pre><code>{\n\"cortexId\":\"Stable\",\n\"artifactId\":\"~816984288\",\n\"analyzerId\":\"Abuse_Finder_3_0\"\n}\n</code></pre> <p>The following fields are required: - <code>cortexId</code>: name of the cortex server from the configuration - <code>artifactId</code>: id of the observable to analyze - <code>analyzerId</code>: id of the cortex analyzer to use</p>"},{"location":"thehive/api/observable/analyzer/#responseexample","title":"Responseexample","text":"<pre><code>{\n\"_type\": \"case_artifact_job\",\n\"analyzerId\": \"bface6faa22029dcf81d5d817f27eb98\",\n\"analyzerName\": \"Abuse_Finder_3_0\",\n\"analyzerDefinition\": \"Abuse_Finder_3_0\",\n\"status\": \"Waiting\",\n\"startDate\": 1630660394582,\n\"endDate\": 1630660394582,\n\"cortexId\": \"Stable\",\n\"cortexJobId\": \"BP3uqnsB8Pn57ils_kFX\",\n\"id\": \"~1433604184\"\n}\n</code></pre>"},{"location":"thehive/api/observable/analyzer/#get-analyzer-report","title":"Get analyzer report","text":"<pre><code>GET /api/connector/job/{jobId}\n</code></pre> <p><code>jobId</code> should be the <code>id</code> returned from the creation request</p>"},{"location":"thehive/api/observable/analyzer/#responseexample_1","title":"Responseexample","text":"<p>Example</p> <pre><code>{\n\"_type\": \"case_artifact_job\",\n\"analyzerId\": \"bface6faa22029dcf81d5d817f27eb98\",\n\"analyzerName\": \"Abuse_Finder_3_0\",\n\"analyzerDefinition\": \"Abuse_Finder_3_0\",\n\"status\": \"Success\",\n\"startDate\": 1630660394582,\n\"endDate\": 1630660427845,\n\"report\": {\n\"success\": true,\n\"full\": {\n\"abuse_finder\": {\n\"value\": \"1.2.3.4\",\n\"names\": [\n\"APNIC Debogon Project\"\n],\n\"abuse\": [\n\"helpdesk@apnic.net\"\n],\n\"raw\": \"% [whois.apnic.net]\\n% Whois data copyright terms    http://www.apnic.net/db/dbcopyright.html\\n\\n% Inf...\"\n}\n},\n\"artifacts\": []\n},\n\"cortexId\": \"Stable\",\n\"cortexJobId\": \"BP3uqnsB8Pn57ils_kFX\",\n\"id\": \"~1433604184\"\n}\n</code></pre> <ul> <li><code>status</code> can be one of:<ul> <li><code>Waiting</code></li> <li><code>Success</code></li> <li><code>InProgress</code></li> <li><code>Failure</code></li> <li><code>Deleted</code></li> </ul> </li> </ul>"},{"location":"thehive/api/observable/analyzer/#list-reports-for-an-observable","title":"List reports for an observable","text":"<pre><code>POST /api/v1/query\n</code></pre>"},{"location":"thehive/api/observable/analyzer/#query-body-example","title":"Query body example","text":"<p>Replace the value of <code>idOrName</code> by the <code>id</code> of your observable</p> <p>Example</p> <pre><code>{\n\"query\": [\n{\n\"_name\": \"getObservable\",\n\"idOrName\": \"~816984288\"\n},\n{\n\"_name\": \"jobs\"\n},\n{\n\"_name\": \"sort\",\n\"_fields\": [\n{\n\"startDate\": \"desc\"\n}\n]\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 200\n}\n]\n}\n</code></pre>"},{"location":"thehive/api/observable/analyzer/#responseexample_2","title":"Responseexample","text":"<p>Example</p> <pre><code>[\n{\n\"_type\": \"case_artifact_job\",\n\"analyzerId\": \"bface6faa22029dcf81d5d817f27eb98\",\n\"analyzerName\": \"Abuse_Finder_3_0\",\n\"analyzerDefinition\": \"Abuse_Finder_3_0\",\n\"status\": \"Waiting\",\n\"startDate\": 1630660394582,\n\"endDate\": 1630660394582,\n\"cortexId\": \"Stable\",\n\"cortexJobId\": \"BP3uqnsB8Pn57ils_kFX\",\n\"id\": \"~1433604184\"\n}\n]\n</code></pre>"},{"location":"thehive/api/observable/create/","title":"Create","text":"<p>Creates an observable which can be linked to a case or an alert.</p> <p>Note</p> <p>(The name artifcat comes from TheHive v3)</p>"},{"location":"thehive/api/observable/create/#query","title":"Query","text":"<p>Create an observable for a case</p> <pre><code>POST /api/v0/case/{caseId}/artifact\n</code></pre> <p>Create an observable for an alert</p> <pre><code>POST /api/v0/alert/{alertId}/artifact\n</code></pre>"},{"location":"thehive/api/observable/create/#request-example","title":"Request Example","text":"Observable with attachmentObservables without atttachment <p>If you want to upload an observable with a <code>dataType</code> of kind attachment, you need to use a multipart request <pre><code>curl -XPOST http://THEHIVE/api/v0/case/{caseId}/artifact -F attachment=@myFile -F _json='\n{\n    \"dataType\": \"file\",\n    \"tlp\": 2,\n    \"ioc\": true,\n    \"sighted\": false,\n    \"tags\": [],\n    \"message\": \"foo\",\n    \"data\": [],\n    \"isZip\": false,\n    \"zipPassword\": \"\"\n}\n'\n</code></pre></p> <p>To add an observable with no attachment, you can post a json body <pre><code>{\n\"dataType\": \"hostname\",\n\"tlp\": 2,\n\"ioc\": true,\n\"sighted\": true,\n\"tags\": [],\n\"data\": [\n\"server.local\"\n]\n}\n</code></pre></p> <p>The following fields are required:</p> <ul> <li><code>dataType</code>: (enum String, should be one registered observable type)</li> <li>One of <code>data</code> (Array of String) or <code>attachment</code> (File)</li> </ul> <p>Other optional fields:</p> <ul> <li><code>message</code>: (String) description of the observable in the context of the case</li> <li><code>startDate</code>: (Date) date of the observable creation default=now</li> <li><code>tlp</code>: (Int) TLP (<code>0</code>: <code>white</code>; <code>1</code>: <code>green</code>; <code>2</code>: <code>amber</code>;<code>3</code>: <code>red</code>) default=2</li> <li><code>tags</code>: (Array of string) a list of tags default=[]</li> <li><code>ioc</code>: (Boolean) indicates if the observable is an IOC default=false</li> <li><code>sighted</code>: (Boolean) indicates if the observable was sighted default=false</li> <li><code>ignoreSimilarity</code>: (Boolean) indicates if the observable should be used or not to calculate the similarity stats default=false</li> </ul>"},{"location":"thehive/api/observable/create/#responsebody-example","title":"ResponseBody Example","text":"Observables with atttachmentObservables without atttachment <pre><code>[\n{\n\"_id\": \"~4104\",\n\"id\": \"~4104\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"createdAt\": 1630508511351,\n\"_type\": \"case_artifact\",\n\"dataType\": \"file\",\n\"startDate\": 1630508511351,\n\"attachment\": {\n\"name\": \"server.log\",\n\"hashes\": [\n\"ccbda6ed6aac6cde57ebac1f011bdf1f58bf61c40c759dc4f7fccb729de10147\",\n\"a09531845b3b26d5707cdf50a8bb11aa507dd88c\",\n\"1f08c024363568d6eb4e18ee97618acc\"\n],\n\"size\": 37165,\n\"contentType\": \"application/octet-stream\",\n\"id\": \"ccbda6ed6aac6cde57ebac1f011bdf1f58bf61c40c759dc4f7fccb729de10147\"\n},\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": true,\n\"sighted\": false,\n\"message\": \"my message\",\n\"reports\": {},\n\"stats\": {}\n}\n]\n</code></pre> <pre><code>[\n{\n\"_id\": \"~4104\",\n\"id\": \"~4104\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"createdAt\": 1630508511351,\n\"_type\": \"case_artifact\",\n\"ip\": \"file\",\n\"data\": \"1.2.3.4\",\n\"startDate\": 1630508511351,\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": true,\n\"sighted\": false,\n\"message\": \"my message\",\n\"reports\": {},\n\"stats\": {}\n}\n]\n</code></pre>"},{"location":"thehive/api/observable/delete/","title":"Delete","text":"<p>Delete a case or alert Observable by its id</p>"},{"location":"thehive/api/observable/delete/#query","title":"Query","text":"<pre><code>DELETE /api/v0/case/artifact/{observableId}\n</code></pre> <pre><code>DELETE /api/v0/alert/artifact/{observableId}\n</code></pre>"},{"location":"thehive/api/observable/delete/#response","title":"Response","text":"<ul> <li><code>204 No Content</code></li> </ul>"},{"location":"thehive/api/observable/list/","title":"List / Search","text":""},{"location":"thehive/api/observable/list/#query","title":"Query","text":"<pre><code>POST /api/v1/query\n</code></pre>"},{"location":"thehive/api/observable/list/#request-body-example","title":"Request Body Example","text":"<p>List last 30 observables for a case:</p> <pre><code>{\n\"query\": [\n{\n\"_name\": \"getCase\",\n\"idOrName\": \"{caseId}\"\n},\n{\n\"_name\": \"observables\"\n},\n{\n\"_name\": \"sort\",\n\"_fields\": [\n{ \"startDate\": \"desc\"}\n]\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 30\n}\n]\n}\n</code></pre>"},{"location":"thehive/api/observable/list/#responseexample","title":"ResponseExample","text":"<pre><code>[\n{\n\"_id\": \"~122884120\",\n\"_type\": \"Observable\",\n\"_createdBy\": \"foo@local.io\",\n\"_updatedBy\": \"foo@local.io\",\n\"_createdAt\": 1630509659446,\n\"_updatedAt\": 1630511666911,\n\"dataType\": \"hostname\",\n\"data\": \"server.local\",\n\"startDate\": 1630509659446,\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": true,\n\"sighted\": false,\n\"reports\": {},\n\"message\": \"myMessage\",\n\"extraData\": {}\n},\n{\n\"_id\": \"~4104\",\n\"_type\": \"Observable\",\n\"_createdBy\": \"foo@local.io\",\n\"_createdAt\": 1630508511351,\n\"dataType\": \"file\",\n\"startDate\": 1630508511351,\n\"attachment\": {\n\"_id\": \"~40964280\",\n\"_type\": \"Attachment\",\n\"_createdBy\": \"foo@local.io\",\n\"_createdAt\": 1630508511313,\n\"name\": \"server.log\",\n\"hashes\": [\n\"ccbda6ed6aac6cde57ebac1f011bdf1f58bf61c40c759dc4f7fccb729de10147\",\n\"a09531845b3b26d5707cdf50a8bb11aa507dd88c\",\n\"1f08c024363568d6eb4e18ee97618acc\"\n],\n\"size\": 37165,\n\"contentType\": \"application/octet-stream\",\n\"id\": \"ccbda6ed6aac6cde57ebac1f011bdf1f58bf61c40c759dc4f7fccb729de10147\"\n},\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": true,\n\"sighted\": false,\n\"reports\": {},\n\"message\": \"foo\",\n\"extraData\": {}\n}\n]\n</code></pre>"},{"location":"thehive/api/observable/responder/","title":"Responder","text":"<p>You need to connect TheHive to a cortex server in order to enable responders.</p> <p>Attention</p> <p>Responder can only be run on an observable of a case.</p>"},{"location":"thehive/api/observable/responder/#run-a-responder-on-an-observable","title":"Run a responder on an observable","text":"<pre><code>POST /api/connector/cortex/action\n</code></pre>"},{"location":"thehive/api/observable/responder/#request-example","title":"Request example","text":"<pre><code>{\n\"cortexId\": \"Stable\",\n\"responderId\": \"e4c500d589d14503883c02d02313cf57\",\n\"objectType\": \"case_artifact\",\n\"objectId\": \"~816984288\"\n}\n</code></pre> <p>The following fields are required:</p> <ul> <li><code>cortexId</code>: name of the cortex server from the configuration</li> <li><code>objectType</code>: should be <code>case_artifact</code> here</li> <li><code>objectId</code>: id of the observable to analyze</li> <li><code>responderId</code>: id of the cortex responder to use</li> </ul>"},{"location":"thehive/api/observable/responder/#responseexample","title":"Responseexample","text":"<pre><code>{\n\"responderId\": \"e4c500d589d14503883c02d02313cf57\",\n\"responderName\": \"ADD_TO_WEBPROXY_BL_1_0\",\n\"responderDefinition\": \"ADD_TO_WEBPROXY_BL_1_0\",\n\"cortexId\": \"Stable\",\n\"cortexJobId\": \"Bv0cq3sB8Pn57ilsUkFM\",\n\"objectType\": \"Observable\",\n\"objectId\": \"~816984288\",\n\"status\": \"Waiting\",\n\"startDate\": 1630663366136,\n\"operations\": \"[]\",\n\"report\": \"{}\"\n}\n</code></pre>"},{"location":"thehive/api/observable/responder/#list-responder-actions","title":"List responder actions","text":"<pre><code>GET /api/connector/cortex/action/case_artifact/{observableId}\n</code></pre>"},{"location":"thehive/api/observable/responder/#responseexample_1","title":"Responseexample","text":"<p>Example</p> <pre><code>[\n{\n\"responderId\": \"e4c500d589d14503883c02d02313cf57\",\n\"responderName\": \"ADD_TO_WEBPROXY_BL_1_0\",\n\"responderDefinition\": \"ADD_TO_WEBPROXY_BL_1_0\",\n\"cortexId\": \"Stable\",\n\"cortexJobId\": \"Bv0cq3sB8Pn57ilsUkFM\",\n\"objectType\": \"Observable\",\n\"objectId\": \"~816984288\",\n\"status\": \"Failure\",\n\"startDate\": 1630663366136,\n\"endDate\": 1630663372393,\n\"operations\": \"[]\",\n\"report\": \"{\\\"summary\\\":{\\\"taxonomies\\\":[]},\\\"full\\\":null,\\\"success\\\":false,\\\"artifacts\\\":[],\\\"operations\\\":[],...}\"\n}\n]\n</code></pre> <ul> <li> <p><code>status</code> can be one of:</p> <ul> <li><code>Waiting</code></li> <li><code>Success</code></li> <li><code>InProgress</code></li> <li><code>Failure</code></li> <li><code>Deleted</code></li> </ul> </li> <li> <p><code>report</code> is a string that contains the output of the responder</p> </li> </ul>"},{"location":"thehive/api/observable/update/","title":"Update","text":"<p>Update a case or alert Observable by its id</p>"},{"location":"thehive/api/observable/update/#query","title":"Query","text":"<pre><code>PATCH /api/v0/case/artifact/{observableId}\n</code></pre> <pre><code>PATCH /api/v0/alert/artifact/{observableId}\n</code></pre>"},{"location":"thehive/api/observable/update/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"sighted\": true,\n\"ioc\": true,\n\"message\": \"This observable was sighted\"\n}\n</code></pre> <p>Fields that can be updated:</p> <ul> <li><code>ioc</code></li> <li><code>sighted</code></li> <li><code>ignoreSimilarity</code></li> <li><code>tags</code></li> <li><code>message</code></li> <li><code>tlp</code></li> </ul> <p>Once an observable is created, it is not possible to change its type or data</p>"},{"location":"thehive/api/observable/update/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>{\n\"_id\": \"~122884120\",\n\"id\": \"~122884120\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"updatedBy\": \"lydia@strangebee.com\",\n\"createdAt\": 1630509659446,\n\"updatedAt\": 1630511666911,\n\"_type\": \"case_artifact\",\n\"dataType\": \"hostname\",\n\"data\": \"server.local\",\n\"startDate\": 1630509659446,\n\"tlp\": 2,\n\"tags\": [],\n\"ioc\": true,\n\"sighted\": true,\n\"message\": \"This observable was sighted\",\n\"reports\": {},\n\"stats\": {}\n}\n</code></pre>"},{"location":"thehive/api/organisation/","title":"Organisation APIs","text":"<ul> <li>List organisations</li> <li>Create organisation</li> <li>Update organisation</li> <li>List organisation links</li> <li>Set organisation links</li> </ul>"},{"location":"thehive/api/organisation/create/","title":"Create","text":"<p>API to create a new TheHive organisation.</p>"},{"location":"thehive/api/organisation/create/#query","title":"Query","text":"<pre><code>POST /api/v0/organisation\n</code></pre>"},{"location":"thehive/api/organisation/create/#authorization","title":"Authorization","text":"<p>This API requires a super admin user with <code>manageOrganisation</code> permission</p>"},{"location":"thehive/api/organisation/create/#request","title":"Request","text":""},{"location":"thehive/api/organisation/create/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"description\": \"SOC team\",\n\"name\": \"soc\"\n}\n</code></pre>"},{"location":"thehive/api/organisation/create/#fields","title":"Fields","text":"<p>The following fields are required:</p> <ul> <li><code>name</code>: (String)</li> <li><code>description</code>: (String)</li> </ul>"},{"location":"thehive/api/organisation/create/#response","title":"Response","text":""},{"location":"thehive/api/organisation/create/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if organisation creation completed successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/organisation/create/#responsebody-example","title":"ResponseBody Example","text":"200401403 <pre><code>{\n\"_id\": \"~204804296\",\n\"_type\": \"organisation\",\n\"createdAt\": 1630385478884,\n\"createdBy\": \"admin@thehive.local\",\n\"description\": \"SOC team\",\n\"id\": \"~204804296\",\n\"links\": [],\n\"name\": \"soc\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Unauthorized action\"\n}\n</code></pre>"},{"location":"thehive/api/organisation/list-links/","title":"List links","text":""},{"location":"thehive/api/organisation/list-links/#query","title":"Query","text":"<pre><code>GET /api/v0/organisation/{idOrName}/links\n</code></pre> <p>with:</p> <ul> <li><code>idOrName</code> id or name of the organisation</li> </ul>"},{"location":"thehive/api/organisation/list-links/#response","title":"Response","text":""},{"location":"thehive/api/organisation/list-links/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if organisation exists</li> <li><code>404</code>: if organisation doesn't exist</li> </ul>"},{"location":"thehive/api/organisation/list/","title":"List/Search","text":"<p>List Organisations.</p>"},{"location":"thehive/api/organisation/list/#query","title":"Query","text":"<pre><code>GET /api/v0/query\n</code></pre>"},{"location":"thehive/api/organisation/list/#request","title":"Request","text":"<p>This is a Query API call, where:</p> <ul> <li><code>listOrganisation</code> is the query name</li> </ul> <pre><code>  {\n\"query\": [\n{\n\"_name\": \"listOrganisation\"\n},\n{\n\"_fields\": [\n{\n\"updatedAt\": \"desc\"\n}\n],\n\"_name\": \"sort\"\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 15\n}\n]\n}\n</code></pre>"},{"location":"thehive/api/organisation/list/#response","title":"Response","text":""},{"location":"thehive/api/organisation/list/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/organisation/list/#responsebody-example","title":"ResponseBody Example","text":"200401 <pre><code>[\n{\n\"_createdAt\": 1630385478884,\n\"_createdBy\": \"admin@thehive.local\",\n\"_id\": \"~204804296\",\n\"_type\": \"Organisation\",\n\"_updatedAt\": 1630415216098,\n\"_updatedBy\": \"admin@thehive.local\",\n\"description\": \"SOC level\",\n\"links\": [\n\"cert\"\n],\n\"name\": \"soc-level1\"\n},\n{\n\"_createdAt\": 1606467059596,\n\"_createdBy\": \"admin@thehive.local\",\n\"_id\": \"~4144\",\n\"_type\": \"Organisation\",\n\"description\": \"CERT\",\n\"links\": [\n\"soc-level1\"\n],\n\"name\": \"cert\"\n},\n{\n\"_createdAt\": 1606464802479,\n\"_createdBy\": \"system@thehive.local\",\n\"_id\": \"~8408\",\n\"_type\": \"Organisation\",\n\"description\": \"organisation for administration\",\n\"links\": [],\n\"name\": \"admin\"\n}\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/organisation/update-links/","title":"Update links","text":"<p>Link orgnisation to one or many other organisations. It sets the list of organisation link to the list provided as input. It overrides the existing list of links.</p>"},{"location":"thehive/api/organisation/update-links/#query","title":"Query","text":"<pre><code>PUT /api/v0/organisation/{idOrName}/links\n</code></pre> <p>with:</p> <ul> <li><code>idOrName</code> id or name of the organisation</li> </ul>"},{"location":"thehive/api/organisation/update-links/#request","title":"Request","text":""},{"location":"thehive/api/organisation/update-links/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"organisations\": [\n\"cert\", \"csirt\"\n]\n}\n</code></pre>"},{"location":"thehive/api/organisation/update-links/#fields","title":"Fields","text":"<ul> <li><code>organisations</code> (required): Array of organisation names</li> </ul>"},{"location":"thehive/api/organisation/update-links/#response","title":"Response","text":""},{"location":"thehive/api/organisation/update-links/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code> if the operation completed successfully</li> </ul>"},{"location":"thehive/api/organisation/update/","title":"Update","text":""},{"location":"thehive/api/organisation/update/#query","title":"Query","text":"<pre><code>PATCH /api/v0/organisation/{id}\n</code></pre> <p>with:</p> <ul> <li><code>id</code>: id or name of the organisation.</li> </ul>"},{"location":"thehive/api/organisation/update/#authorization","title":"Authorization","text":"<p>This API requires a super admin user with <code>manageOrganisation</code> permission</p>"},{"location":"thehive/api/organisation/update/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"description\": \"SOC level 1 team\",\n\"name\": \"soc-level1\"\n}\n</code></pre>"},{"location":"thehive/api/organisation/update/#fields","title":"Fields","text":"<p>The following fields are editable:</p> <ul> <li><code>name</code> (String)</li> <li><code>description</code> (String)</li> </ul>"},{"location":"thehive/api/organisation/update/#response","title":"Response","text":"<ul> <li><code>204</code>: if the organisation is updated successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/search/","title":"Search APIs","text":"<ul> <li>Build queries</li> </ul>"},{"location":"thehive/api/search/query/","title":"Query API","text":""},{"location":"thehive/api/search/query/#overview","title":"Overview","text":"<p>The Query API is the API used to search for objects with filtering and sorting capabilities. It's an API introduced by TheHive 4 and is optimized for the the new data model.</p> <p>TheHive comes with a list of predefined search Queries like:</p> <ul> <li><code>listOrganisation</code></li> <li><code>listUser</code></li> <li><code>listAlert</code></li> <li><code>listCase</code></li> </ul>"},{"location":"thehive/api/search/query/#query","title":"Query","text":"<pre><code>POST /api/v0/query\n</code></pre>"},{"location":"thehive/api/search/query/#request-body","title":"Request Body","text":"<p>The Query API request body should be an array of operations of different types:</p> <ul> <li>Selection: Required<ul> <li>list of objects</li> <li>object by identifier</li> </ul> </li> <li>Filtering: optional</li> <li>Sorting: optional</li> <li>Pagination: optional</li> <li>Formatting: optional</li> </ul> <p>Examples</p> Simple ListList with filtersList with filters and sortList with pagination <pre><code>{\n\"query\": [\n{\n\"_name\": \"listOrganisation\"\n}\n]\n}\n</code></pre> <p>List organisations called admin <pre><code>{\n\"query\": [\n{\n\"_name\": \"listOrganisation\"\n},\n{\n\"_like\": {\n\"_field\": \"name\",\n\"_value\": \"admin\"\n},\n\"_name\": \"filter\"\n}\n]\n}\n</code></pre></p> <p>List organisations called admin, sorted by ascendant <code>updatedAt</code> value <pre><code>{\n\"query\": [\n{\n\"_name\": \"listOrganisation\"\n},\n{\n\"_like\": {\n\"_field\": \"name\",\n\"_value\": \"admin\"\n},\n\"_name\": \"filter\"\n},\n{\n\"_fields\": [\n{\n\"updatedAt\": \"asc\"\n}\n],\n\"_name\": \"sort\"\n}\n]\n}\n</code></pre></p> <p>List organisations called admin, sorted by ascendant <code>updatedAt</code> value, paginated to display the first 15 items <pre><code>{\n\"query\": [\n{\n\"_name\": \"listOrganisation\"\n},\n{\n\"_like\": {\n\"_field\": \"name\",\n\"_value\": \"admin\"\n},\n\"_name\": \"filter\"\n},\n{\n\"_fields\": [\n{\n\"updatedAt\": \"asc\"\n}\n],\n\"_name\": \"sort\"\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 15\n}\n]\n}\n</code></pre></p>"},{"location":"thehive/api/task/","title":"Case task APIs","text":""},{"location":"thehive/api/task/#case-task-operations","title":"Case task operations","text":"<ul> <li>List case tasks</li> <li>Create task</li> <li>Update task</li> <li>Get task details</li> <li>Run responder</li> <li>List responder jobs</li> </ul>"},{"location":"thehive/api/task/#case-task-log-oprations","title":"Case task log oprations","text":"<ul> <li>List task logs</li> <li>Create task log</li> <li>Delete task log</li> <li>Run responder on log</li> <li>List responder jobs on log</li> </ul>"},{"location":"thehive/api/task/#global-task-operations","title":"Global task operations","text":"<ul> <li>List waiting tasks</li> </ul>"},{"location":"thehive/api/task/create-log/","title":"Add log","text":"<p>Add a Log to an existing task (requires <code>manageTask</code> permission).</p>"},{"location":"thehive/api/task/create-log/#query","title":"Query","text":"<pre><code>POST /api/case/task/{id}/log\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Task identifier</li> </ul>"},{"location":"thehive/api/task/create-log/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"message\": \"The sandbox hasn't detected any suspicious activity\",\n\"startDate\": 1630683608000,\n}\n</code></pre> <p>The only required field is <code>message</code>.</p> <p>If you want to attach a file to the log, you need to use a multipart request</p> <pre><code>curl -XPOST http://THEHIVE/api/v0/case/task/{taskId}/log -F attachment=@report.pdf -F _json='\n{\n    \"message\": \"The sandbox report\"\n}\n'\n</code></pre>"},{"location":"thehive/api/task/create-log/#response","title":"Response","text":""},{"location":"thehive/api/task/create-log/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if Log is created successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/task/create-log/#response-body-example","title":"Response Body Example","text":"201401403 <pre><code>{\n\"id\": \"~4264\",\n\"_id\": \"~4264\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"createdAt\": 1630684502715,\n\"_type\": \"case_task\u00e7log\",\n\"message\": \"The sandbox hasn't detected any suspicious activity\",\n\"startDate\": 1630683608000\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create Log, you haven't the permission manageTask\"\n}\n</code></pre>"},{"location":"thehive/api/task/create/","title":"Create","text":"<p>Create a Task (requires <code>manageTask</code> permission).</p>"},{"location":"thehive/api/task/create/#query","title":"Query","text":"<pre><code>POST /api/case/{id}task\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Case identifier</li> </ul>"},{"location":"thehive/api/task/create/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"title\": \"Malware analysis\",\n\"group\": \"identification\",\n\"description\": \"Analysis of the file to identify the malware\",\n\"owner\": \"jerome@strangebee.com\",\n\"status\": \"InProgress\",\n\"flag\": false,\n\"startDate\": 1630683608000,\n\"endDate\": 1630684608000,\n\"order\": 3,\n\"dueDate\": 1630694608000\n}\n</code></pre> <p>The only required field is <code>title</code>.</p> <p>The <code>status</code> can be <code>Waiting</code>, <code>InProgress</code>, <code>Completed</code> or <code>Cancel</code>.</p>"},{"location":"thehive/api/task/create/#response","title":"Response","text":""},{"location":"thehive/api/task/create/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if Tasks is created successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/task/create/#responsebody-example","title":"ResponseBody Example","text":"201401403 <pre><code>{\n\"id\": \"~4264\",\n\"_id\": \"~4264\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"createdAt\": 1630684502715,\n\"_type\": \"case_task\",\n\"title\": \"Malware analysis\",\n\"group\": \"identification\",\n\"description\": \"Analysis of the file to identify the malware\",\n\"owner\": \"jerome@strangebee.com\",\n\"status\": \"InProgress\",\n\"flag\": false,\n\"startDate\": 1630683608000,\n\"endDate\": 1630684608000,\n\"order\": 3,\n\"dueDate\": 1630694608000\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create Task, you haven't the permission manageTask\"\n}\n</code></pre>"},{"location":"thehive/api/task/delete-log/","title":"Delete log","text":"<p>Delete a Log of an existing task (requires <code>manageTask</code> permission).</p>"},{"location":"thehive/api/task/delete-log/#query","title":"Query","text":"<pre><code>DELETE /api/case/task/log/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Log identifier</li> </ul>"},{"location":"thehive/api/task/delete-log/#response","title":"Response","text":""},{"location":"thehive/api/task/delete-log/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if Log is deleted successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/task/get/","title":"Get case task","text":"<p>Get Task of a case.</p>"},{"location":"thehive/api/task/get/#query","title":"Query","text":"<pre><code>GET /api/case/task/{id}\n</code></pre> <p>with: </p> <ul> <li><code>id</code>: id of the task.</li> </ul>"},{"location":"thehive/api/task/get/#response","title":"Response","text":""},{"location":"thehive/api/task/get/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> <li><code>404</code>: The Task is not found</li> </ul>"},{"location":"thehive/api/task/get/#responsebody-example","title":"ResponseBody Example","text":"201401404 <pre><code>  {\n\"id\": \"~4264\",\n\"_id\": \"~4264\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"createdAt\": 1630684502715,\n\"_type\": \"case_task\",\n\"title\": \"Malware analysis\",\n\"group\": \"identification\",\n\"description\": \"Analysis of the file to identify the malware\",\n\"owner\": \"jerome@strangebee.com\",\n\"status\": \"InProgress\",\n\"flag\": false,\n\"startDate\": 1630683608000,\n\"endDate\": 1630684608000,\n\"order\": 3,\n\"dueDate\": 1630694608000\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Task not found\"\n}\n</code></pre>"},{"location":"thehive/api/task/list/","title":"List case tasks","text":"<p>List Tasks of a case.</p>"},{"location":"thehive/api/task/list/#query","title":"Query","text":"<pre><code>POST /api/v0/query\n</code></pre>"},{"location":"thehive/api/task/list/#request-body-example","title":"Request Body Example","text":"<p>List 15 waiting tasks in case ~25485360.</p> <pre><code>{\n\"query\": [\n{\n\"_name\": \"getCase\",\n\"idOrName\": \"~25485360\"\n},\n{\n\"_name\": \"tasks\"\n},\n{\n\"_name\": \"filter\",\n\"status\": \"Waiting\"\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 15\n}\n]\n}\n</code></pre>"},{"location":"thehive/api/task/list/#response","title":"Response","text":""},{"location":"thehive/api/task/list/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/task/list/#responsebody-example","title":"ResponseBody Example","text":"201401 <pre><code>[\n{\n\"id\": \"~4264\",\n\"_id\": \"~4264\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"createdAt\": 1630684502715,\n\"_type\": \"case_task\",\n\"title\": \"Malware analysis\",\n\"group\": \"identification\",\n\"description\": \"Analysis of the file to identify the malware\",\n\"owner\": \"jerome@strangebee.com\",\n\"status\": \"InProgress\",\n\"flag\": false,\n\"startDate\": 1630683608000,\n\"endDate\": 1630684608000,\n\"order\": 3,\n\"dueDate\": 1630694608000\n},\n{\n\"id\": \"~8360\",\n\"_id\": \"~8360\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"updatedBy\": \"jerome@strangebee.com\",\n\"createdAt\": 1630687291729,\n\"updatedAt\": 1630687323936,\n\"_type\": \"case_task\",\n\"title\": \"Block malware URLs in proxy\",\n\"group\": \"containment\",\n\"description\": \"Add identified malicious URLs in proxy black list\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 0\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/task/log-responder-jobs/","title":"List responder jobs on log","text":"<p>List actions run on a log.</p>"},{"location":"thehive/api/task/log-responder-jobs/#query","title":"Query","text":"<pre><code>GET /api/connector/cortex/action/case_task_log/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Log identifier</li> </ul>"},{"location":"thehive/api/task/log-responder-jobs/#response","title":"Response","text":""},{"location":"thehive/api/task/log-responder-jobs/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/task/log-responder-jobs/#response-body-example","title":"Response Body Example","text":"200401 <pre><code>  [\n{\n\"responderId\": \"25dcbbb69d50dd5a5ae4bd55f4ca5903\",\n\"responderName\": \"reponderName_1_0\",\n\"responderDefinition\": \"reponderName_1_0\",\n\"cortexId\": \"local-cortex\",\n\"cortexJobId\": \"408-unsB3SwW9-eEPXXW\",\n\"objectType\": \"Log\",\n\"objectId\": \"~25313328\",\n\"status\": \"Success\",\n\"startDate\": 1630917246993,\n\"endDate\": 1630917254406,\n\"operations\": \"[]\",\n\"report\": \"{\\\"summary\\\":{\\\"taxonomies\\\":[]},\\\"full\\\":null,\\\"success\\\":true,\\\"artifacts\\\":[],\\\"operations\\\":[],\\\\\\\"message\\\\\\\":\\\\\\\"Ok\\\\\\\",\\\\\\\"parameters\\\\\\\":{\\\\\\\"organisation\\\\\\\":\\\\\\\"StrangeBee\\\\\\\",\\\\\\\"user\\\\\\\":\\\\\\\"jerome@strangebee.com\\\\\\\"},\\\\\\\"config\\\\\\\":{\\\\\\\"proxy_https\\\\\\\":null,\\\\\\\"cacerts\\\\\\\":null,\\\\\\\"check_tlp\\\\\\\":false,\\\\\\\"max_tlp\\\\\\\":2,\\\\\\\"check_pap\\\\\\\":false,\\\\\\\"max_pap\\\\\\\":2,\\\\\\\"jobTimeout\\\\\\\":30,\\\\\\\"proxy_http\\\\\\\":null}}\\\"}\"\n}\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/task/log-run-responder/","title":"Run responder","text":"<p>Run a responder on a Log (requires <code>manageAction</code> permission).</p>"},{"location":"thehive/api/task/log-run-responder/#query","title":"Query","text":"<pre><code>POST /api/connector/cortex/action\n</code></pre>"},{"location":"thehive/api/task/log-run-responder/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"responderId\": \"25dcbbb69d50dd5a5ae4bd55f4ca5903\",\n\"cortexId\": \"local-cortex\",\n\"objectType\": \"case_task_log\",\n\"objectId\": \"~11123\"\n}\n</code></pre> <p>The required fields are <code>responderId</code>, <code>objectType</code> and <code>objectId</code>.</p>"},{"location":"thehive/api/task/log-run-responder/#response","title":"Response","text":""},{"location":"thehive/api/task/log-run-responder/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if responder is started successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> <li><code>404</code>: Log is not found</li> </ul>"},{"location":"thehive/api/task/log-run-responder/#response-body-example","title":"Response Body Example","text":"201401403404 <pre><code>  {\n\"responderId\": \"25dcbbb69d50dd5a5ae4bd55f4ca5903\",\n\"responderName\": \"reponderName_1_0\",\n\"responderDefinition\": \"reponderName_1_0\",\n\"cortexId\": \"local-cortex\",\n\"cortexJobId\": \"408-unsB3SwW9-eEPXXW\",\n\"objectType\": \"Log\",\n\"objectId\": \"~25313328\",\n\"status\": \"Waiting\",\n\"startDate\": 1630917246993,\n\"operations\": \"[]\",\n\"report\": \"{}\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create action, you haven't the permission manageTask\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Log not found\"\n}\n</code></pre>"},{"location":"thehive/api/task/logs/","title":"List task logs","text":"<p>List Task logs of a Case.</p>"},{"location":"thehive/api/task/logs/#query","title":"Query","text":"<pre><code>POST /api/v1/query?name=case-task-logs\n</code></pre>"},{"location":"thehive/api/task/logs/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"query\":[{\n\"_name\":\"getTask\",\n\"idOrName\":\"id\"\n},\n{\n\"_name\":\"logs\"\n},\n{\n\"_name\":\"sort\",\n\"_fields\":[{\n\"date\":\"desc\"\n}]\n},\n{\n\"_name\":\"page\",\n\"from\":0,\n\"to\":10,\n\"extraData\":[\"actionCount\"]\n}]\n}\n</code></pre>"},{"location":"thehive/api/task/logs/#response","title":"Response","text":""},{"location":"thehive/api/task/logs/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/task/logs/#responsebody-example","title":"ResponseBody Example","text":"200401 <pre><code>[\n{\n\"_id\":\"~1421384\",\n\"_type\":\"Log\",\n\"_createdBy\":\"analyst@soc\",\n\"_createdAt\":1637090593968,\n\"message\":\"42\",\n\"date\":1637090593968,\n\"owner\":\"analyst@soc\",\n\"extraData\":{\"actionCount\":0}\n},\n{\n\"_id\":\"~1429680\",\n\"_type\":\"Log\",\n\"_createdBy\":\"analyst@soc\",\n\"_createdAt\":1637090578809,\n\"message\":\"test sample\",\n\"date\":1637090578809,\n\"owner\":\"analyst@soc\",\n\"extraData\":{\"actionCount\":0}\n}\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/task/responder-jobs/","title":"List responder jobs","text":"<p>List actions run on a task.</p>"},{"location":"thehive/api/task/responder-jobs/#query","title":"Query","text":"<pre><code>GET /api/connector/cortex/action/case_task/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: Task identifier</li> </ul>"},{"location":"thehive/api/task/responder-jobs/#response","title":"Response","text":""},{"location":"thehive/api/task/responder-jobs/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/task/responder-jobs/#response-body-example","title":"Response Body Example","text":"200401 <pre><code>  [\n{\n\"responderId\": \"25dcbbb69d50dd5a5ae4bd55f4ca5903\",\n\"responderName\": \"reponderName_1_0\",\n\"responderDefinition\": \"reponderName_1_0\",\n\"cortexId\": \"local-cortex\",\n\"cortexJobId\": \"408-unsB3SwW9-eEPXXW\",\n\"objectType\": \"Task\",\n\"objectId\": \"~25313328\",\n\"status\": \"Success\",\n\"startDate\": 1630917246993,\n\"endDate\": 1630917254406,\n\"operations\": \"[]\",\n\"report\": \"{\\\"summary\\\":{\\\"taxonomies\\\":[]},\\\"full\\\":null,\\\"success\\\":true,\\\"artifacts\\\":[],\\\"operations\\\":[],\\\\\\\"message\\\\\\\":\\\\\\\"Ok\\\\\\\",\\\\\\\"parameters\\\\\\\":{\\\\\\\"organisation\\\\\\\":\\\\\\\"StrangeBee\\\\\\\",\\\\\\\"user\\\\\\\":\\\\\\\"jerome@strangebee.com\\\\\\\"},\\\\\\\"config\\\\\\\":{\\\\\\\"proxy_https\\\\\\\":null,\\\\\\\"cacerts\\\\\\\":null,\\\\\\\"check_tlp\\\\\\\":false,\\\\\\\"max_tlp\\\\\\\":2,\\\\\\\"check_pap\\\\\\\":false,\\\\\\\"max_pap\\\\\\\":2,\\\\\\\"jobTimeout\\\\\\\":30,\\\\\\\"proxy_http\\\\\\\":null}}\\\"}\"\n}\n]\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/task/run-responder/","title":"Run responder","text":"<p>Run a responder on a Task (requires <code>manageAction</code> permission).</p>"},{"location":"thehive/api/task/run-responder/#query","title":"Query","text":"<pre><code>POST /api/connector/cortex/action\n</code></pre>"},{"location":"thehive/api/task/run-responder/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"responderId\": \"25dcbbb69d50dd5a5ae4bd55f4ca5903\",\n\"cortexId\": \"local-cortex\",\n\"objectType\": \"case_task\",\n\"objectId\": \"~11123\"\n}\n</code></pre> <p>The required fields are <code>responderId</code>, <code>objectType</code> and <code>objectId</code>.</p>"},{"location":"thehive/api/task/run-responder/#response","title":"Response","text":""},{"location":"thehive/api/task/run-responder/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if responder is started successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> <li><code>404</code>: Task is not found</li> </ul>"},{"location":"thehive/api/task/run-responder/#response-body-example","title":"Response Body Example","text":"201401403404 <pre><code>  {\n\"responderId\": \"25dcbbb69d50dd5a5ae4bd55f4ca5903\",\n\"responderName\": \"reponderName_1_0\",\n\"responderDefinition\": \"reponderName_1_0\",\n\"cortexId\": \"local-cortex\",\n\"cortexJobId\": \"408-unsB3SwW9-eEPXXW\",\n\"objectType\": \"Task\",\n\"objectId\": \"~25313328\",\n\"status\": \"Waiting\",\n\"startDate\": 1630917246993,\n\"operations\": \"[]\",\n\"report\": \"{}\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to create action, you haven't the permission manageTask\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Task not found\"\n}\n</code></pre>"},{"location":"thehive/api/task/update/","title":"Update","text":"<p>Update a Task (requires <code>manageTask</code> permission).</p>"},{"location":"thehive/api/task/update/#query","title":"Query","text":"<pre><code>PATCH /api/case/task/{id}\n</code></pre> <p>with: </p> <ul> <li><code>id</code>: id of the task.</li> </ul>"},{"location":"thehive/api/task/update/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"title\": \"Block malware URLs in proxy\",\n\"group\": \"containment\",\n\"description\": \"Add identified malicious URLs in proxy black list\",\n\"owner\": \"jerome@strangebee.com\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"startDate\": 1630683608000,\n\"endDate\": 1630684608000,\n\"order\": 5,\n\"dueDate\": 1630694608000\n}\n</code></pre> <p>No fields are required.</p>"},{"location":"thehive/api/task/update/#response","title":"Response","text":""},{"location":"thehive/api/task/update/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if Task is updated successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/task/update/#responsebody-example","title":"ResponseBody Example","text":"201401403 <pre><code>{\n\"id\": \"~4264\",\n\"_id\": \"~4264\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"createdAt\": 1630684502715,\n\"updatedBy\": \"jerome@strangebee.com\",\n\"updatedAt\": 1630685486000,\n\"_type\": \"case_task\",\n\"title\": \"Block malware URLs in proxy\",\n\"group\": \"containment\",\n\"description\": \"Add identified malicious URLs in proxy black list\",\n\"owner\": \"jerome@strangebee.com\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"startDate\": 1630683608000,\n\"endDate\": 1630684608000,\n\"order\": 5,\n\"dueDate\": 1630694608000\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthorizationError\",\n\"message\": \"Your are not authorized to update Task, you haven't the permission manageTask\"\n}\n</code></pre>"},{"location":"thehive/api/task/waiting-tasks/","title":"List waiting tasks","text":"<p>List all waiting Tasks.</p>"},{"location":"thehive/api/task/waiting-tasks/#query","title":"Query","text":"<pre><code>POST /api/v0/query\n</code></pre>"},{"location":"thehive/api/task/waiting-tasks/#request-body-example","title":"Request Body Example","text":"<p>List 15 waiting tasks, sorted by <code>flag</code> and <code>startDate</code>.</p> <pre><code>{\n\"query\": [\n{\n\"_name\": \"waitingTasks\"\n},\n{\n\"_name\": \"sort\",\n\"_fields\": [\n{\n\"flag\": \"desc\"\n},\n{\n\"startDate\": \"desc\"\n}\n]\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 15\n}\n]\n}\n</code></pre>"},{"location":"thehive/api/task/waiting-tasks/#response","title":"Response","text":""},{"location":"thehive/api/task/waiting-tasks/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> </ul>"},{"location":"thehive/api/task/waiting-tasks/#responsebody-example","title":"ResponseBody Example","text":"201401 <pre><code>[\n{\n\"id\": \"~4264\",\n\"_id\": \"~4264\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"createdAt\": 1630684502715,\n\"_type\": \"case_task\",\n\"title\": \"Malware analysis\",\n\"group\": \"identification\",\n\"description\": \"Analysis of the file to identify the malware\",\n\"owner\": \"jerome@strangebee.com\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"startDate\": 1630683608000,\n\"endDate\": 1630684608000,\n\"order\": 3,\n\"dueDate\": 1630694608000\n},\n{\n\"id\": \"~8360\",\n\"_id\": \"~8360\",\n\"createdBy\": \"jerome@strangebee.com\",\n\"updatedBy\": \"jerome@strangebee.com\",\n\"createdAt\": 1630687291729,\n\"updatedAt\": 1630687323936,\n\"_type\": \"case_task\",\n\"title\": \"Block malware URLs in proxy\",\n\"group\": \"containment\",\n\"description\": \"Add identified malicious URLs in proxy black list\",\n\"status\": \"Waiting\",\n\"flag\": false,\n\"order\": 0\n}\n</code></pre> <pre><code>{\n\"type\": \"AuthenticationError\",\n\"message\": \"Authentication failure\"\n}\n</code></pre>"},{"location":"thehive/api/ttp/","title":"Tactic, Technique and Procedure APIs","text":"<ul> <li>List case TTPs</li> <li>Create TTP</li> <li>Update TTP</li> <li>Delete TTP</li> </ul>"},{"location":"thehive/api/ttp/create/","title":"Create","text":""},{"location":"thehive/api/ttp/create/#query","title":"Query","text":""},{"location":"thehive/api/ttp/create/#request-body-example","title":"Request Body Example","text":""},{"location":"thehive/api/ttp/create/#responsebody-example","title":"ResponseBody Example","text":""},{"location":"thehive/api/ttp/update/","title":"Update","text":""},{"location":"thehive/api/ttp/update/#query","title":"Query","text":""},{"location":"thehive/api/ttp/update/#request-body-example","title":"Request Body Example","text":""},{"location":"thehive/api/ttp/update/#responsebody-example","title":"ResponseBody Example","text":""},{"location":"thehive/api/user/","title":"User APIs","text":"<ul> <li>List users</li> <li>Create a user</li> <li>Update a user</li> <li>Delete a user</li> <li>Lock user</li> <li>Generate API key</li> <li>Get API key</li> <li>Revoke API key</li> <li>Set password</li> </ul>"},{"location":"thehive/api/user/create/","title":"Create","text":"<p>Create an User.</p>"},{"location":"thehive/api/user/create/#query","title":"Query","text":"<pre><code>POST /api/v1/user\n</code></pre>"},{"location":"thehive/api/user/create/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"login\" : \"jerome@strangebee.com\",\n\"name\" : \"Jerome\",\n\"organisation\": \"StrangeBee\",\n\"profile\": \"org-admin\",\n\"email\": \"jerome@strangebee.com\",\n\"password\": \"my-secret-password\"\n}\n</code></pre> <p>The following fields are required: </p> <ul> <li><code>login</code>: (String - email address)</li> <li><code>name</code>: (String)</li> <li><code>organisation</code>:  (String)</li> <li><code>profile</code>:  [admin|org-admin|analyst|read-only|any customed profile]</li> </ul>"},{"location":"thehive/api/user/create/#response","title":"Response","text":""},{"location":"thehive/api/user/create/#status-codes","title":"Status codes","text":"<ul> <li><code>201</code>: if User is created successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/user/create/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>{\n\"_id\": \"~947527808\",\n\"_createdBy\": \"admin@thehive.local\",\n\"_createdAt\": 1630411433091,\n\"login\": \"jerome@strangebee.com\",\n\"name\": \"Jerome\",\n\"hasKey\": false,\n\"hasPassword\": false,\n\"hasMFA\": false,\n\"locked\": false,\n\"profile\": \"analyst\",\n\"permissions\": [\n\"manageShare\",\n\"manageAnalyse\",\n\"manageTask\",\n\"manageCase\",\n\"manageProcedure\",\n\"managePage\",\n\"manageObservable\",\n\"manageAlert\",\n\"accessTheHiveFS\",\n\"manageAction\"\n],\n\"organisation\": \"StrangeBee\",\n\"organisations\": [],\n\"email\": \"jerome@strangebee.com\"\n}\n</code></pre>"},{"location":"thehive/api/user/delete/","title":"Delete","text":"<p>Delete a User.</p>"},{"location":"thehive/api/user/delete/#query","title":"Query","text":"<pre><code>DELETE /api/v1/user/{id}/force?organisation={ORG_NAME}\n</code></pre> <p>with:</p> <ul> <li><code>id</code>: id or login of the user</li> <li><code>ORG_NAME</code>: the organisation name from which the user is to be removed</li> </ul>"},{"location":"thehive/api/user/delete/#response","title":"Response","text":""},{"location":"thehive/api/user/delete/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if User is successfully deleted</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/user/generate-api-key/","title":"Generate API key","text":"<p>Generate an API key for a user. </p>"},{"location":"thehive/api/user/generate-api-key/#query","title":"Query","text":"<pre><code>POST /api/v1/user/{id}/key/renew\n</code></pre> <p>with: </p> <ul> <li><code>id</code>: id or login of the user</li> </ul>"},{"location":"thehive/api/user/generate-api-key/#request-body-example","title":"Request Body Example","text":"<p>The body is empty.</p>"},{"location":"thehive/api/user/generate-api-key/#response","title":"Response","text":""},{"location":"thehive/api/user/generate-api-key/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if the API key have succesfully been generated</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/user/generate-api-key/#responsebody-example","title":"ResponseBody Example","text":"<p>The key in plain text.</p> <pre><code>  BOXTE+Cq0qrZcHhTK4j0LpT/TVW5auOz\n</code></pre>"},{"location":"thehive/api/user/get-api-key/","title":"Get API key","text":"<p>Get the API key of a user. </p>"},{"location":"thehive/api/user/get-api-key/#query","title":"Query","text":"<pre><code>GET /api/v1/user/{id}/key\n</code></pre> <p>with: </p> <ul> <li><code>id</code>: id or login of the user</li> </ul>"},{"location":"thehive/api/user/get-api-key/#response","title":"Response","text":""},{"location":"thehive/api/user/get-api-key/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if the API key have succesfully been generated</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/user/get-api-key/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>  BOXTE+Cq0qrZcHhTK4j0LpT/TVW5auOz\n</code></pre>"},{"location":"thehive/api/user/list/","title":"List","text":"<p>List users.</p>"},{"location":"thehive/api/user/list/#query","title":"Query","text":"<pre><code>POST /api/v1/query\n</code></pre>"},{"location":"thehive/api/user/list/#request-body-example","title":"Request Body Example","text":"<p>List last 15 users created.</p> <pre><code>{\n\"query\": [\n{\n\"_name\": \"getOrganisation\",\n\"idOrName\": \"StrangeBee\"\n},\n{\n\"_name\": \"users\"\n},\n{\n\"_name\": \"sort\",\n\"_fields\": [\n{\n\"login\": \"asc\"\n}\n]\n},\n{\n\"_name\": \"page\",\n\"from\": 0,\n\"to\": 15,\n\"organisation\": \"StrangeBee\"\n}\n]\n}\n</code></pre>"},{"location":"thehive/api/user/list/#response","title":"Response","text":""},{"location":"thehive/api/user/list/#status-codes","title":"Status codes","text":"<ul> <li><code>200</code>: if query is run successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/user/list/#responsebody-example","title":"ResponseBody Example","text":"<pre><code>[\n{\n\"_id\": \"~947527808\",\n\"_createdBy\": \"admin@thehive.local\",\n\"_createdAt\": 1630411433091,\n\"login\": \"jerome@strangebee.com\",\n\"name\": \"Jerome\",\n\"hasKey\": false,\n\"hasPassword\": false,\n\"hasMFA\": false,\n\"locked\": false,\n\"profile\": \"analyst\",\n\"permissions\": [\n\"manageShare\",\n\"manageAnalyse\",\n\"manageTask\",\n\"manageCase\",\n\"manageProcedure\",\n\"managePage\",\n\"manageObservable\",\n\"manageAlert\",\n\"accessTheHiveFS\",\n\"manageAction\"\n],\n\"organisation\": \"StrangeBee\",\n\"organisations\": []\n}\n]\n</code></pre>"},{"location":"thehive/api/user/lock/","title":"Lock / Unlock","text":"<p>Lock a User.</p>"},{"location":"thehive/api/user/lock/#query","title":"Query","text":"<pre><code>PATCH /api/v1/user/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: id or login of the user</li> </ul>"},{"location":"thehive/api/user/lock/#request-body-example","title":"Request Body Example","text":"LockUnlock <pre><code>{\n\"locked\": true\n}\n</code></pre> <pre><code>{\n\"locked\": false\n}\n</code></pre> <p>The following fields are required: </p> <ul> <li><code>locked</code>: (Boolean)</li> </ul>"},{"location":"thehive/api/user/lock/#response","title":"Response","text":""},{"location":"thehive/api/user/lock/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if User is locked successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/user/revoke-api-key/","title":"Revoke API key","text":"<p>Revoke the API key of a user</p>"},{"location":"thehive/api/user/revoke-api-key/#query","title":"Query","text":"<pre><code>DELETE /api/v1/user/{id}/key\n</code></pre> <p>with:</p> <ul> <li><code>id</code>: id or login of the user</li> </ul>"},{"location":"thehive/api/user/revoke-api-key/#response","title":"Response","text":""},{"location":"thehive/api/user/revoke-api-key/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if API key is successfully revoked</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/user/set-password/","title":"Set password","text":"<p>Set a User's password.</p> <p>The user making the query needs to be an admin of the platform</p>"},{"location":"thehive/api/user/set-password/#query","title":"Query","text":"<pre><code>POST /api/v1/user/{id}/password/set\n</code></pre> <p>with:</p> <ul> <li><code>id</code>: id of the user</li> </ul>"},{"location":"thehive/api/user/set-password/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"password\": \"thehive1234\"\n}\n</code></pre> <p>The following fields are required:</p> <ul> <li><code>password</code>: (String)</li> </ul>"},{"location":"thehive/api/user/set-password/#response","title":"Response","text":""},{"location":"thehive/api/user/set-password/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if password is set successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/api/user/update/","title":"Update","text":"<p>Update User's information.</p>"},{"location":"thehive/api/user/update/#query","title":"Query","text":"<pre><code>PATCH /api/v1/user/{id}\n</code></pre> <p>With:</p> <ul> <li><code>id</code>: id or login of the user</li> </ul>"},{"location":"thehive/api/user/update/#request-body-example","title":"Request Body Example","text":"<pre><code>{\n\"name\": \"Jerome\",\n\"profile\": \"org-admin\",\n\"organisation\": \"StrangeBee\",\n\"locked\": false\n}\n</code></pre> <p>The field <code>organisation</code> is used if the profile is updated (the profile of an user depends on the organisation). If not specified, the current organisation is  used. No fields are required.</p>"},{"location":"thehive/api/user/update/#response","title":"Response","text":""},{"location":"thehive/api/user/update/#status-codes","title":"Status codes","text":"<ul> <li><code>204</code>: if User is updated successfully</li> <li><code>401</code>: Authentication error</li> <li><code>403</code>: Authorization error</li> </ul>"},{"location":"thehive/installation-and-configuration/","title":"Installation &amp; configuration guides","text":""},{"location":"thehive/installation-and-configuration/#overview","title":"Overview","text":"<p>The scalability of TheHive allows it to be set up as a standalone server or as nodes inside a cluster. Any number of nodes can rely on a database and a file system also setup as standalone servers or a cluster. </p> <p>Before starting installing and configuring, you need to identify and define the targetted architecture.</p> <p></p>"},{"location":"thehive/installation-and-configuration/#choose-a-setup","title":"Choose a setup","text":"<p>The modular architecture makes it support several types of database, file storage system and indexing system. The initial choices made with the target architecture and the setup are crucial, especially for the database.</p> <p>If high availability and fault tolerance are necessary, implementing a cluster might be the choice, and this choice determines the database, the file storage and indexing system to install.  </p> <p>Hardware Pre-requisites</p> <p>Hardware requirements depends on the number of concurrent users and how they use the system. The following table give some information to choose the hardware.</p> Number of users CPU RAM &lt; 3 2 4-8 &lt; 10 4 8-16 &lt; 20 8 16-32"},{"location":"thehive/installation-and-configuration/#choose-a-database","title":"Choose a database","text":"<p>Once the target setup is identified, the first choice to make is the database. Even of local Berkeley DB and Cassandra database are supported, we recommend using Apache Cassandra, which is a scalable and high available Database, even for standalone servers. </p> <p>Berkeley DB can be enough for testing purposes.</p> <p>Upgradability</p> <p>This choice is decisive as migration from Berkeley DB to Cassandra is not possible.</p>"},{"location":"thehive/installation-and-configuration/#choose-a-file-storage-system","title":"Choose a file storage system","text":"<p>Like for databases, several options exist regarding file system. </p> <p>Basically, for standalone setups, using the local filesystem is the easiest solution. If installing a cluster, there are several options:</p> <ul> <li>Using a share NFS folder</li> <li>Using Apache Hadoop, a distributed file system</li> <li>Using a S3-compatible storage service ; for example with Min.IO</li> </ul> <p>Upgradability</p> <p>Starting with a standalone server and a local file storage and upgrading to a cluster with S3 of Hadoop is possible. Existing files can be moved to the targetted solutions.</p>"},{"location":"thehive/installation-and-configuration/#choose-an-index-system","title":"Choose an index system","text":"<p>Introduced with TheHive 4.1 to increase performances, TheHive relies on a dedicated indexing process. With a standalone setup, using a local index with Lucene is sufficient.</p> <p>In the case of a cluster, all nodes have to connect to the same index: an instance of Elasticsearch is then required.   </p> <p>Upgradability</p> <p>Starting with a standalone server and Lucene and upgrading to a cluster with Elasticsearch is possible. Indices can be rebuilt. However, it can takes some time.</p>"},{"location":"thehive/installation-and-configuration/#installation-guide","title":"Installation Guide","text":"<p>The following Guide let you prepare, install and configure TheHive and its prerequisites for Debian and RPM packages based Operating Systems, as well as for other systems and using our binary packages. </p> <p>If you want to build TheHive from sources, you can follow this guide.</p>"},{"location":"thehive/installation-and-configuration/#configuration-guides","title":"Configuration Guides","text":"<p>The configuration of TheHive is in files stored in the <code>/etc/thehive</code> folder:</p> <ul> <li><code>application.conf</code> contains all parameters and options</li> <li><code>logback.xml</code> is dedicated to log management</li> </ul> <pre><code>/etc/thehive\n\u251c\u2500\u2500 application.conf\n\u251c\u2500\u2500 logback.xml\n\u2514\u2500\u2500 secret.conf\n</code></pre> <p>A separate secret.conf file is automatically created by Debian or RPM packages. This file should contain a secret that should be used by one instance.</p> <p>Various aspects can configured in the <code>application.conf</code> file:</p> <ul> <li>database and indexing</li> <li>File storage</li> <li>Akka</li> <li>Authentication</li> <li>Connectors<ul> <li>Cortex: connecting to one or more organisation</li> <li>MISP: connecting to one or more organisation</li> </ul> </li> <li>Webhooks</li> <li>Other service parameters</li> </ul>"},{"location":"thehive/installation-and-configuration/#uses-cases","title":"Uses Cases","text":""},{"location":"thehive/installation-and-configuration/#basic-stand-alone-server","title":"Basic stand alone server","text":"<p>Follow the installation guides for you prefered operating system.</p>"},{"location":"thehive/installation-and-configuration/#cluster-with-3-thehive-nodes","title":"Cluster with 3 TheHive nodes","text":"<p>The folling guide details all the installation and configuration steps to get a cluster with 3 nodes working. The cluster is composed of:  </p> <ul> <li>3 TheHive servers  </li> <li>3 Cassandra servers </li> <li>3 Min.IO servers</li> </ul>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/","title":"Use TheHive as a cluster","text":"<p>This guide provides configuration examples for TheHive, Cassandra and MinIO to build a fault-tolerant cluster of 3 active nodes. </p>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#prerequisite","title":"Prerequisite","text":"<p>3 servers with TheHive and Cassandra installed. </p>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#thehive","title":"TheHive","text":"<p>In this guide, we are considering the node 1 to be the master node. Start by configuring <code>akka</code> component by editing the <code>/etc/thehive/application.conf</code> file of each node like this:</p> <pre><code>akka {\n  cluster.enable = on \n  actor {\n    provider = cluster\n  }\nremote.artery {\n  canonical {\n    hostname = \"&lt;My IP address&gt;\"\n    port = 2551\n  }\n}\n# seed node list contains at least one active node\ncluster.seed-nodes = [\n                      \"akka://application@&lt;Node 1 IP address&gt;:2551\",\n                      \"akka://application@&lt;Node 2 IP address&gt;:2551\",\n                      \"akka://application@&lt;Node 3 IP address&gt;:2551\"\n                     ]\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#cassandra","title":"Cassandra","text":"<p>We are considering setting up a cluster of 3 active nodes of Cassandra with a replication factor of 3. That means that all nodes are active and the data is present on each node.  This setup is tolerant to a 1 node failure.</p> <p>For the rest of this part, we are considering that all nodes sit on the same network.</p>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#configuration","title":"Configuration","text":""},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#nodes-configuration","title":"Nodes configuration","text":"<p>For each node, update configuration files with the following parameters: </p> <ul> <li><code>/etc/cassandra/cassandra.yml</code> </li> </ul> <pre><code>cluster_name: 'thp'\nnum_tokens: 256\nauthenticator: PasswordAuthenticator\nauthorizer: CassandraAuthorizer\nrole_manager: CassandraRoleManager\ndata_file_directories:\n    - /var/lib/cassandra/data\ncommitlog_directory: /var/lib/cassandra/commitlog\nsaved_caches_directory: /var/lib/cassandra/saved_caches\nseed_provider:\n    - class_name: org.apache.cassandra.locator.SimpleSeedProvider\n      parameters:\n        - seeds: \"&lt;ip node 1&gt;, &lt;ip node 2&gt;, &lt;ip node 3&gt;\"\nlisten_interface : eth0\nrpc_interface: eth0\nendpoint_snitch: SimpleSnitch\n</code></pre> <p>Ensure to setup the right interface name.</p> <ul> <li>delete file <code>/etc/cassandra/cassandra-topology.properties</code> </li> </ul> <pre><code>rm /etc/cassandra/cassandra-topology.properties\n</code></pre>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#start-nodes","title":"Start nodes","text":"<p>On each node, start the service: </p> <pre><code>service cassandra start\n</code></pre> <p>Ensure that all nodes are up and running: </p> <pre><code>root@cassandra:/# nodetool status\nDatacenter: dc1\n===============\nStatus=Up/Down\n|/ State=Normal/Leaving/Joining/Moving\n--  Address      Load       Tokens       Owns (effective)  Host ID                               Rack\nUN  &lt;ip node 1&gt;  776.53 KiB  256          100.0%            a79c9a8c-c99b-4d74-8e78-6b0c252abd86  rack1\nUN  &lt;ip node 2&gt;  671.72 KiB  256          100.0%            8fda2906-2097-4d62-91f8-005e33d3e839  rack1\nUN  &lt;ip node 3&gt;  611.54 KiB  256          100.0%            201ab99c-8e16-49b1-9b66-5444044fb1cd  rack1\n</code></pre>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#initialise-the-database","title":"Initialise the database","text":"<p>On one node run (default password for <code>cassandra</code> account is <code>cassandra</code>): </p> <pre><code>cqlsh &lt;ip node X&gt; -u cassandra\n</code></pre> <ul> <li>Start by changing the password of superadmin named <code>cassandra</code>: </li> </ul> <pre><code>ALTER USER cassandra WITH PASSWORD 'NEWPASSWORD';\n</code></pre> <pre><code>exit and reconnect.\n</code></pre> <ul> <li>Ensure user accounts are duplicated on all nodes </li> </ul> <pre><code>ALTER KEYSPACE system_auth WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3 };\n</code></pre> <ul> <li>Create keyspace named <code>thehive</code></li> </ul> <pre><code>CREATE KEYSPACE thehive WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '3' } AND durable_writes = 'true';\n</code></pre> <ul> <li>Create role <code>thehive</code> and grant permissions on <code>thehive</code> keyspace (choose a password) </li> </ul> <pre><code>CREATE ROLE thehive WITH LOGIN = true AND PASSWORD = 'PASSWORD';\nGRANT ALL PERMISSIONS ON KEYSPACE thehive TO 'thehive';\n</code></pre>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#thehive-associated-configuration","title":"TheHive associated configuration","text":"<p>Update the configuration of thehive accordingly in <code>/etc/thehive/application.conf</code> :  <pre><code>## Database configuration\ndb.janusgraph {\n  storage {\n    ## Cassandra configuration\n    # More information at https://docs.janusgraph.org/basics/configuration-reference/#storagecql\n    backend: cql\n    hostname: [\"&lt;ip node 1&gt;\", \"&lt;ip node 2&gt;\", \"&lt;ip node 3&gt;\"]\n    # Cassandra authentication (if configured)\n    username: \"thehive\"\n    password: \"PASSWORD\"\n    cql {\n      cluster-name: thp\n      keyspace: thehive\n    }\n  }\n</code></pre></p>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p><code>InvalidRequest: code=2200 [Invalid query] message=\u201dorg.apache.cassandra.auth.CassandraRoleManager doesn\u2019t support PASSWORD\u201d.</code></p> </li> </ul> <p>set the value <code>authenticator: PasswordAuthenticator</code> in <code>cassandra.yaml</code></p> <ul> <li> <p><code>Caused by: java.util.concurrent.ExecutionException: com.datastax.driver.core.exceptions.UnauthorizedException: Unable to perform authorization of permissions: Unable to perform authorization of super-user permission: Cannot achieve consistency level LOCAL_ONE</code> </p> <pre><code>ALTER KEYSPACE system_auth WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3 };\n</code></pre> </li> </ul>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#minio","title":"MinIO","text":"<p>MinIO distributed mode requires fresh directories. Here is an example of implementation of MinIO with TheHive.</p> <p>The following procedure should be performed on all servers belonging the the cluster. We are considering the setup where the cluster is composed of 3 servers named minio1, minio2 &amp; minio3.</p>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#create-a-dedicated-system-account","title":"Create a dedicated system account","text":"<p>Create a dedicated user with <code>/opt/minio</code> as homedir. </p> <pre><code>adduser minio\n</code></pre>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#create-at-least-2-data-volumes-on-each-server","title":"Create at least 2 data volumes on each server","text":"<p>Create 2 folders on each server: </p> <pre><code>mkdir -p /srv/minio/{1,2}\nchown -R minio:minio /srv/minio\n</code></pre>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#setup-hosts-files","title":"Setup hosts files","text":"<p>Edit <code>/etc/hosts</code> of all servers </p> <pre><code>ip-minio-1     minio1\nip-minio-2     minio2\nip-minio-3     minio3\n</code></pre>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#installation","title":"installation","text":"<pre><code>cd /opt/minio\nmkdir /opt/minio/{bin,etc}\nwget -O /opt/minio/bin https://dl.minio.io/server/minio/release/linux-amd64/minio\nchown -R minio:minio /opt/minio\n</code></pre>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#configuration_1","title":"Configuration","text":"<p>Create or edit file `/opt/minio/etc/minio.conf</p> <pre><code>MINIO_OPTS=\"server --address :9100 http://minio{1...3}/srv/minio/{1...2}\"\nMINIO_ACCESS_KEY=\"&lt;ACCESS_KEY&gt;\"\nMINIO_SECRET_KEY=\"&lt;SECRET_KEY&gt;\"\n</code></pre> <p>Create a service file named <code>/usr/lib/systemd/system/minio.service</code> </p> <pre><code>[Unit]\nDescription=minio\nDocumentation=https://docs.min.io\nWants=network-online.target\nAfter=network-online.target\nAssertFileIsExecutable=/opt/minio/bin/minio\n\n[Service]\nWorkingDirectory=/opt/minio\nUser=minio\nGroup=minio\nEnvironmentFile=/opt/minio/etc/minio.conf\nExecStart=/opt/minio/bin/minio $MINIO_OPTS\nRestart=always\nLimitNOFILE=65536\nTimeoutStopSec=0\nSendSIGKILL=no\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#enable-and-start-the-service","title":"Enable and start the service","text":"<pre><code>systemctl daemon-reload\nsystemctl enable minio\nsystemctl start minio.service\n</code></pre>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#prepare-the-service-for-thehive","title":"Prepare the service for TheHive","text":"<p>Following operations should be performed once all servers are up and running. A new server CAN NOT be added afterward. Connect using the access key and secret key  to one server with your browser on port 9100: <code>http://minio:9100</code></p> <p></p> <p>Create a bucket named <code>thehive</code></p> <p></p> <p>The bucket should be created and available on all your servers. </p>"},{"location":"thehive/installation-and-configuration/architecture/3_nodes_cluster/#thehive-associated-configuration_1","title":"TheHive associated configuration","text":"<p>For each TheHive node of the cluster, add the relevant storage configuration. Example for the first node thehive1: </p> <pre><code>storage {\n  provider: s3\n  s3 {\n    bucket = \"thehive\"\n    readTimeout = 1 minute\n    writeTimeout = 1 minute\n    chunkSize = 1 MB\n    endpoint = \"http://&lt;IP_MINIO_1&gt;:9100\"\n    accessKey = \"&lt;MINIO ACCESS KEY&gt;\"\n    secretKey = \"&lt;MINIO SECRET KEY&gt;\"\n    region = \"us-east-1\"\n  }\n}\n\nalpakka.s3.path-style-access = force\n</code></pre> <p><code>us-east-1</code> is the default region if none has been specified in MinIO configuration. In this case, this parameter is optional.</p> <p>Each TheHive server can connect to one MinIO server.</p>"},{"location":"thehive/installation-and-configuration/configuration/akka/","title":"Cluster","text":"<p>Quote</p> <p>Akka is a toolkit for building highly concurrent, distributed, and resilient message-driven applications for Java and Scala</p> <p>-- https://akka.io/</p> <p>Akka is used to make several nodes of TheHive work together and offer a smooth user experience. </p> <p>A good cluster setup requires at least 3 nodes of THeHive applications. For each node, Akka must be configured like this: </p> <pre><code>## Akka server\nakka {\ncluster.enable = on\nactor {\nprovider = cluster\n}\nremote.artery {\ncanonical {\nhostname = \"&lt;HOSTNAME OR IP_ADDRESS&gt;\"\nport = 2551\n}\n}\n# seed node list contains at least one active node\ncluster.seed-nodes = [ \"akka://application@HOSTNAME1:2551\", \"akka://application@HOSTNAME2:2551\", \"akka://application@HOSTNAME3:2551\" ]\n}\n</code></pre> <p>with:</p> <ul> <li><code>remote.artery.hostname</code> containing the hostname or IP address of the node,</li> <li><code>cluster.seed-nodes</code> containing the list of akka nodes and beeing the same on all nodes </li> </ul> <p>Configuration of a Cluster with 3 nodes</p> Node 1Node 2Node 3 <p>Akka configuration for Node 1:</p> <pre><code>akka {\ncluster.enable = on\nactor {\nprovider = cluster\n}\nremote.artery {\ncanonical {\nhostname = \"10.1.2.1\"\nport = 2551\n}\n}\n# seed node list contains at least one active node\ncluster.seed-nodes = [ \"akka://application@10.1.2.1:2551\", \"akka://application@10.1.2.2:2551\", \"akka://application@10.1.2.3:2551\" ]\n}\n</code></pre> <p>Akka configuration for Node 2:</p> <pre><code>akka {\ncluster.enable = on\nactor {\nprovider = cluster\n}\nremote.artery {\ncanonical {\nhostname = \"10.1.2.2\"\nport = 2551\n}\n}\n# seed node list contains at least one active node\ncluster.seed-nodes = [ \"akka://application@10.1.2.1:2551\", \"akka://application@10.1.2.2:2551\", \"akka://application@10.1.2.3:2551\" ]\n}\n</code></pre> <p>Akka configuration for Node 3:</p> <pre><code>akka {\ncluster.enable = on\nactor {\nprovider = cluster\n}\nremote.artery {\ncanonical {\nhostname = \"10.1.2.3\"\nport = 2551\n}\n}\n# seed node list contains at least one active node\ncluster.seed-nodes = [ \"akka://application@10.1.2.1:2551\", \"akka://application@10.1.2.2:2551\", \"akka://application@10.1.2.3:2551\" ]\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/akka/#ssltls","title":"SSL/TLS","text":"<p>Akka supports SSL/TLS to encrypt communications between nodes. A typical configuration with SSL support : </p> <pre><code>## Akka server\nakka {\ncluster.enable = on\nactor {\nprovider = cluster\n}\nremote.artery {\ntransport = tls-tcp\ncanonical {\nhostname = \"&lt;HOSTNAME OR IP_ADDRESS&gt;\"\nport = 2551\n}\n\nssl.config-ssl-engine {\nkey-store = \"&lt;PATH TO KEYSTORE&gt;\"\ntrust-store = \"&lt;PATH TO TRUSTSTORE&gt;\"\n\nkey-store-password = \"chamgeme\"\nkey-password = \"chamgeme\"\ntrust-store-password = \"chamgeme\"\n\nprotocol = \"TLSv1.2\"\n}\n}\n# seed node list contains at least one active node\ncluster.seed-nodes = [ \"akka://application@HOSTNAME1:2551\", \"akka://application@HOSTNAME2:2551\", \"akka://application@HOSTNAME3:2551\" ]\n}\n</code></pre> <p>Note</p> <p>Note that <code>akka.remote.artery.transport</code> has changed and <code>akka.ssl.config-ssl-engine</code> needs to be configured.</p> <p>Reference: https://doc.akka.io/docs/akka/current/remoting-artery.html#remote-security</p> <p>About Certificates</p> <p>Use your own internal PKI, or <code>keytool</code> commands to generate your certificates.</p> <p>Reference: https://lightbend.github.io/ssl-config/CertificateGeneration.html#using-keytool</p> <p>Your server certificates should contain various KeyUsage and ExtendedkeyUsage extensions to make everything work properly:</p> <ul> <li>KeyUsage extensions<ul> <li><code>nonRepudiation</code></li> <li><code>dataEncipherment</code></li> <li><code>digitalSignature</code></li> <li><code>keyEncipherment</code></li> </ul> </li> <li>ExtendedkeyUsage extensions<ul> <li><code>serverAuth</code></li> <li><code>clientAuth</code></li> </ul> </li> </ul> <p>Akka configuration with SSL for Node 1</p> <pre><code>## Akka server\nakka {\ncluster.enable = on\nactor {\nprovider = cluster\n}\nremote.artery {\ntransport = tls-tcp\ncanonical {\nhostname = \"10.1.2.1\"\nport = 2551\n}\n\nssl.config-ssl-engine {\nkey-store = \"/etc/thehive/application.conf.d/certs/10.1.2.1.jks\"\ntrust-store = \"/etc/thehive/application.conf.d/certs/internal_ca.jks\"\n\nkey-store-password = \"chamgeme\"\nkey-password = \"chamgeme\"\ntrust-store-password = \"chamgeme\"\n\nprotocol = \"TLSv1.2\"\n}\n}\n# seed node list contains at least one active node\ncluster.seed-nodes = [ \"akka://application@10.1.2.1:2551\", \"akka://application@10.1.2.2:2551\", \"akka://application@10.1.2.3:2551\" ]\n}\n</code></pre> <p>Apply the same principle for the other nodes, and restart all services.</p>"},{"location":"thehive/installation-and-configuration/configuration/authentication/","title":"Authentication","text":"<p>Authentication consists of a set of module. Each one tries to authenticate the user. If it fails, the next one in the list is tried until the end of the list. The default configuration for authentication is:</p> <pre><code>auth {\nproviders = [\n{name: session}\n{name: basic, realm: thehive}\n{name: local}\n{name: key}\n]\n}\n</code></pre> <p>Below are the available authentication modules:</p>"},{"location":"thehive/installation-and-configuration/configuration/authentication/#session","title":"session","text":"<p>Authenticates HTTP requests using a cookie. This module manage the cookie creation and expiration. It accepts the following configuration parameters:</p> Parameter Type Description <code>inactivity</code> duration the maximum time of user inactivity before the session is closed <code>warning</code> duration the time before the expiration TheHive returns a warning message <p>Example</p> <pre><code>  auth {\nproviders = [\n{\nname: session\ninactivity: 600 minutes\nwarning: 10 minutes\n}\n]\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/authentication/#local","title":"local","text":"<p>Create a session if the provided login and password, or API key is correct according to the local user database.</p>"},{"location":"thehive/installation-and-configuration/configuration/authentication/#key","title":"key","text":"<p>Authenticates HTTP requests using API key provided in the authorization header. The format is <code>Authorization: Bearer xxx</code> (xxx is replaced by the API key). The key is searched using other authentication modules (currently, only local authentication module can validate the key).</p>"},{"location":"thehive/installation-and-configuration/configuration/authentication/#basic","title":"basic","text":"<p>Authenticates HTTP requests using the login and password provided in authorization header using basic authentication format (Base64). Password is checked from the local user database.</p> Parameter Type Description <code>realm</code> string name of the realm. Without this parameter, the browser doesn't ask to authenticate"},{"location":"thehive/installation-and-configuration/configuration/authentication/#header","title":"header","text":"<p>Authenticates HTTP requests using a HTTP header containing the user login. This is used to delegate authentication in a reverse proxy. This module accepts the configuration:</p> Parameter Type Description <code>userHeader</code> string the name of the header that contain the user login"},{"location":"thehive/installation-and-configuration/configuration/authentication/#ad","title":"ad","text":"<p>Use Microsoft ActiveDirectory to authenticate the user. The configuration is:</p> Parameter Type Description <code>hosts</code> list of string the addresses of the domain controllers. If missing, the dnsDomain is used <code>winDomain</code> string the Windows domain name (<code>MYDOMAIN</code>) <code>dnsDomain</code> string the Windows domain name in DNS format (<code>mydomain.local</code>) <code>useSSL</code> boolean indicate if SSL must be used to connect to domain controller. The global trust store of the JVM is used to validate remote certificate (<code>JAVA_OPTS=\"-Djavax.net.ssl.trustStore=/path/to/truststore.jks\"</code>) <p>Example</p> <pre><code>auth {\nproviders: [\n{name: session}\n{name: basic, realm: thehive}\n{name: local}\n{\n      name: ad,\n      hosts: [\"dc.mydomain.local\"],\n      dnsDomain: \"mydomain.local\",\n      winDomain: \"MYDOMAIN\",\n}\n]\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/authentication/#ldap","title":"ldap","text":"<p>Use LDAP directory server to authenticate the user. The configuration is:</p> Parameter Type Description <code>hosts</code> list of string the addresses of the LDAP servers <code>bindDN</code> string DN of the service account in LDAP. This account is used to search the user <code>bindPW</code> string password of the service account <code>baseDN</code> string DN where the users are located in <code>filter</code> string filter used to search the user. \"{0}\" is replaced by the user login. A valid filter is: <code>(&amp;(uid={0})(objectClass=posixAccount))</code> <code>useSSL</code> boolean indicate if SSL must be used to connect to LDAP server. The global trust store of the JVM is used to validate remote certificate (<code>JAVA_OPTS=\"-Djavax.net.ssl.trustStore=/path/to/truststore.jks\"</code>) <p>Example</p> <pre><code>auth {\nproviders: [\n{name: session}\n{name: basic, realm: thehive}\n{name: local}\n{\n      name: ldap\nhosts: [ldap1.mydomain.local, ldap2.mydomain.local]\n      bindDN: \"cn=thehive,ou=services,dc=mydomain,dc=local\"\n      bindPW: \"SuperSecretPassword\"\n      baseDN: \"ou=users,dc=mydomain,dc=local\"\n      filter:  \"(cn={0})\"\n      useSSL: true\n}\n]\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/authentication/#oauth2","title":"oauth2","text":"<p>Authenticate the user using an external OAuth2 authenticator server. It accepts the following configuration parameters:</p> Parameter Type Description <code>clientId</code> string client ID in the OAuth2 server <code>clientSecret</code> string client secret in the OAuth2 server <code>redirectUri</code> string the url of TheHive AOuth2 page ( <code>xxx/api/ssoLogin</code>) <code>responseType</code> string type of the response. Currently only \"code\" is accepted <code>grantType</code> string type of the grant. Currently only \"authorization_code\" is accepted <code>authorizationUrl</code> string the url of the OAuth2 server <code>tokenUrl</code> string the token url of the OAuth2 server <code>userUrl</code> string the url to get user information in OAuth2 server <code>scope</code> list of string list of scope <code>userIdField</code> string the field that contains the id of the user in user info <code>organisationField</code> string (optional) the field that contains the organisation name in user info <code>defaultOrganisation</code> string (optional) the default organisation used to login if not present on user info <code>authorizationHeader</code> string prefix of the authorization header to get user info: Bearer, token, ... <p>Example</p> KeycloakOktaGithubMicrosoft 365Google <pre><code>  ## Authentication\nauth {\nproviders: [\n{name: session}\n{name: basic, realm: thehive}\n{name: local}\n{name: key}\n{\n        name: oauth2\nclientId: \"CLIENT_ID\"\n        clientSecret: \"CLIENT_SECRET\"\n        redirectUri: \"http://THEHIVE_URL/api/ssoLogin\"\n        responseType: \"code\"\n        grantType: \"authorization_code\"\n        authorizationUrl: \"http://KEYCLOAK/auth/realms/TENANT/protocol/openid-connect/auth\"\n        authorizationHeader: \"Bearer\"\n        tokenUrl: \"http://KEYCLOAK/auth/realms/TENANT/protocol/openid-connect/token\"\n        userUrl: \"http://KEYCLOAK/auth/realms/TENANT/protocol/openid-connect/userinfo\"\n        scope: [\"openid\", \"email\"]\n        userIdField: \"email\"\n}\n]\n}\n</code></pre> <pre><code>  ## Authentication\nauth {\nproviders: [\n{name: session}\n{name: basic, realm: thehive}\n{name: local}\n{name: key}\n{\n        name: oauth2\nclientId: \"CLIENT_ID\"\n        clientSecret: \"CLIENT_SECRET\"\n        redirectUri: \"http://THEHIVE_URL/api/ssoLogin\"\n        responseType: \"code\"\n        grantType: \"authorization_code\"\n        authorizationUrl: \"https://OKTA/oauth2/v1/authorize\"\n        authorizationHeader: \"Bearer\"\n        tokenUrl: \"http://OKTA/oauth2/v1/token\"\n        userUrl: \"http://OKTA/oauth2/v1/userinfo\"\n        scope: [\"openid\", \"email\"]\n        userIdField: \"email\"\n}\n]\n}\n</code></pre> <pre><code>  ## Authentication\nauth {\nproviders: [\n{name: session}\n{name: basic, realm: thehive}\n{name: local}\n{name: key}\n{\n        name: oauth2\nclientId: \"CLIENT_ID\"\n        clientSecret: \"CLIENT_SECRET\"\n        redirectUri: \"http://THEHIVE_URL/api/ssoLogin\"\n        responseType: code\ngrantType: \"authorization_code\"\n        authorizationUrl: \"https://github.com/login/oauth/authorize\"\n        authorizationHeader: \"token\"\n        tokenUrl: \"https://github.com/login/oauth/access_token\"\n        userUrl: \"https://api.github.com/user\"\n        scope: [\"user\"]\n        userIdField: \"email\"\n        #userOrganisation: \"\"\n}\n\n]\n}\n</code></pre> <p>Note</p> <ul> <li><code>CLIENT_ID</code> and <code>CLIENT_SECRET</code> are created in the OAuth Apps section at https://github.com/settings/developers.</li> <li>this configuration requires that users set the Public email in their Public Profile on https://github.com/settings/profile.</li> </ul> <pre><code>  ## Authentication\nauth {\nproviders: [\n{name: session}\n{name: basic, realm: thehive}\n{name: local}\n{name: key}\n{\n        name: oauth2\nclientId: \"CLIENT_ID\"\n        clientSecret: \"CLIENT_SECRET\"\n        redirectUri: \"http://THEHIVE_URL/api/ssoLogin\"\n        responseType: code\ngrantType: \"authorization_code\"\n        authorizationUrl: \"https://login.microsoftonline.com/TENANT/oauth2/v2.0/authorize\"\n        authorizationHeader: \"Bearer \"\n        tokenUrl: \"https://login.microsoftonline.com/TENANT/oauth2/v2.0/token\"\n        userUrl: \"https://graph.microsoft.com/v1.0/me\"\n        scope: [\"User.Read\"]\n        userIdField: \"mail\"\n        #userOrganisation: \"\" ## if not existing in the response, use default organisation\n}\n]\n}\n</code></pre> <p>Note</p> <p>To create <code>CLIENT_ID</code>, <code>CLIENT_SECRET</code> and <code>TENANT</code>, register a new app at https://aad.portal.azure.com/#blade/Microsoft_AAD_IAM/ActiveDirectoryMenuBlade/RegisteredApps.</p> <pre><code>    ## Authentication\nauth {\nproviders: [\n{name: session}\n{name: basic, realm: thehive}\n{name: local}\n{name: key}\n{\n        name: oauth2\nclientId: \"CLIENT_ID\"\n        clientSecret: \"CLIENT_SECRET\"\n        redirectUri: \"http://THEHIVE_URL/api/ssoLogin\"\n        responseType: code\ngrantType: \"authorization_code\"\n        authorizationUrl: \"https://accounts.google.com/o/oauth2/v2/auth\"\n        authorizationHeader: \"Bearer \"\n        tokenUrl: \"https://oauth2.googleapis.com/token\"\n        userUrl: \"https://openidconnect.googleapis.com/v1/userinfo\"\n        scope: [\"email\", \"profile\", \"openid\"]\n        userIdField: \"email\"\n        # userOrganisation: \"\" ## if not existing in the response, use default organisation\n}\n]\n}\n</code></pre> <p>Note</p> <ul> <li><code>CLIENT_ID</code> and <code>CLIENT_SECRET</code> are created in the <code>_APIs &amp; Services_ &gt; _Credentials_</code> section of the GCP Console</li> <li>Instructions on how to create Oauth2 credentials at https://support.google.com/cloud/answer/6158849</li> <li>For the latest reference for Google auth URLs please check Google's .well-known/openid-configuration</li> </ul>"},{"location":"thehive/installation-and-configuration/configuration/authentication/#user-autocreation","title":"User autocreation","text":"<p>To allow users to login without previously creating them, you can enable autocreation by adding <code>user.autoCreateOnSso=true</code> to the top level of your configuration.</p> <p>Example</p> <pre><code>  user.autoCreateOnSso: true\nuser.profileFieldName: profile\nuser.organisationFieldName: organisation\nuser.defaults.profile: analyst\nuser.defaults.organisation: cert\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/authentication/#multi-factor-authentication","title":"Multi-Factor Authentication","text":"<p>Multi-Factor Authentication is enabled by default. This means users can configure their MFA through their User Settings page (top-Right corner button &gt; Settings).</p> <p>User administrators can:</p> <ul> <li>See which users have activated MFA</li> <li>Reset MFA settings of any user</li> </ul> <p>This feature can be <code>**disabled**</code> by setting a config property to <code>false</code>:</p> <p>Example</p> <pre><code>auth.multifactor.enabled = false\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/connectors-cortex/","title":"TheHive connector: Cortex","text":""},{"location":"thehive/installation-and-configuration/configuration/connectors-cortex/#enable-the-connector","title":"Enable the connector","text":"<p>The Cortex connector module needs to be enabled to allow TheHive work with Cortex. Enable the module with this line of configuration: </p> <pre><code>play.modules.enabled += org.thp.thehive.connector.cortex.CortexModule\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/connectors-cortex/#configure-one-connection","title":"Configure one connection","text":"<p>TheHive is able to connect more than one Cortex organisation. Several parameters can be configured for one server :</p> Parameter Type Description <code>name</code> string name given to the Cortex instance (eg: Cortex-Internal) <code>url</code> string url to connect to the Cortex instance <code>auth</code> dict method used to authenticate on the server (bearer if using API keys) <code>wsConfig</code> dict network configuration dedicated to Play Framework for SSL and proxy <code>refreshDelay</code> duration frequency of job updates checks (default: <code>5 seconds</code>) <code>maxRetryOnError</code> integer maximum number of successive errors before give up (default: <code>3</code>) <code>statusCheckInterval</code> duration check remote Cortex status time interval (default: <code>1 minute</code>) <code>includedTheHiveOrganisations</code> list of string list of TheHive organisations which can use this Cortex server (default: all (<code>[*]</code>) <code>excludedTheHiveOrganisations</code> list of string list of TheHive organisations which cannot use this Cortex server (default: None (<code>[]</code>) ) <p>This configuration has to be added to TheHive <code>conf/application.conf</code> file. </p> <pre><code>## Cortex configuration\nplay.modules.enabled += org.thp.thehive.connector.cortex.CortexModule\ncortex {\n  servers = [\n    {\n      name = local\n      url = \"http://localhost:9001\"\n      auth {\n        type = \"bearer\"\n        key = \"[REDACTED]\"\n      }\n      wsConfig {}\n    includedTheHiveOrganisations = [\"*\"]\n    excludedTheHiveOrganisations = []\n    }\n  ]\n  refreshDelay = 5 seconds\n  maxRetryOnError = 3\n  statusCheckInterval = 1 minute\n}\n</code></pre> <p>Note</p> <p>By default, adding a Cortex server in TheHive configuration make it available for all organisations added on the instance.</p> <p>Example</p> 1 servermore servers <p>Configuration with one Cortex connection: </p> <pre><code>## Cortex configuration\nplay.modules.enabled += org.thp.thehive.connector.cortex.CortexModule\ncortex {\nservers = [\n{\nname = Cortex\nurl = \"http://cortex1:9001\"\nauth {\ntype = \"bearer\"\nkey = \"tkjjyfsdgrKuPttaaasdDWSEzClKuPt\"\n}\nwsConfig {\nproxy {\nhost: \"10.1.2.10\"\nport: 8080\n}\n}\nincludedTheHiveOrganisations = [\"ORG1\", \"ORG2\"]\nexcludedTheHiveOrganisations = []\n}\n]\nrefreshDelay = 5 seconds\nmaxRetryOnError = 3\nstatusCheckInterval = 1 minute\n}\n</code></pre> <p>Configuration with 2 Cortex connections: </p> <pre><code>## Cortex configuration\nplay.modules.enabled += org.thp.thehive.connector.cortex.CortexModule\ncortex {\nservers = [\n{\nname = Cortex1\nurl = \"http://cortex1:9001\"\nauth {\ntype = \"bearer\"\nkey = \"tkjjyfsdgrKuPttaaasdDWSEzClKuPt\"\n}\nwsConfig {}\nincludedTheHiveOrganisations = [\"ORG1\", \"ORG2\"]\nexcludedTheHiveOrganisations = []\n}\n{\nname = Cortex2\nurl = \"http://cortex2:9001\"\nauth {\ntype = \"bearer\"\nkey = \"lSDkjDGGGHtipueroBHOroNJKLbpi\"\n}\nwsConfig {\nproxy {\nhost: \"10.1.2.10\"\nport: 8080\n}\n}\nincludedTheHiveOrganisations = [\"ORG2\", \"ORG3\"]\nexcludedTheHiveOrganisations = [\"ORG1\"]\n}\n]\nrefreshDelay = 5 seconds\nmaxRetryOnError = 3\nstatusCheckInterval = 5 minutes\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/connectors-misp/","title":"TheHive connector: MISP","text":""},{"location":"thehive/installation-and-configuration/configuration/connectors-misp/#enable-misp-connector","title":"Enable MISP connector","text":"<p>The MISP connector module needs to be enabled to allow TheHive to interact with MISP. Enable the module with this line of configuration: </p> <pre><code>play.modules.enabled += org.thp.thehive.connector.misp.MispModule\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/connectors-misp/#configuration","title":"Configuration","text":"<p>TheHive is able to connect to more than one MISP server for pulling, pushing or both.</p> <p>Several parameters can be configured for one server :</p> Parameter Type Description <code>interval</code> duration delay between to pull/push events to remote MISP servers. This is a common parameter for all configured server <code>name</code> string name given to the MISP instance (eg: <code>MISP-MyOrg</code>) <code>url</code> string url to connect to the MISP instance <code>auth</code> dict method used to authenticate on the server (key if using API keys) <code>purpose</code> string define the purpose of the server MISP: <code>ImportOnly</code>, <code>ExportOnly</code> or <code>ImportAndExport</code> (default: <code>ImportAndExport</code>) <code>wsConfig</code> dict network configuration dedicated to Play Framework for SSL and proxy <code>caseTemplate</code> string case template used by default in TheHive to import events as Alerts <code>tags</code> list of string tags to be added to events imported as Alerts in TheHive <code>exportCaseTags</code> boolean indicate if the tags of the case should be exported to MISP event (default: false) <p>Optional parameters can be added to filter out some events coming into TheHive:</p> Parameter Type Description <code>exclusion.organisations</code> list of string list of MISP organisation from which event will not be imported <code>exclusion.tags</code> list of string don't import MISP events which have one of these tags <code>whitelist.organisations</code> list of string import only events from these MISP organisations <code>whitelist.tags</code> list of string import only MISP events which have one of these tags <code>max-age</code> duration maximum age of the last publish date of event to be imported in TheHive <code>includedTheHiveOrganisations</code> list of string list of TheHive organisations which can use this MISP server (default: all (<code>[*]</code>) <code>excludedTheHiveOrganisations</code> list of string list of TheHive organisations which cannot use this MISP server (default: None (<code>[]</code>) ) <p>Additionally, some organisations or tags from MISP can be defined to exclude events. </p> <p>Note</p> <p>By default, adding a MISP server in TheHive configuration make it available for all organisations added on the instance.</p> <p>This configuration has to be added to TheHive <code>conf/application.conf</code> file:</p> <pre><code>## MISP configuration\n# More information at https://github.com/TheHive-Project/TheHiveDocs/TheHive4/Administration/Connectors.md\n# Enable MISP connector\nplay.modules.enabled += org.thp.thehive.connector.misp.MispModule\nmisp {\ninterval: 1 hour\nservers: [\n{\nname = \"local\"            url = \"http://localhost/\" auth {\ntype = key\nkey = \"***\"\n}\nwsConfig {}\ncaseTemplate = \"&lt;Template_Name_goes_here&gt;\"      tags = [\"misp-server-id\"]\nmax-age = 7 days\nexclusion {\norganisations = [\"bad organisation\", \"other orga\"]\ntags = [\"tag1\", \"tag2\"]\n}\nwhitelist {\ntags = [\"tag1\", \"tag2\"]\n}\nincludedTheHiveOrganisations = [\"*\"]\nexcludedTheHiveOrganisations = []\n}\n]\n} </code></pre> <p>Example</p> <p>Connection with 1 MISP server:</p> <pre><code>## MISP configuration\n# More information at https://github.com/TheHive-Project/TheHiveDocs/TheHive4/Administration/Connectors.md\n# Enable MISP connector\nplay.modules.enabled += org.thp.thehive.connector.misp.MispModule\nmisp {\ninterval: 1 hour\nservers: [\n{\nname = \"MISP Server\"     url = \"https://misp.server\"\nauth {\ntype = key\nkey = \"XhtropikjthiuGIORWUHHlLhlfeerljta\"\n}\nwsConfig {\nproxy {\n          host: \"10.1.2.10\"\n          port: 8080\n}\n}\ntags = [\"tag1\", \"tag2\", \"tag3\"]\ncaseTemplate = \"misp\"\nincludedTheHiveOrganisations = [\"ORG1\", \"ORG2\" ]\n}\n]\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/database/","title":"Database and index configuration","text":"<p>TheHive can be configured to connect to local Berkeley database or Cassandra database. </p> <p>Tip</p> <p>Using Cassandra is strongly recommended for production use while Berkeley DB can be prefered for testing and training purpose.</p> <p>Starting with TheHive 4.1.0, indexes are managed by a dedicated engine. </p> <p>According to the setup, the instance can use:</p> <ul> <li>A local engine, Lucene driven by TheHive</li> <li>A centralised engine, Elasticsearch.</li> </ul>"},{"location":"thehive/installation-and-configuration/configuration/database/#configuation","title":"Configuation","text":"<p>A typical database configuration for TheHive looks like this:</p> <pre><code>## Database configuration\ndb {\n  provider: janusgraph\n  janusgraph {\n    ## Storage configuration\n    storage {\n      backend: cql\n      hostname: [\"IP_ADDRESS\"]\n      cql {\n        cluster-name: thp\n        keyspace: thehive\n      }\n    }\n    ## Index configuration\n    index {\n      search {\n        backend : lucene\n        directory:  /path/to/index/folder\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/database/#list-of-possible-parameters","title":"List of possible parameters","text":"Parameter Type Description <code>provider</code> string provider name. Default: <code>janusgraph</code> <code>storage</code> dict storage configuration <code>storage.backend</code> string storage type. Can be <code>cql</code> or <code>berkeleyje</code> <code>storage.hostname</code> list of string list of IP addresses or hostnames when using <code>cql</code> backend <code>storage.directory</code> string local path for data when using <code>berkeleyje</code> backend <code>storage.username</code> string account username with <code>cql</code> backend if Cassandra auth is configured <code>storage.password</code> string account password with <code>cql</code> backend if Cassandra auth is configured <code>storage.port</code> integer port number with <code>cql</code> backend (<code>9042</code> by default). Change this if using an alternate port or a dedicated port number when using SSL with Cassandra <code>storage.cql</code> dict configuration for <code>cql</code> backend if used <code>storage.cql.cluster-name</code> string name of the cluster name used in the configuration of Apache Cassandra <code>storage.cql.keyspace</code> string Keyspace name used to store TheHive data in Apache Cassandra <code>storage.cql.ssl.enabled</code> boolean <code>false</code> by default. set it to <code>true</code> if SSL is used with Cassandra <code>storage.cql.ssl.truststore.location</code> string path the the truststore. Specify it when using SSL with Cassandra <code>storage.cql.ssl.password</code> string password to access the truststore <code>storage.cql.ssl.client-authentication-enabled</code> boolean Enables use of a client key to authenticate with Cassandra <code>storage.cql.ssl.keystore.location</code> string path the the keystore. Specify it when using SSL and client auth. with Cassandra <code>storage.cql.ssl.keystore.keypassword</code> string password to access the key in the keystore <code>storage.cql.ssl.truststore.storepassword</code> string password the access the keystore <code>index.search</code> dict configuration for indexes <code>index.search.backend</code> string index engine. Default: <code>lucene</code> provided with TheHive. Can also be <code>elasticsearch</code> <code>index.search.directory</code> string path to folder where indexes should be stored, when using <code>lucene</code> engine <code>index.search.hostname</code> list of string list of IP addresses or hostnames when using <code>elasticsearch</code> engine <code>index.search.index-name</code> string name of index, when using <code>elasticseach</code> engine <code>index.search.elasticsearch.http.auth.type: basic</code> string <code>basic</code> is the only possible value <code>index.search.elasticsearch.http.auth.basic.username</code> string Username account on Elasticsearch <code>index.search.elasticsearch.http.auth.basic.password</code> string Password of the account on Elasticsearch <code>index.search.elasticsearch.ssl.enabled</code> boolean Enable SSL <code>true/false</code> <code>index.search.elasticsearch.ssl.truststore.location</code> string Location of the truststore <code>index.search.elasticsearch.ssl.truststore.password</code> string Password of the truststore <code>index.search.elasticsearch.ssl.keystore.location</code> string Location of the keystore for client authentication <code>index.search.elasticsearch.ssl.keystore.storepassword</code> string Password of the keystore <code>index.search.elasticsearch.ssl.keystore.keypassword</code> string Password of the client certificate <code>index.search.elasticsearch.ssl.disable-hostname-verification</code> boolean Disable SSL verification <code>true/false</code> <code>index.search.elasticsearch.ssl.allow-self-signed-certificates</code> boolean Allow self signe certificates <code>true/false</code> <p>Warning</p> <ul> <li>Using Elasticsearch to manage indexes is required if you are setting up TheHive as a cluster.</li> <li>The initial start, or first start after configuring indexes might take some time if the database contains a large amount of data. This time is due to the indexes creation</li> </ul> <p>More information on configuration for Elasticsearch connection: https://docs.janusgraph.org/index-backend/elasticsearch/.</p>"},{"location":"thehive/installation-and-configuration/configuration/database/#use-cases","title":"Use cases","text":"<p>Database and index engine can be different, depending on the use case and target setup:</p> <p>Example</p> Testing serverStandalone server with CassandraCluster with Cassandra &amp; Elasticsearch  <p>For such use cases, local database and indexes are adequate:</p> <ol> <li> <p>Create a dedicated folder for data and for indexes. These folders should belong to the user <code>thehive:thehive</code>.</p> <pre><code>mkdir /opt/thp/thehive/{data, index}\nchown -R thehive:thehive /opt/thp/thehive/{data, index}\n</code></pre> </li> <li> <p>Configure TheHive accordingly: </p> <pre><code>## Database Configuration\ndb {\n  provider: janusgraph\n  janusgraph {\n    ## Storage configuration\n    storage {\n      backend: berkeleyje\n      directory: /opt/thp/thehive/database\n    }\n    ## Index configuration\n    index {\n      search {\n        backend: lucene\n        directory: /opt/thp/thehive/index\n      }\n    }\n  }\n}\n</code></pre> </li> </ol> <ol> <li>Install a Cassandra server locally</li> <li>Create a dedicated folder for indexes. This folder should belong to the user <code>thehive:thehive</code></li> </ol> <pre><code>  mkdir /opt/thp/thehive/index\n  chown -R thehive:thehive /opt/thp/thehive/index\n</code></pre> <ol> <li> <p>Configure TheHive accordingly </p> <pre><code>## Database Configuration\ndb {\n  provider: janusgraph\n  janusgraph {\n    ## Storage configuration\n    storage {\n      backend: cql\n      hostname: [\"127.0.0.1\"]\n      ## Cassandra authentication (if configured)\n      username: \"thehive_account\"\n      password: \"cassandra_password\"\n      cql {\n        cluster-name: thp\n        keyspace: thehive\n      }\n    }\n    ## Index configuration\n    index {\n      search {\n        backend: lucene\n        directory: /opt/thp/thehive/index\n      }\n    }\n  }\n}\n</code></pre> </li> </ol> <ol> <li>Install a cluster of Cassandra servers</li> <li>Get access to an Elasticsearch server</li> <li> <p>Configure TheHive accordingly</p> <pre><code>## Database Configuration\ndb {\n  provider: janusgraph\n  janusgraph {\n    ## Storage configuration\n    storage {\n      backend: cql\n      hostname: [\"10.1.2.1\", \"10.1.2.2\", \"10.1.2.3\"]\n      ## Cassandra authentication (if configured)\n      username: \"thehive_account\"\n      password: \"cassandra_password\"\n      cql {\n        cluster-name: thp\n        keyspace: thehive\n      }\n    }\n    ## Index configuration\n    index {\n      search {\n        backend : elasticsearch\n        hostname : [\"10.1.2.5\"]\n        index-name : thehive\n        elasticsearch {\n          http {\n            auth {\n              type: basic\n              basic {\n                username: httpuser\n                password: httppassword\n              }\n            }\n          }\n          ssl {\n            enabled: true\n            truststore {\n              location: /path/to/your/truststore.jks\n              password: truststorepwd\n            }\n          }\n        }\n      }\n    }\n  }\n}                \n</code></pre> </li> </ol> <p>Warning</p> <p>In this configuration, all TheHive nodes should have the same configuration.</p> <p>Elasticsearch configuration should use the default value for <code>script.allowed_types</code>, or contain the following configuration line: </p> <pre><code>script.allowed_types: inline,stored\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/file-storage/","title":"File storage configuration","text":"<p>TheHive can be configured to use local or distributed filesystems. </p> <p>Example</p> Local or NFSMin.IOApache Hadoop <ol> <li> <p>Create dedicated folder ; it should belong to user and group <code>thehive:thehive</code>.</p> <pre><code>mkdir /opt/thp/thehive/files\nchown thehive:thehive /opt/thp/thehive/files\n</code></pre> </li> <li> <p>Configure TheHive accordingly:</p> <pre><code>## Attachment storage configuration\nstorage {\n## Local filesystem\nprovider: localfs\nlocalfs {\nlocation: /opt/thp/thehive/files\n}\n}\n</code></pre> </li> </ol> <ol> <li> <p>Install a Min.IO cluster</p> </li> <li> <p>Configure each node of TheHive accordingly: </p> <pre><code>## Attachment storage configuration\nstorage {\nprovider: s3\ns3 {\nbucket = \"thehive\"\nreadTimeout = 1 minute\nwriteTimeout = 1 minute\nchunkSize = 1 MB\nendpoint = \"http://10.1.2.4:9100\"\naccessKey = \"thehive\"\nsecretKey = \"minio_password\"\nregion = \"us-east-1\"\n}\n}\n\nalpakka.s3.path-style-access = force\n</code></pre> <p><code>us-east-1</code> is the default region if none has been specified in MinIO configuration. In this case, this parameter is optional.</p> </li> </ol> <ol> <li> <p>Install an Apache Hadoop server</p> </li> <li> <p>Configure each node of TheHive accordingly (<code>/etc/thehive/application.conf</code>): </p> <pre><code>## Attachment storage configuration\n## Hadoop filesystem (HDFS)\nprovider: hdfs\nhdfs {\nroot: \"hdfs://10.1.2.4:10000\" # namenode server hostname\nlocation: \"/thehive\"           # location inside HDFS\nusername: thehive              # file owner\n}\n}   </code></pre> </li> </ol>"},{"location":"thehive/installation-and-configuration/configuration/manage-configuration/","title":"Manage configuration files","text":"<p>TheHive uses HOCON as configuration file format.  This format gives enough flexibility to structure and organise the configuration of TheHive.</p> <p>TheHive is delivered with following files, in the folder <code>/etc/thehive</code> : </p> <ul> <li><code>logback.xml</code> containing the log policy</li> <li><code>secret.conf</code> containing a secret key used to create sessions. This key should be unique per instance (in the case of a cluster, this key should be the same for all nodes of this cluster)</li> <li><code>application.conf</code></li> </ul> <p>HOCON file format let you organise the configuration to have separate files for each purpose. It is the possible to create a <code>/etc/thehive/application.conf.d</code> folder and have several files inside that will be included in the main file <code>/etc/thehive/application.conf</code>. </p> <p>At the end, the following configuration structure is possible: </p> <pre><code>/etc/thehive\n|-- application.conf\n|-- application.conf.d\n|   |-- secret.conf\n|   |-- service.conf\n|   |-- ssl.conf\n|   |-- proxy.conf\n|   |-- database.conf\n|   |-- storage.conf\n|   |-- cluster.conf\n|   |-- authentication.conf\n|   |-- cortex.conf\n|   |-- misp.conf\n|   `-- webhooks.conf\n`-- logback.xml\n</code></pre> <p>And the content of <code>/etc/thehive/application.conf</code>: </p> <pre><code>###\n## Documentation is available at https://docs.thehive-project.org\n###\n\n## Include Play secret key\n# More information on secret key at https://www.playframework.com/documentation/2.8.x/ApplicationSecret\ninclude \"/etc/thehive/application.conf.d/secret.conf\"\n\n## Service\ninclude \"/etc/thehive/application.conf.d/service.conf\"\n\n## SSL settings\ninclude \"/etc/thehive/application.conf.d/ssl.conf\"\n\n## PROXY settings\ninclude \"/etc/thehive/application.conf.d/proxy.conf\"\n\n## Database\ninclude \"/etc/thehive/application.conf.d/database.conf\"\n\n## Storage\ninclude \"/etc/thehive/application.conf.d/storage.conf\"\n\n## Cluster\ninclude \"/etc/thehive/application.conf.d/cluster.conf\"\n\n## Authentication\ninclude \"/etc/thehive/application.conf.d/authentication.conf\"\n\n## Cortex\ninclude \"/etc/thehive/application.conf.d/cortex.conf\"\n\n## MISP\ninclude \"/etc/thehive/application.conf.d/misp.conf\"\n\n## Webhooks\ninclude \"/etc/thehive/application.conf.d/webhooks.conf\"\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/proxy/","title":"Proxy settings","text":""},{"location":"thehive/installation-and-configuration/configuration/proxy/#proxy-for-connectors","title":"Proxy for connectors","text":"<p>Refer to Cortex or MISP configuration to setup specific proxy configuration for these remote services. </p>"},{"location":"thehive/installation-and-configuration/configuration/proxy/#proxy-for-global-application","title":"Proxy for global application","text":"<p>Proxy can be used. By default, the proxy configured in JVM is used but one can configured specific configurations for each HTTP client.</p> Parameter Type Description <code>wsConfig.proxy.host</code> string The hostname of the proxy server <code>wsConfig.proxy.port</code> integer The port of the proxy server <code>wsConfig.proxy.protocol</code> string The protocol of the proxy server.  Use \"http\" or \"https\".  Defaults to \"http\" if not specified <code>wsConfig.proxy.user</code> string The username of the credentials for the proxy server <code>wsConfig.proxy.password</code> string The password for the credentials for the proxy server <code>wsConfig.proxy.ntlmDomain</code> string The NTLM domain <code>wsConfig.proxy.encoding</code> string The realm's charset <code>wsConfig.proxy.nonProxyHosts</code> list The list of hosts on which proxy must not be used"},{"location":"thehive/installation-and-configuration/configuration/secret/","title":"<code>secret.conf</code> file","text":"<p>This file contains a secret that is used to define cookies used to manage the users session. As a result, one instance of TheHive should use a unique secret key. </p> <p>Example</p> <pre><code>## Play secret key\nplay.http.secret.key=\"dgngu325mbnbc39cxas4l5kb24503836y2vsvsg465989fbsvop9d09ds6df6\"\n</code></pre> <p>Warning</p> <p>In the case of a cluster of TheHive nodes, all nodes should have the same <code>secret.conf</code> file with the same secret key. The secret is used to generate user sessions.</p>"},{"location":"thehive/installation-and-configuration/configuration/service/","title":"Service","text":""},{"location":"thehive/installation-and-configuration/configuration/service/#listen-address-port","title":"Listen address &amp; port","text":"<p>By default the application listens on all interfaces and port <code>9000</code>.  This is possible to specify listen address and ports with following parameters in the <code>application.conf</code> file: </p> <pre><code>http.address=127.0.0.1\nhttp.port=9000\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/service/#context","title":"Context","text":"<p>If you are using a reverse proxy, and you want to specify a location (ex: <code>/thehive</code>), updating the configuration of TheHive is also required</p> <p>Example</p> <pre><code>play.http.context: \"/thehive\"\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/service/#specific-configuration-for-streams","title":"Specific configuration for streams","text":"<p>If you are using a reverse proxy like Nginx, you might receive error popups with the following message: StreamSrv 504 Gateway Time-Out. </p> <p>You need to change default setting for long polling refresh,  Set <code>stream.longPolling.refresh</code> accordingly.</p> <p>Example</p> <pre><code>stream.longPolling.refresh: 45 seconds\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/service/#manage-content-length","title":"Manage content length","text":"<p>Content length of text and files managed by the application are limited by default. </p> <p>Before TheHive v4.1.1, the Play framework sets the HTTP body size limit to 100KB by default for textual content (json, xml, text, form data) and 10MB for file uploads.</p> <p>Since TheHive v4.1.1, these values are set with default parameters: </p> <pre><code># Max file size\nplay.http.parser.maxDiskBuffer: 128MB\n# Max textual content length\nplay.http.parser.maxMemoryBuffer: 256kB\n</code></pre> <p>If you feel that these should be updated, edit <code>/etc/thehive/application.conf</code> file and update these parameters accordingly. </p> <p>Tip</p> <p>if you are using a NGINX reverse proxy in front of TheHive, be aware that it doesn't distinguish between text data and a file upload. </p> <p>So, you should also set the <code>client_max_body_size</code> parameter in your NGINX server configuration to the highest value among the two: file upload and text size defined in TheHive application.conf file.</p>"},{"location":"thehive/installation-and-configuration/configuration/ssl/","title":"SSL","text":""},{"location":"thehive/installation-and-configuration/configuration/ssl/#server-configuration","title":"Server configuration","text":"<p>We recommend using a reverse proxy to manage SSL layer.</p>"},{"location":"thehive/installation-and-configuration/configuration/ssl/#connectors","title":"Connectors","text":"<p>Refer to Cortex or MISP configuration to setup specific SSL configuration of these remote services. </p>"},{"location":"thehive/installation-and-configuration/configuration/ssl/#client-configuration","title":"Client configuration","text":"<p>SSL configuration might be requis required to connect remote services. Following parameters can be defined: </p> Parameter Type Description <code>wsConfig.ssl.keyManager.stores</code> list Stores client certificates (see #certificate-manager ) <code>wsConfig.ssl.trustManager.stores</code> list Stored custom Certificate Authorities (see #certificate-manager <code>wsConfig.ssl.protocol</code> string Defines a different default protocol (see #protocols) <code>wsConfig.ssl.enabledProtocols</code> list List of enabled protocols (see #protocols) <code>wsConfig.ssl.enabledCipherSuites</code> list List of enabled cipher suites (see #ciphers) <code>wsConfig.ssl.loose.acceptAnyCertificate</code> boolean Accept any certificates true / false"},{"location":"thehive/installation-and-configuration/configuration/ssl/#certificate-manager","title":"Certificate manager","text":"<p>Certificate manager is used to store client certificates and certificate authorities.</p>"},{"location":"thehive/installation-and-configuration/configuration/ssl/#custom-certificate-authority","title":"Custom Certificate Authority","text":""},{"location":"thehive/installation-and-configuration/configuration/ssl/#global-configuration","title":"Global configuration","text":"<p>If setting up a custom Certificate Authority (to connect web proxies, remote services ...) is required globally in the application, the better solution consists of installing it on the OS and restarting TheHive. </p> Debian <pre><code>apt-get install -y ca-certificates-java\nmkdir /usr/share/ca-certificates/extra\ncp mysctomcert.crt /usr/share/ca-certificates/extra\ndpkg-reconfigure ca-certificates\nservice thehive restart\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/ssl/#use-dedicated-trust-stores","title":"Use dedicated trust stores","text":"<p>the other way, is to use the <code>trustManager</code> key in TheHive configuration. It is used to establish a secure connection with remote host. Server certificate must be signed by a trusted certificate authority. <pre><code>  wsConfig.ssl.trustManager {\n    stores = [\n      {\n        type: \"JKS\" // JKS or PEM\n        path: \"keystore.jks\"\n        password: \"password1\"\n      }\n    ]\n  }\n</code></pre></p>"},{"location":"thehive/installation-and-configuration/configuration/ssl/#client-certificates","title":"Client certificates","text":"<p><code>keyManager</code> indicates which certificate HTTP client can use to authenticate itself on remote host (when certificate based authentication is used) <pre><code>  wsConfig.ssl.keyManager {\n    stores = [\n      {\n        type: \"pkcs12\" // JKS or PEM\n        path: \"mycert.p12\"\n        password: \"password1\"\n      }\n    ]\n  }\n</code></pre></p>"},{"location":"thehive/installation-and-configuration/configuration/ssl/#protocols","title":"Protocols","text":"<p>If you want to define a different default protocol, you can set it specifically in the client: <pre><code>wsConfig.ssl.protocol = \"TLSv1.2\"\n</code></pre> If you want to define the list of enabled protocols, you can do so explicitly: <pre><code>wsConfig.ssl.enabledProtocols = [\"TLSv1.2\", \"TLSv1.1\", \"TLSv1\"]\n</code></pre></p>"},{"location":"thehive/installation-and-configuration/configuration/ssl/#ciphers","title":"Ciphers","text":"<p>Cipher suites can be configured using <code>wsConfig.ssl.enabledCipherSuites</code>:</p> <pre><code>wsConfig.ssl.enabledCipherSuites = [\n  \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\",\n  \"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n  \"TLS_DHE_RSA_WITH_AES_256_GCM_SHA384\",\n  \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n]\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/ssl/#debugging","title":"Debugging","text":"<p>To debug the key manager / trust manager, set the following flags: <pre><code>  wsConfig.ssl.debug = {\n    ssl = true\n    trustmanager = true\n    keymanager = true\n    sslctx = true\n    handshake = true\n    verbose = true\n    data = true\n    certpath = true\n  }\n</code></pre></p>"},{"location":"thehive/installation-and-configuration/configuration/webhooks/","title":"TheHive webhooks","text":"<p>TheHive can notify external system of modification events (case creation, alert update, task assignment, ...). To use webhooks notifications, 2 steps are required: configure a notification, and activate it.</p>"},{"location":"thehive/installation-and-configuration/configuration/webhooks/#1-define-webhook-endpoints","title":"1. Define webhook endpoints","text":"<p>The configuration can accept following parameters:</p> Parameter Type Description <code>name</code> string the identifier of the endpoint. It is used when the webhook is setup for an organisation <code>version</code> integer defines the format of the message. If <code>version</code> is <code>0</code>, TheHive will send messages with the same format as TheHive3. Currently TheHive only supports version 0. <code>wsConfig</code> dict the configuration of HTTP client. It contains proxy, SSL and timeout configuration. <code>auth</code> dict the configuration of authenticationI. It contains type, and additional options. <code>includedTheHiveOrganisations</code> list of string list of TheHive organisations which can use this endpoint (default: all (<code>[*]</code>) <code>excludedTheHiveOrganisations</code> list of string list of TheHive organisations which cannot use this endpoint (default: None (<code>[]</code>) ) <p>The following section should be added in <code>application.conf</code> : </p> <pre><code>## Webhook notification\nnotification.webhook.endpoints = [\n{\nname: local\nurl: \"http://127.0.0.1:5000/\"\nversion: 0\nwsConfig: {}\nauth: {type: \"none\"}\nincludedTheHiveOrganisations: [\"*\"]\nexcludedTheHiveOrganisations: []\n}\n]\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/webhooks/#use-a-proxy","title":"Use a proxy","text":"<p>Wehbook call can go through a proxy, in which case, Webhooks configuration requires a <code>wsConfig</code> config</p> <pre><code>notification.webhook.endpoints = [\n{\nname: local\nurl: \"http://127.0.0.1:5000/\"\nversion: 0\nwsConfig {\nproxy {\nhost: \"10.1.2.10\"\nport: 8080\n}\n}\nauth: {\n      type: \"none\"\n}\nincludedTheHiveOrganisations: [\"*\"]\nexcludedTheHiveOrganisations: []\n}\n]"},{"location":"thehive/installation-and-configuration/configuration/webhooks/#use-an-authentication-method","title":"Use an authentication method","text":"<p>Webhook endpoints can be authenticated, in this case, Webhook configuration requires a <code>auth</code> setting. Supported methods are:</p>\nNo Auth (Default)Basic AuthBeared AuthKey Auth\n<pre><code>  auth: {       type: \"none\" }\n</code></pre>\n<pre><code>  auth: {       type: \"basic\",       username: \"foo\",       password: \"bar\" }\n</code></pre>\n<pre><code>  auth: {       type: \"bearer\",       key: \"foobar\" }\n</code></pre>\n<pre><code>  auth: {       type: \"key\",       key: \"foobar\" }\n</code></pre>\n<p>Warning</p>\n<p>In 4.1.0 release, the <code>auth</code> config is REQUIRED.</p>"},{"location":"thehive/installation-and-configuration/configuration/webhooks/#examples","title":"Examples","text":"<p>Example</p>\n<pre><code>## Webhook notification\nnotification.webhook.endpoints = [\n{\nname: local\nurl: \"http://127.0.0.1:5000/\"\nversion: 0\nwsConfig {\nproxy {\nhost: \"10.1.2.10\"\nport: 8080\n}\n}\nauth: {\n      type: \"bearer\",\n      key: \"API_KEY\"\n}\nincludedTheHiveOrganisations: [\"ORG1\", \"ORG2\"]\nexcludedTheHiveOrganisations: [\"ORG3\"]\n}\n]\n</code></pre>"},{"location":"thehive/installation-and-configuration/configuration/webhooks/#2-activate-webhooks","title":"2. Activate webhooks","text":"<p>This action must be done by an organisation admin (with permission <code>manageConfig</code>) and requires to run a <code>curl</code> command:</p>\n<pre><code>read -p 'Enter the URL of TheHive: ' thehive_url\nread -p 'Enter your login: ' thehive_user\nread -s -p 'Enter your password: ' thehive_password\n\ncurl -XPUT -u$thehive_user:$thehive_password -H 'Content-type: application/json' $thehive_url/api/config/organisation/notification -d '\n{\n  \"value\": [\n    {\n      \"delegate\": false,\n      \"trigger\": { \"name\": \"AnyEvent\"},\n      \"notifier\": { \"name\": \"webhook\", \"endpoint\": \"local\" }\n    }\n  ]\n}'\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/build-sources/","title":"Build sources","text":""},{"location":"thehive/installation-and-configuration/installation/build-sources/#installing-and-running-from-sources","title":"Installing and running from sources","text":""},{"location":"thehive/installation-and-configuration/installation/build-sources/#dependencies","title":"Dependencies","text":""},{"location":"thehive/installation-and-configuration/installation/build-sources/#system-packages","title":"System packages","text":"<pre><code>apt-get install apt-transport-https\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/build-sources/#npm","title":"NPM","text":"<pre><code>curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.0/install.sh | bash\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/build-sources/#bower-and-grunt","title":"Bower and Grunt","text":"<pre><code>nvm install --lts\nnpm install -g bower grunt\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/build-sources/#build","title":"Build","text":"<ul> <li>The backend</li> </ul> <pre><code>cd /opt\ngit clone https://github.com/TheHive-Project/TheHive.git\ncd TheHive\ngit checkout scalligraph\ngit submodule init\ngit submodule update\n./sbt stage\n</code></pre> <ul> <li>The UI</li> </ul> <pre><code>cd /opt/TheHive/frontend\nnpm install\nbower install\ngrunt build\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/hadoop/","title":"Hadoop: installation and configuration","text":"<p>This guide proposes an example of installation and configuration of Apache Hadoop.</p>"},{"location":"thehive/installation-and-configuration/installation/hadoop/#installation","title":"Installation","text":"<ul> <li>Download hadoop distribution from https://hadoop.apache.org/releases.html and uncompress.</li> </ul> <pre><code>cd /tmp\nwget https://downloads.apache.org/hadoop/common/hadoop-3.1.3/hadoop-3.1.3.tar.gz\ncd /opt\ntar zxf /tmp/hadoop-3.1.3.tar.gz\nln -s hadoop-3.1.3 hadoop\n</code></pre> <ul> <li>Create a user and update permissions</li> </ul> <pre><code>useradd hadoop\nchown hadoop:root -R /opt/hadoop*\n</code></pre> <ul> <li>Create a datastore and set permissions</li> </ul> <pre><code>mkdir /opt/thp/thehive/hdfs\nchown hadoop:root -R /opt/thp/thehive/hdfs\n</code></pre> <ul> <li>Create ssh keys for <code>hadoop</code> user:</li> </ul> <pre><code>su - hadoop\nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa\ncat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys\nchmod 0600 ~/.ssh/authorized_keys\n</code></pre> <ul> <li>Update <code>.bashrc</code>file for <code>hadoop</code> user. Add following lines:</li> </ul> <pre><code>export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\nexport HADOOP_HOME=/opt/hadoop\nexport PATH=$PATH:$HADOOP_HOME/bin\nexport PATH=$PATH:$HADOOP_HOME/sbin\nexport HADOOP_MAPRED_HOME=$HADOOP_HOME\nexport HADOOP_COMMON_HOME=$HADOOP_HOME\nexport HADOOP_HDFS_HOME=$HADOOP_HOME\nexport YARN_HOME=$HADOOP_HOME\n</code></pre> <p>Note: Apache has a well detailed documentation for more advanced configuration with Hadoop.</p>"},{"location":"thehive/installation-and-configuration/installation/hadoop/#configuration-the-hadoop-master","title":"Configuration the Hadoop Master","text":"<p>Configuration files are located in <code>etc/hadoop</code> (<code>/opt/hadoop/etc/hadoop</code>). They must be identical in all nodes.</p> <p>Notes:</p> <ul> <li>The configuration described there is for a single node server. This node is the master node, namenode and datanode (refer to Hadoop documentation for more information). After validating this node is running successfully, refer to the related guide to add nodes;</li> <li> <p>Ensure you update the port value to something different than <code>9000</code> as it is already reserved for TheHive application service;</p> </li> <li> <p>Edit the file <code>core-site.xml</code>:</p> </li> </ul> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;\n&lt;configuration&gt;\n&lt;property&gt;\n&lt;name&gt;fs.defaultFS&lt;/name&gt;\n&lt;value&gt;hdfs://thehive1:10000&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n&lt;value&gt;/opt/thp/thehive/hdfs/temp&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n&lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.best-effort&lt;/name&gt;\n&lt;value&gt;true&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <ul> <li>Edit the file <code>hdfs-site.xml</code></li> </ul> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;\n&lt;configuration&gt;\n&lt;property&gt;\n&lt;name&gt;dfs.replication&lt;/name&gt;\n&lt;value&gt;2&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n&lt;value&gt;/opt/thp/thehive/hdfs/namenode/data&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n&lt;name&gt;dfs.datanode.name.dir&lt;/name&gt;\n&lt;value&gt;/opt/thp/thehive/hdfs/datanode/data&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n&lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt;\n&lt;value&gt;/opt/thp/thehive/hdfs/checkpoint&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n&lt;name&gt;dfs.namenode.http-address&lt;/name&gt;\n&lt;value&gt;0.0.0.0:9870&lt;/value&gt;\n&lt;/property&gt;\n&lt;!--\n  &lt;property&gt;\n    &lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.best-effort&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n  &lt;/property&gt;\n--&gt;\n&lt;property&gt;\n&lt;name&gt;dfs.client.block.write.replace-datanode-on-failure.policy&lt;/name&gt;\n&lt;value&gt;NEVER&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/hadoop/#format-the-volume-and-start-services","title":"Format the volume and start services","text":"<ul> <li>Format  the volume</li> </ul> <pre><code>su - hadoop\ncd /opt/hadoop\nbin/hdfs namenode -format\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/hadoop/#run-it-as-a-service","title":"Run it as a service","text":"<p>Create the <code>/etc/systemd/system/hadoop.service</code> file with the following content:</p> <pre><code>[Unit]\nDescription=Hadoop\nDocumentation=https://hadoop.apache.org/docs/current/index.html\nWants=network-online.target\nAfter=network-online.target\n\n[Service]\nWorkingDirectory=/opt/hadoop\nType=forking\n\nUser=hadoop\nGroup=hadoop\nEnvironment=JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\nEnvironment=HADOOP_HOME=/opt/hadoop\nEnvironment=YARN_HOME=/opt/hadoop\nEnvironment=HADOOP_COMMON_HOME=/opt/hadoop\nEnvironment=HADOOP_HDFS_HOME=/opt/hadoop\nEnvironment=HADOOP_MAPRED_HOME=/opt/hadoop\nRestart=on-failure\n\nTimeoutStartSec=2min\n\n\nExecStart=/opt/hadoop/sbin/start-all.sh\nExecStop=/opt/hadoop/sbin/stop-all.sh\n\nStandardOutput=null\nStandardError=null\n\n# Specifies the maximum file descriptor number that can be opened by this process\nLimitNOFILE=65536\n\n# Disable timeout logic and wait until process is stopped\nTimeoutStopSec=0\n\n# SIGTERM signal is used to stop the Java process\nKillSignal=SIGTERM\n\n# Java process is never killed\nSendSIGKILL=no\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/hadoop/#start-the-service","title":"Start the service","text":"<pre><code>service hadoop start\n</code></pre> <p>You can check cluster status in http://thehive1:9870</p>"},{"location":"thehive/installation-and-configuration/installation/hadoop/#add-nodes","title":"Add nodes","text":"<p>To add Hadoop nodes, refer the the related guide.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/","title":"Step-by-Step guide","text":"<p>This page is a step by step installation and configuration guide to get an TheHive 4 instance up and running. This guide is illustrated with examples for Debian and RPM packages based systems and for installation from binary packages.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#java-virtual-machine","title":"Java Virtual Machine","text":"DebianRPMOther <pre><code>apt-get install -y openjdk-8-jre-headless\necho JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\" &gt;&gt; /etc/environment\nexport JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n</code></pre> <pre><code>yum install -y java-1.8.0-openjdk-headless.x86_64\necho JAVA_HOME=\"/usr/lib/jvm/jre-1.8.0\" &gt;&gt; /etc/environment\nexport JAVA_HOME=\"/usr/lib/jvm/jre-1.8.0\"\n</code></pre> <p>The installation requires Java 8, so refer to your system documentation to install it.</p> <p>Note</p> <p>TheHive can be loaded by Java 11, but not the stable version of Cassandra, which still requires Java 8.  If you set up a cluster for the database distinct from TheHive servers:</p> <ul> <li>Cassandra nodes can be loaded by Java 8</li> <li>TheHive nodes can be loaded by Java 11 </li> </ul> <p>For standalone servers, with TheHive and Cassandra on the same OS, we recommend having only Java 8 installed for both applications.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#cassandra-database","title":"Cassandra database","text":"<p>Apache Cassandra is a scalable and high available database. TheHive supports the latest stable version  3.11.x of Cassandra.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#install-from-repository","title":"Install from repository","text":"DebianRPMOther <ol> <li> <p>Add Apache repository references</p> <pre><code>curl -fsSL https://www.apache.org/dist/cassandra/KEYS | sudo apt-key add -\necho \"deb http://www.apache.org/dist/cassandra/debian 311x main\" | sudo tee -a /etc/apt/sources.list.d/cassandra.sources.list\n</code></pre> </li> <li> <p>Install the package</p> <pre><code>sudo apt update\nsudo apt install cassandra\n</code></pre> </li> </ol> <ol> <li> <p>Add the Apache repository of Cassandra to <code>/etc/yum.repos.d/cassandra.repo</code></p> <pre><code>[cassandra]\nname=Apache Cassandra\nbaseurl=https://downloads.apache.org/cassandra/redhat/311x/\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://downloads.apache.org/cassandra/KEYS\n</code></pre> </li> <li> <p>Install the package</p> <pre><code>yum install -y cassandra\n</code></pre> </li> </ol> <p>Download and untgz archive from http://cassandra.apache.org/download/ in the folder of your choice.</p> <p>By default, data is stored in <code>/var/lib/cassandra</code>.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#configuration","title":"Configuration","text":"<p>Start by changing the <code>cluster_name</code> with <code>thp</code>. Run the command <code>cqlsh</code>: </p> <pre><code>cqlsh localhost 9042\n</code></pre> <pre><code>cqlsh&gt; UPDATE system.local SET cluster_name = 'thp' where key='local';\n</code></pre> <p>Exit and then run:</p> <pre><code>nodetool flush\n</code></pre> <p>Configure Cassandra by editing <code>/etc/cassandra/cassandra.yaml</code> file.</p> <pre><code># content from /etc/cassandra/cassandra.yaml\n\ncluster_name: 'thp'\nlisten_address: 'xx.xx.xx.xx' # address for nodes\nrpc_address: 'xx.xx.xx.xx' # address for clients\nseed_provider:\n    - class_name: org.apache.cassandra.locator.SimpleSeedProvider\n      parameters:\n          # Ex: \"&lt;ip1&gt;,&lt;ip2&gt;,&lt;ip3&gt;\"\n          - seeds: 'xx.xx.xx.xx' # self for the first node\ndata_file_directories:\n  - '/var/lib/cassandra/data'\ncommitlog_directory: '/var/lib/cassandra/commitlog'\nsaved_caches_directory: '/var/lib/cassandra/saved_caches'\nhints_directory: \n  - '/var/lib/cassandra/hints'\n</code></pre> <p>Then restart the service:</p> DebianRPM <pre><code>service cassandra restart\n</code></pre> <p>Run the service and ensure it restart after a reboot:</p> <pre><code>systemctl daemon-reload\nservice cassandra start\nchkconfig cassandra on\n</code></pre> <p>Warning</p> <p>Cassandra service does not start well with the new systemd version. There is an existing issue and a fix on Apache website: https://issues.apache.org/jira/browse/CASSANDRA-15273</p> <p>By default Cassandra listens on <code>7000/tcp</code> (inter-node), <code>9042/tcp</code> (client).</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#additional-configuration","title":"Additional configuration","text":"<p>For additional configuration options, refer to:</p> <ul> <li>Cassandra documentation page</li> <li>Datastax documentation page</li> </ul>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#security","title":"Security","text":"<p>To add security measures in Cassandra , refer the the related administration guide.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#add-nodes","title":"Add nodes","text":"<p>To add Cassandra nodes, refer the the related administration guide.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#indexing-engine","title":"Indexing engine","text":"<p>Starting from TheHive 4.1.0, a solution to store data indexes is required. These indexes should be unique and the same for all nodes of TheHive cluster. </p> <ul> <li>TheHive embed a Lucene engine you can use for standalone server</li> <li>For clusters setups, an instance of Elasticsearch is required </li> </ul> Local lucene engineElasticsearch <p>Create a folder dedicated to host indexes for TheHive: </p> <pre><code>mkdir /opt/thp/thehive/index\nchown thehive:thehive -R /opt/thp/thehive/index\n</code></pre> <p>Use an existing Elasticsearch instance or install a new one. This instance should be reachable by all nodes of a cluster.</p> <p>Warning</p> <p>Elasticsearch configuration should use the default value for <code>script.allowed_types</code>, or contain the following configuration line: </p> <pre><code>script.allowed_types: inline,stored\n</code></pre> <p>Note</p> <ul> <li>Indexes will be created at the first start of TheHive. It can take a certain amount of time, depending the size of the database</li> <li>Like data and files, indexes should be part of the backup policy</li> <li>Indexes can removed and created again</li> </ul>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#file-storage","title":"File storage","text":"<p>Files uploaded in TheHive (in task logs or in observables) can be stores in localsystem, in a Hadoop filesystem (recommended) or in the graph database.</p> <p>For standalone production and test servers , we recommends using local filesystem. If you think about building a cluster with TheHive, you have several possible solutions: using Hadoop or S3 services ; see the related guide for more details and an example with MinIO servers.  </p> Local FilesystemS3 with Min.ioHDFS with Hadoop <p>Warning</p> <p>This option is perfect for standalone servers. If you intend to build a cluster for your instance of TheHive 4 we recommend:</p> <ul> <li>using a NFS share, common to all nodes</li> <li>having a look at storage solutions implementing S3 or HDFS.</li> </ul> <p>To store files on the local filesystem, start by choosing the dedicated folder:</p> <pre><code>mkdir -p /opt/thp/thehive/files\n</code></pre> <p>This path will be used in the configuration of TheHive.</p> <p>Later, after having installed TheHive, ensure the user <code>thehive</code> owns the path chosen for storing files:</p> <pre><code>chown -R thehive:thehive /opt/thp/thehive/files\n</code></pre> <p>An example of installing, configuring and use Min.IO is detailed in this documentation.</p> <p>An example of installing, configuring and use Apache Hadoop is detailed in this documentation.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#thehive","title":"TheHive","text":"<p>This part contains instructions to install TheHive and then configure it.</p> <p>Warning</p> <p>TheHive4 can't be installed on the same server than older versions. We recommend installing it on a new server, especially if a migration is foreseen.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#installation","title":"Installation","text":"<p>All packages are published on our packages repository. We support Debian and RPM packages as well as binary packages (zip archive). All packages are signed using our GPG key 562CBC1C. Its fingerprint is <code>0CD5 AC59 DE5C 5A8E 0EE1  3849 3D99 BB18 562C BC1C</code>.</p> DebianRPM <pre><code>curl https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY | sudo apt-key add -\n</code></pre> <pre><code>sudo rpm --import https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY\n</code></pre> <p>We also release stable and beta version of the applications.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#stable-versions","title":"Stable versions","text":"<p>Install TheHive 4.x package of the stable version by using the following commands:</p> DebianRPMOther <pre><code>echo 'deb https://deb.thehive-project.org release main' | sudo tee -a /etc/apt/sources.list.d/thehive-project.list\nsudo apt-get update\nsudo apt-get install thehive4\n</code></pre> <ol> <li> <p>Setup your system to connect the RPM repository. Create and edit the file <code>/etc/yum.repos.d/thehive-project.repo</code>:</p> <pre><code>[thehive-project]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=https://rpm.thehive-project.org/release/noarch\ngpgcheck=1\n</code></pre> </li> <li> <p>Then install the package using <code>yum</code>:</p> <pre><code>yum install thehive4\n</code></pre> </li> </ol> <ol> <li>Download and unzip the chosen binary package. TheHive files can be installed wherever you want on the filesystem. In this guide, we assume you have chosen to install them under <code>/opt</code>.</li> </ol> <pre><code>cd /opt\nwget https://download.thehive-project.org/thehive4-latest.zip\nunzip thehive4-latest.zip\nln -s thehive4-x.x.x thehive\n</code></pre> <ol> <li> <p>Prepare the system</p> <p>It is recommended to use a dedicated, non-privileged user account to start TheHive. If so, make sure that the chosen account can create log files in <code>/opt/thehive/logs</code>.</p> <p>If you'd rather start the application as a service, use the following commands:</p> <pre><code>addgroup thehive\nadduser --system thehive\nchown -R thehive:thehive /opt/thehive\nmkdir /etc/thehive\ntouch /etc/thehive/application.conf\nchown root:thehive /etc/thehive\nchgrp thehive /etc/thehive/application.conf\nchmod 640 /etc/thehive/application.conf\n</code></pre> <p>Copy the systemd script in <code>/etc/systemd/system/thehive.service</code>.</p> <pre><code>cd /tmp\nwget https://github.com/TheHive-Project/TheHive/blob/master/package/thehive.service\ncp thehive.service /etc/systemd/system/thehive.service\n</code></pre> </li> </ol>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#beta-versions","title":"Beta versions","text":"<p>To install beta versions of TheHive4, use the following setup:</p> DebianRPMOther <pre><code>echo 'deb https://deb.thehive-project.org beta main' | sudo tee -a /etc/apt/sources.list.d/thehive-project.list\nsudo apt-get update\nsudo apt-get install thehive4\n</code></pre> <ol> <li> <p>setup your system to connect the RPM repository. Create and edit the file <code>/etc/yum.repos.d/thehive-project.repo</code>:</p> <pre><code>[thehive-project]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=https://rpm.thehive-project.org/beta/noarch\ngpgcheck=1\n</code></pre> </li> <li> <p>Then install the package using <code>yum</code>:</p> <pre><code>yum install thehive4\n</code></pre> </li> </ol> <ol> <li> <p>Download and unzip the chosen binary package. TheHive files can be installed wherever you want on the filesystem. In this guide, we assume you have chosen to install them under <code>/opt</code>.</p> <pre><code>cd /opt\nwget https://download.thehive-project.org/thehive4-beta-latest.zip\nunzip thehive4-beta-latest.zip\nln -s thehive4-x.x.x thehive\n</code></pre> </li> <li> <p>Prepare the system</p> <p>It is recommended to use a dedicated, non-privileged user account to start TheHive. If so, make sure that the chosen account can create log files in <code>/opt/thehive/logs</code>.</p> <p>If you'd rather start the application as a service, use the following commands:</p> <pre><code>addgroup thehive\nadduser --system thehive\nchown -R thehive:thehive /opt/thehive\nmkdir /etc/thehive\ntouch /etc/thehive/application.conf\nchown root:thehive /etc/thehive\nchgrp thehive /etc/thehive/application.conf\nchmod 640 /etc/thehive/application.conf\n</code></pre> <p>Copy the systemd script in <code>/etc/systemd/system/thehive.service</code>.</p> <pre><code>cd /tmp\nwget https://github.com/TheHive-Project/TheHive/blob/master/package/thehive.service\ncp thehive.service /etc/systemd/system/thehive.service\n</code></pre> </li> </ol> <p>Warning</p> <p>We recommend using or playing with Beta version for testing purpose only.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#configuration_1","title":"Configuration","text":"<p>Following configurations are required to start TheHive successfully:</p> <ul> <li>Secret key configuration</li> <li>Database configuration</li> <li>File storage configuration</li> </ul>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#secret-key-configuration","title":"Secret key configuration","text":"DebianRPMOther <p>The secret key is automatically generated and stored in <code>/etc/thehive/secret.conf</code> by package installation script.</p> <p>The secret key is automatically generated and stored in <code>/etc/thehive/secret.conf</code> by package installation script.</p> <p>Setup a secret key in the <code>/etc/thehive/secret.conf</code> file by running the following command:</p> <pre><code>cat &gt; /etc/thehive/secret.conf &lt;&lt; _EOF_\nplay.http.secret.key=\"$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 64 | head -n 1)\"\n_EOF_\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#database","title":"Database","text":"<p>To use Cassandra database, TheHive configuration file (<code>/etc/thehive/application.conf</code>) has to be edited and updated with following lines:</p> <pre><code>db {\nprovider: janusgraph\njanusgraph {\nstorage {\nbackend: cql\nhostname: [\"127.0.0.1\"] # seed node ip addresses\n#username: \"&lt;cassandra_username&gt;\"       # login to connect to database (if configured in Cassandra)\n#password: \"&lt;cassandra_passowrd\"\ncql {\ncluster-name: thp       # cluster name\nkeyspace: thehive           # name of the keyspace\nlocal-datacenter: datacenter1   # name of the datacenter where TheHive runs (relevant only on multi datacenter setup)\n# replication-factor: 2 # number of replica\nread-consistency-level: ONE\nwrite-consistency-level: ONE\n}\n}\n}\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#indexes","title":"Indexes","text":"<p>Update <code>db.storage</code> configuration part in <code>/etc/thehive/application.conf</code> accordingly to your setup. </p> LuceneElasticsearch <p>If your setup is a standalone server or you are using a common NFS share, configure TheHive like this:  </p> <pre><code>db {\nprovider: janusgraph\njanusgraph {\nstorage {\n[..]\n}\n## Index configuration\nindex.search {\nbackend : lucene\ndirectory:  /opt/thp/thehive/index\n}\n}\n}\n</code></pre> <p>If you decided to have access to a centralised index with Elasticsearch, configure TheHive like this:  </p> <pre><code>db {\nprovider: janusgraph\njanusgraph {\nstorage {\n[..]\n}\n## Index configuration\nindex.search {\nbackend : elasticsearch\nhostname : [\"10.1.2.20\"]\nindex-name : thehive\n}\n}\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#filesystem","title":"Filesystem","text":"Local filesystemS3HDFS <p>If you chose to store files on the local filesystem:</p> <ol> <li> <p>Ensure permission of the folder</p> <pre><code>chown -R thehive:thehive /opt/thp/thehive/files\n</code></pre> </li> <li> <p>add following lines to TheHive configuration file (<code>/etc/thehive/application.conf</code>)</p> <pre><code>## Storage configuration\nstorage {\nprovider = localfs\nlocalfs.location = /opt/thp/thehive/files\n}\n</code></pre> </li> </ol> <p>If you chose MinIO and a S3 object storage system to store files in a  filesystem, add following lines to TheHive configuration file (<code>/etc/thehive/application.conf</code>)</p> <pre><code>## Storage configuration\nstorage {\nprovider: s3\ns3 {\nbucket = \"thehive\"\nreadTimeout = 1 minute\nwriteTimeout = 1 minute\nchunkSize = 1 MB\nendpoint = \"http://&lt;IP_ADDRESS&gt;:9100\"\naccessKey = \"&lt;MINIO ACCESS KEY&gt;\"\nsecretKey = \"&lt;MINIO SECRET KEY&gt;\"\n}\n}\n</code></pre> <p>If you chose Apache Hadoop and a HDFS filesystem to store files in a distrubuted filesystem, add following lines to TheHive configuration file (<code>/etc/thehive/application.conf</code>)</p> <pre><code>## Storage configuration\nstorage {\nprovider: hdfs\nhdfs {\nroot: \"hdfs://thehive1:10000\" # namenode server\nlocation: \"/thehive\"\nusername: thehive\n}\n}\n</code></pre>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#run","title":"Run","text":"<p>Save configuration file and run the service:</p> <pre><code>service thehive start\n</code></pre> <p>Please note that the service may take some time to start. Once it is started, you may launch your browser and connect to <code>http://YOUR_SERVER_ADDRESS:9000/</code>.</p> <p>The default admin user is <code>admin@thehive.local</code> with password <code>secret</code>. It is recommended to change the default password.</p>"},{"location":"thehive/installation-and-configuration/installation/step-by-step-guide/#advanced-configuration","title":"Advanced configuration","text":"<p>For additional configuration options, please refer to the Configuration Guides.</p>"},{"location":"thehive/legacy/thehive3/","title":"Index","text":"<p>TheHive is a scalable 4-in-1 open source and free security incident response platform designed to make life easier for SOCs, CSIRTs, CERTs and any information security practitioner dealing with security incidents that need to be investigated and acted upon swiftly. Thanks to Cortex, our powerful free and open source analysis engine, you can analyze (and triage) observables at scale using more than 100 analyzers.</p> <p>Additionally and starting from TheHive 3.1.0, you can actively respond to threats and interact with your constituency and other parties thanks to Cortex responders.</p> <p>Last but not least, TheHive is highly integrated with MISP, the de facto standard of threat sharing, as it can pull events from several MISP instances and export investigation cases back to one or several ones. It also has additional features such as MISP extended events and health checking.</p> <ul> <li>This is TheHive's documentation repository. If you are looking for its source code, please visit https://github.com/TheHive-Project/TheHive/.</li> </ul>"},{"location":"thehive/legacy/thehive3/#hardware-pre-requisites","title":"Hardware Pre-requisites","text":"<p>TheHive uses ElasticSearch to store data. Both software use a Java VM. We recommend using a virtual machine with 8vCPU, 8 GB of RAM and 60 GB of disk. You can also use a physical machine with similar specifications.</p>"},{"location":"thehive/legacy/thehive3/#guides","title":"Guides","text":"<ul> <li>Installation Guide</li> <li>Administration Guide</li> <li>Configuration Guide</li> <li>Webhooks</li> <li>Cluster Configuration</li> <li>Updating</li> <li>Backup &amp; Restore</li> <li>Migration Guide</li> <li>API Documentation (incomplete)</li> </ul>"},{"location":"thehive/legacy/thehive3/#miscellaneous-information","title":"Miscellaneous Information","text":"<ul> <li>Feature Set (In Progress)</li> <li>Changelog</li> <li>Training Material</li> <li>Additional Resources</li> <li>Single Sign-On on TheHive with X.509 Certificates (Experimental Feature)</li> </ul>"},{"location":"thehive/legacy/thehive3/#license","title":"License","text":"<p>TheHive is an open source and free software released under the AGPL (Affero General Public License). We, TheHive Project, are committed to ensure that TheHive will remain a free and open source project on the long-run.</p>"},{"location":"thehive/legacy/thehive3/#updates","title":"Updates","text":"<p>Information, news and updates are regularly posted on TheHive Project Twitter account and on the blog.</p>"},{"location":"thehive/legacy/thehive3/#contributing","title":"Contributing","text":"<p>We welcome your contributions. Please feel free to fork the code, play with it, make some patches and send us pull requests using issues.</p> <p>We do have a Code of conduct. Make sure to check it out before contributing.</p>"},{"location":"thehive/legacy/thehive3/#support","title":"Support","text":"<p>Please open an issue on GitHub if you'd like to report a bug or request a feature. We are also available on Gitter to help you out.</p> <p>If you need to contact the Project's team, send an email to support@thehive-project.org.</p> <p>Important Note:</p> <ul> <li>If you have problems with TheHive4py, please open an issue on its dedicated repository.</li> <li>If you encounter an issue with Cortex or would like to request a Cortex-related feature, please open an issue on its dedicated GitHub repository.</li> <li>If you have troubles with a Cortex analyzer or would like to request a new one or an improvement to an existing analyzer, please open an issue on the analyzers' dedicated GitHub repository.</li> </ul>"},{"location":"thehive/legacy/thehive3/#community-discussions","title":"Community Discussions","text":"<p>We have set up a Google forum at https://groups.google.com/a/thehive-project.org/d/forum/users. To request access, you need a Google account. You may create one using a Gmail address or without it.</p>"},{"location":"thehive/legacy/thehive3/#website","title":"Website","text":"<p>https://thehive-project.org/</p>"},{"location":"thehive/legacy/thehive3/feature-set/","title":"Feature set","text":"<p>This document lists the features provided by TheHive in either the UI or APIs and Webhooks.</p> <p>TheHive comes with the native support of integrating:</p> <ul> <li>one or more Cortex instances</li> <li>one or more MISP instances</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#authentication","title":"Authentication","text":"<p>TheHive supports multiple authentication methods:</p> <ul> <li>Local authentication using a local user collection</li> <li>AD authentication</li> <li>LDAP authentication</li> <li>SSO authentication</li> <li>X.509 certificates authentication</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#case-management","title":"Case Management","text":"<ul> <li>List and filter cases</li> <li>Create new cases from scratch or using case templates</li> <li>Add custom fields to cases</li> <li>Add metrics to cases</li> <li>Find linked cases to a given case based shared observables</li> <li>Add tasks and task groups to cases</li> <li>Assign tasks to a given user</li> <li>Add logs to tasks, including attachment to task logs</li> <li>Add observables to a case</li> <li>Execute Cortex responders against</li> <li>cases</li> <li>tasks</li> <li>task logs</li> <li>Delete cases by administrators only</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#alert-management","title":"Alert Management","text":"<p>Alerts are a sort of incident not yet qualified as a Case. The Alerts sections allows:</p> <ul> <li>Listing and searching for alerts</li> <li>Marking alerts as read</li> <li>Ignoring alert updates</li> <li>Previewing alert details</li> <li>Display alert details and editable custom fields</li> <li>Display alerts observables</li> <li>Display similar cases</li> <li>Importing an alert as an emtpty case or using a case template</li> <li>Merging an alert into an existing case</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#misp-integration","title":"MISP Integration","text":"<p>MISP is natively integrated to TheHive allowing:</p> <ul> <li>The declaration of one or more MISP instances</li> <li>Each instance can be used to Import and/or Export events from MISP or cases to MISP</li> <li>Imported MISP events are made available as Alerts</li> <li>Imporing is configurable using filters (configuration files)</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#feeders","title":"Feeders","text":"<ul> <li>Feeders are external tools designed to send alerts to TheHive leveraging the REST APIs Thehive offers</li> <li>Feeders can be written and any programming language as long as it is compatible with TheHive APIs</li> <li>Feeders can be written in Python and use TheHive4Py</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#search-capabilities","title":"Search capabilities","text":"<p>The search section provided by TheHive allows searching for the following objects using dynamic forms:</p> <ul> <li>cases</li> <li>tasks</li> <li>observables</li> <li>logs</li> <li>alerts</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#dashboarding","title":"Dashboarding","text":"<p>The dashboards section allows:</p> <ul> <li>creating private dashboards per user</li> <li>creating shared dashboads visible by all users</li> <li>adding widgets to dashboards using a drag &amp; drop capabilities</li> <li>creating widgets that target cases, tasks, observables, alerts, jobs</li> <li>configuring widgets in a granular manner</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#administration","title":"Administration","text":""},{"location":"thehive/legacy/thehive3/feature-set/#case-templates","title":"Case templates","text":"<ul> <li>Create case templates</li> <li>Add tasks to templates</li> <li>Add metrics to templates</li> <li>Add custom fields to templates</li> <li>Define default values for custom fields, metrics and tasks</li> <li>Export case template definitions</li> <li>Import case template definitions</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#metrics","title":"Metrics","text":"<ul> <li>List and Create metrics</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#custom-fields","title":"Custom fields","text":"<ul> <li>Create custom fields</li> <li>Update custom fields</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#users","title":"Users","text":"<ul> <li>List users</li> <li>Create/Edit users</li> <li>Set a user password</li> <li>Set a user API key</li> <li>Revoke a user's API key</li> <li>Lock a user</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#analyzer-report-templates","title":"Analyzer report templates","text":"<p>Report templates are used to display the raw reports from Cortex in a text format. This section allows:</p> <ul> <li>Importing short and long reports</li> <li>Customize short and long reports for each analyzer</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#cortex-integration","title":"Cortex integration","text":"<p>TheHive uses Cortex to have access to analyzers and responsders</p> <ul> <li>Analyzers can be launched against observables to get more details about a given observable</li> <li>Responders can be launched against case, tasks, observables, logs, and alerts to execute an action</li> <li>One or more Cortex instances can be connected to TheHive</li> </ul>"},{"location":"thehive/legacy/thehive3/feature-set/#database-migration","title":"Database migration","text":"<p>TheHive provides a mechanism to upgrade the Elasticsearch database by copying the index and making transformations on it.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/","title":"Migration guide","text":""},{"location":"thehive/legacy/thehive3/migration-guide/#from-34x-to-350","title":"From 3.4.x to 3.5.0","text":"<p>Taking into account the EoL of version 6.x. of Elasticsearch, TheHive 3.5.0 is the first version to support Elasticsearch 7.x. This version introduce breaking changes.  This time,  we had no choice, we were not able to make TheHive support smoothly the ES upgrade. </p> <p>TheHive 3.5.0 supports Elasticsearch 7.x ONLY.</p> <p>This first steps before starting the upgrade process are: </p> <ul> <li>Identify the version of Elasticsearch which created your index</li> <li>Stop TheHive service</li> <li>Stop Elasticsearch service</li> </ul>"},{"location":"thehive/legacy/thehive3/migration-guide/#how-to-identify-the-version-of-elasticsearch-which-created-your-database-index","title":"How to identify the version of Elasticsearch which created your database index ?","text":"<p>The software <code>jq</code> is required to manipulate JSON and create new indexes. More information at https://stedolan.github.io/jq/. </p> <p>Run the following command : </p> <pre><code>curl -s http://127.0.0.1:9200/the_hive_15?human | jq '.the_hive_15.settings.index.version.created_string'\n</code></pre> <ul> <li>if the output is similar to <code>\"5.x\"</code>  then your database index has been created with Elasticsearch 5.x  reindexing is required, you should follow a dedicated process to upgrade. </li> <li>If it is   <code>\"6.x\"</code> then your database has been created with Elasticsearch 6.</li> </ul>"},{"location":"thehive/legacy/thehive3/migration-guide/#your-database-was-created-with-elasticsearch-5x-or-earlier","title":"Your database was created with Elasticsearch 5.x or earlier","text":"<p>This is where things might be complicated. This upgrade progress  requires handling the database index by updating parameters, and reindex before updating Elasticsearch, and updating TheHive.</p> <p>Read carefully the dedicated documentation. It should help you run this specific actions on your Elasticsearch database, and also install or update application whether you are using DEB, RPM or binary packages, and even docker images.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#your-database-was-created-with-elasticsearch-6x","title":"Your database was created with Elasticsearch 6.x","text":"<p>If you started using TheHive with Elasticsearch 6.x, then you just need to update the configuration of Elasticsearch to reflect this one: </p> <pre><code>[..]\nhttp.host: 127.0.0.1\ndiscovery.type: single-node\ncluster.name: hive\nscript.allowed_types: inline\nthread_pool.search.queue_size: 100000\nthread_pool.write.queue_size: 10000\n</code></pre> <p>Following parameters *are not accepted anymore by Elasticsearch 7: </p> <ul> <li><code>thread_pool.index.queue_size</code></li> <li><code>thread_pool.bulk.queue_size</code> </li> </ul> <p>With TheHive service stopped, ensure the new version of Elasticsearch starts.</p> <p>If everything is ok, then TheHive 3.5.0 can be installed. To run this operation successfully, you need to update your repository configuration  if you are using DEB and RPM packages, or specify the right version to install if using docker. Read carefully the installation guide. </p>"},{"location":"thehive/legacy/thehive3/migration-guide/#from-33x-to-340","title":"From 3.3.x to 3.4.0","text":"<p>Starting from version 3.4.0-RC1, TheHive supports Elasticsearch 6 and will continue to work with Elasticsearch 5.x.</p> <p>TheHive 3.4.0-RC1 and later versions communicate with Elasticsearch using its HTTP service (9200/tcp by default) instead of its legacy binary protocol (9300/tcp by default). If you have a firewall between TheHive and Elasticsearch, you probably need to update its rules to change to the new port number.</p> <p>The configuration file (<code>application.conf</code>) needs some modifications to reflect the protocol change:</p> <ul> <li>The setting <code>search.host</code> is replaced by <code>search.uri</code></li> <li>The general format of the URI is: <code>http(s)://host:port,host:port(/prefix)?querystring</code>. Multiple <code>host:port</code> combinations can be specified, separated by commas. Options can be specified using a standard URI query string syntax, eg. <code>cluster.name=hive</code>.</li> <li>The <code>search.cluster</code>setting is no longer used.</li> <li>Authentication can be configured with the <code>search.user</code> and <code>search.password</code> settings.</li> </ul> <p>When SSL/TLS is enabled, you can set a truststore and a keystore. The truststore contains the certificate authorities used to validate remote certificates. The keystore contains the certificate and the private key used to connect to the Elasticsearch cluster. The configuration is: <pre><code>search {\n  keyStore {\n    path: \"/path/to/keystore/file\"\n    type: \"JKS\" # or PKCS12\n    password: \"secret.password.of.keystore\"\n  }\n  trustStore {\n    path: \"/path/to/truststore/file\"\n    type: \"JKS\"\n    password: \"secret.password.of.truststore\"\n  }\n}\n</code></pre></p> <p>The Elasticsearch client also accepts the following settings:  - <code>circularRedirectsAllowed</code> (<code>true</code>/<code>false</code>)  - <code>connectionRequestTimeout</code> (number of seconds)  - <code>connectTimeout</code>  - <code>contentCompressionEnabled.foreach(requestConfigBuilder.setContentCompressionEnabled)</code>  - <code>search.cookieSpec</code> (??)  - <code>expectContinueEnabled</code> (<code>true</code>/<code>false</code>)  - <code>maxRedirects</code> (number)  - <code>proxy</code> -- not yet supported  - <code>proxyPreferredAuthSchemes</code> -- not yet supported  - <code>redirectsEnabled</code> (<code>true</code>/<code>false</code>)  - <code>relativeRedirectsAllowed</code> (<code>true</code>/<code>false</code>)  - <code>socketTimeout</code> (number of seconds)  - <code>targetPreferredAuthSchemes</code> (??) </p> <p>The configuration items <code>keepalive</code>, <code>pageSize</code>, <code>nbshards</code> and <code>nbreplicas</code> are still valid.</p> <p>For practical details, you can have a look here for an example of migration of TheHive and Elasticsearch.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#from-30x-to-304","title":"From 3.0.x to 3.0.4","text":"<p>TheHive 3.0.4 (Cerana 0.4) comes with new MISP settings to filter events that will be imported as alerts. Please refer to MISP event filters configuration section. The maximum number of custom fields and metrics in a case is 50 by default. If you try to put more, ElasticSearch will raise an error. You can now increase the limit by adding in your application.conf: <pre><code>index {\n  settings {\n    # Maximum number of nested fields\n    mapping.nested_fields.limit = 100\n  }\n}\n</code></pre> The data schema has been changed in Cerana to support some dashboard features. At the first connection, TheHive will ask you to migrate the data. A new index, called <code>the_hive_13</code> by default, will be created then.  See Updating.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#from-213x-to-300","title":"From 2.13.x to 3.0.0","text":"<p>The schema of data has been changed in Cerana to integrate dashboard. At the first request, TheHive will ask you to migrate the data. A new index, called <code>the_hive_12</code> by default, will be created then.  See Updating.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#from-2130-or-2131-to-2132","title":"From 2.13.0 or 2.13.1 to 2.13.2","text":"<p>At the first connection to TheHive 2.13.2, a migration of the database will be asked. This will create a new ElasticSearch index (<code>the_hive_11</code> by default). See Updating.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#from-212x-to-213x","title":"From 2.12.x to 2.13.x","text":""},{"location":"thehive/legacy/thehive3/migration-guide/#configuration-updates","title":"Configuration updates","text":"<p><code>play.crypto.secret</code> is deprecated, use <code>play.http.secret.key</code> instead.</p> <p><code>auth.type</code> is deprecated, use <code>auth.provider</code> instead.</p> <p>Basic authentication is disabled by default. We strongly recommand to update the clients that rely on the API to interact with TheHive to use the new API key authentication method. This feature has been added in this release. If you need to enable basic authentication, use <code>auth.method.basic=true</code> in <code>application.conf</code></p> <p>Note that the TheHive4Py 1.3.0 Python library also adds API key authentication support.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#alert-role","title":"Alert role","text":"<p>A new role \"alert\" has been added. Only users with this role can create an alert. If you have tool that uses TheHive API to create alerts, you must give the ability to do it in user administration.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#elasticsearch","title":"ElasticSearch","text":"<p>TheHive 2.13 uses ElasticSearch 5.x. Our tests have been done on ElasticSearch 5.5. So we recommend to use this specific version, even if TheHive should work perfectly with ElasticSearch 5.6 that doesn't introduce breaking changes.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#data-structure-migration","title":"Data structure migration","text":"<p>Before upgrading ElasticSearch, backup all your indices. Then remove all indices except the last index of TheHive (most probably the_hive_10). You can list all indices with the following command:</p> <p><code>curl http://127.0.0.1:9200/_cat/indices</code></p> <p>ElasticSearch has changed the structure of its data directory (please refer to Path to data on disk). The node name in the path where data are stored (DATA_DIR) must be removed. Stop ElasticSearch and execute the following lines to change the directory structure: <pre><code>echo -n 'Enter the path of ElasticSearch data: '\nread DATA_DIR\necho -n 'Enter the name of your cluster [hive]: '\nread CLUSTER_NAME\n\nmv ${DATA_DIR}/${CLUSTER_NAME:=hive}/* ${DATA_DIR}\nrmdir ${DATA_DIR}/${CLUSTER_NAME}\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/migration-guide/#system-requirements","title":"System requirements","text":"<p>ElasticSearch 5.x requires at least 262144 memory map areas (vm.max_map_count). Run sysctl -w vm.max_map_count=262144. To make this setting persistent after a server restart, add <code>vm.max_map_count = 262144</code> in <code>/etc/sysctl.conf</code> (or to <code>/etc/sysctl.d/80-elasticsearch.conf</code>)</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#configuration","title":"Configuration","text":"<p>The configuration of ElasticSearch should contain the following settings: <pre><code>http.host: 127.0.0.1\ntransport.host: 127.0.0.1\ncluster.name: hive\nscript.inline: true\nthread_pool.index.queue_size: 100000\nthread_pool.search.queue_size: 100000\nthread_pool.bulk.queue_size: 100000\n</code></pre> Adapt <code>http.host</code> and <code>transport.host</code> to your environment.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#docker","title":"Docker","text":"<p>The default ElasticSearch image has been deprecated. It is recommended to use the docker image from Elastic.co.</p> <p>The new image doesn't use the same user ID so you need to change the owner of the data files. You can simply run <code>chown -R 1000.1000 $DATA_DIR</code> (DATA_DIR is the folder which contains ElasticSearch data).</p> <p>Then you can use the following script: <pre><code>docker run \\\n  --name elasticsearch \\\n  --hostname elasticsearch \\\n  --rm \\\n  --publish 127.0.0.1:9200:9200 \\\n    --publish 127.0.0.1:9300:9300 \\\n  --volume ***DATA_DIR***:/usr/share/elasticsearch/data \\\n    -e \"http.host=0.0.0.0\" \\\n    -e \"transport.host=0.0.0.0\" \\\n    -e \"xpack.security.enabled=false\" \\\n    -e \"cluster.name=hive\" \\\n  -e \"script.inline=true\" \\\n  -e \"thread_pool.index.queue_size=100000\" \\\n  -e \"thread_pool.search.queue_size=100000\" \\\n  -e \"thread_pool.bulk.queue_size=100000\" \\\n    docker.elastic.co/elasticsearch/elasticsearch:5.5.2\n</code></pre></p> <p>Note: TheHive doesn't support X-Pack. Don't enable it.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#warnings-you-can-safely-ignore-with-es-55","title":"Warnings You Can Safely Ignore with ES 5.5","text":"<p>ElasticSearch 5.5 will output the following warnings:  - <code>unexpected docvalues type NONE for field '_parent' (expected one of [SORTED, SORTED_SET]). Re-index with correct docvalues type.</code>  You can safely ignore this message. For more information see issues #25849  and #26341  - <code>License [will expire] on [***]. If you have a new license, please update it.</code>  Ignore this warning as TheHive doesn't use Elasticsearch's commercial features.</p> <p>Note: ElasticSearch 5.6 fixes those warnings.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#from-211x-to-212x","title":"From 2.11.x to 2.12.x","text":""},{"location":"thehive/legacy/thehive3/migration-guide/#database-migration","title":"Database migration","text":"<p>At the first connection to TheHive 2.12, a migration of the database will be asked. This will create a new ElasticSearch index (the_hive_10). See Updating.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#from-210x-to-211x","title":"From 2.10.x to 2.11.x","text":""},{"location":"thehive/legacy/thehive3/migration-guide/#database-migration_1","title":"Database migration","text":"<p>At the first connection to TheHive 2.11, a migration of the database will be asked. This will create a new ElastciSearch index (the_hive_9). See Updating.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#misp-to-alert","title":"MISP to alert","text":"<p>MISP synchronization is now done using alerting framework. MISP events are seen like other alert. You can use TheHive4py to create your own alert.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#configuration-changes","title":"Configuration changes","text":""},{"location":"thehive/legacy/thehive3/migration-guide/#misp-certificate-authority-deprecated","title":"MISP certificate authority deprecated","text":"<p>Specifying certificate authority in MISP configuration using \"cert\" key is now deprecated. You must replace it by - before: <pre><code>misp {\n  [...]\n  cert = \"/path/to/truststore.jks\"\n}\n</code></pre> - after: <pre><code>misp {\n  [...]\n  ws.ssl.trustManager.stores = [\n    {\n      type: \"JKS\"\n      path: \"/path/to/truststore.jks\"\n    }\n  ]\n}\n</code></pre></p> <p><code>ws</code> key can be placed in MISP server section or in global MISP section. In the latter, ws configuration will be applied on all MISP instances.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#cortex-and-misp-http-client-options","title":"Cortex and MISP HTTP client options","text":"<p>HTTP client used by Cortex and MISP is more configurable. Proxy can be configured, with or without authentication. Refer to configuration for all possible options.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#packages","title":"Packages","text":""},{"location":"thehive/legacy/thehive3/migration-guide/#new-rpm-and-deb-packages","title":"New RPM and DEB packages","text":"<p>RPM and DEB packages are now available. This makes the installation easier than using a binary package (ZIP). See the Installation Guide for reference.</p>"},{"location":"thehive/legacy/thehive3/migration-guide/#docker_1","title":"Docker","text":"<p>All-in-One docker (containing TheHive and Cortex) is not provided any longer. New TheHive docker image doesn't contain ElasticSearch. We recommend to use docker-compose to link TheHive, ElasticSearch and Cortex dockers. For more information, see the Installation Guide for reference.</p> <p>TheHive configuration is located in <code>/etc/thehive/application.conf</code> for all packages. If you use docker package you must update its location (previously was <code>/opt/docker/conf/application.conf</code>).</p>"},{"location":"thehive/legacy/thehive3/admin/admin-guide/","title":"Administrator's guide","text":""},{"location":"thehive/legacy/thehive3/admin/admin-guide/#1-user-management","title":"1. User management","text":"<p>Users can be managed through the <code>Administration</code> &gt; <code>Users</code> page. Only administrators may access it. Each user is identified by their login, full name and role.</p> <p></p> <p>Please note that you still need to create user accounts if you use LDAP or Active Directory authentication. This is necessary for TheHive to retrieve their role and authenticate them against the local database, LDAP and/or AD directories.</p> <p>There are 4 roles currently:  - <code>read</code> : all non-sensitive data can be read. With this role, a user can't make any change. They can't add a case, task, log or observable. They also can't run analyzers;  - <code>write</code>: create, remove and change data of any type. This role is for standard users. <code>write</code> role inherits <code>read</code> rights;  - <code>admin</code>: this role is reserved for TheHive administrators. Users with this role can manage user accounts, metrics, create case templates and observable data types. <code>admin</code> inherits <code>write</code> rights;  - <code>alert</code>: users with this role can only create alerts.</p> <p>Warning: Please note that user accounts cannot be removed once they have been created, otherwise audit logs will refer to an unknown user. However, unwanted or unused accounts can be locked.</p>"},{"location":"thehive/legacy/thehive3/admin/admin-guide/#2-case-template-management","title":"2. Case template management","text":"<p>Some cases may share the same structure (tags, tasks, description, metrics). Templates are here to automatically add tasks, description, metrics and custom fields while creating a new case. A user can choose to create an empty case or based on a registered template.</p> <p>To create a template, as admin go into the administration menu, and open the \"Case templates\" item.</p> <p></p> <p>In this screen, you can add, remove or change template. A template contains:  * default severity  * default tags  * title prefix (can be changed by user at case creation)  * default TLP  * default default  * task list (title and description)  * metrics  * custom fields</p> <p>Except for title prefix, task list and metrics, the user can change values defined in template.</p>"},{"location":"thehive/legacy/thehive3/admin/admin-guide/#3-report-template-management","title":"3. Report template management","text":"<p>When TheHive is connected to a Cortex server, observables can be analyzed to get additional information on them. Cortex outputs reports in JSON format. In order to make reports more readable, you can configure report templates. Report templates convert JSON in to HTML using the AngularJS template engine.</p> <p>For each analyzer available in Cortex you can define two kinds of templates: short and long. A short report exposes synthetic information, shows in top of observable page. With short reports you can see a summary of all run analyzers. Long reports show detailed information only when the user selects the report. Raw data in JSON format is always available.</p> <p>Report templates can be configured in the <code>Admin</code> &gt; <code>Report templates</code> menu. We offer report templates for default Cortex analyzers. A package with all report templates can be downloaded at https://download.thehive-project.org/report-templates.zip and can be injected using the <code>Import templates</code> button.</p>"},{"location":"thehive/legacy/thehive3/admin/admin-guide/#4-metrics-management","title":"4. Metrics management","text":"<p>Metrics have been integrated to have relevant indicators about cases.</p> <p>Metrics are numerical values associated to cases (for example, the number of impacted users). Each metric has a name, a title and a description, defined by an administrator. When a metric is added to a case, it can't be removed and must be filled. Metrics are used to monitor business indicators, thanks to graphs.</p> <p>Metrics are defined globally. To create metrics, as admin go into the administration menu, and open the \"Case metrics\" item.</p> <p></p> <p>Metrics are used to create statistics (\"Statistics\" item in the user profile menu). They can be filtered on time interval, and case with specific tags.</p> <p>For example you can show metrics of case with \"malspam\" tag on January 2016 :</p> <p></p> <p>For graphs based on time, the user can choose metrics to show. They are aggregated on interval of time (by day, week, month of year) using a function (sum, min or max).</p> <p>Some metrics are predefined (in addition to those defined by administrator) like case handling duration (how much time the case had been open) and number of cases open or closed.</p>"},{"location":"thehive/legacy/thehive3/admin/backup-restore/","title":"Backup and restore data","text":"<p>All persistent data is stored in an Elasticsearch database. The backup and restore procedures are the ones that are detailed in Elasticsearch documentation.</p> <p>Note: you may have to adapt your indices in the examples below. To find the right index, use the following command :</p> <pre><code>curl 'localhost:9200/_cat/indices?v'\n</code></pre> <p>You can also refer to the schema version page.</p> <p>To save all your data you only need to backup the last indice. For example, if the previous command gives you the following results, all your data belongs to the_hive_12.</p> <pre><code>health status index                         uuid                   pri rep docs.count docs.deleted store.size pri.store.size\nyellow open   the_hive_11                   HVVYDC68SrGAfSbcjVPZWg   5   1      43018           17     24.9mb         24.9mb\nyellow open   the_hive_12                   Cq4Gc4qkRPaTCqrorFgDRw   5   1      43226            0     25.3mb         25.3mb\n</code></pre> <p>In the rest of this document, ensure to change  to your own last index in order to backup or restore all your data."},{"location":"thehive/legacy/thehive3/admin/backup-restore/#1-create-a-backup-repository","title":"1. Create a backup repository","text":"<p>First you must define a location in local filesystem (where Elasticsearch instance runs) where the backup will be written. This repository must be declared in the Elasticsearch configuration. Edit elasticsearch.yml file by adding:</p> <pre><code>path.repo: [\"/absolute/path/to/backup/directory\"]\n</code></pre> <p>Then, restart the Elasticsearch service.</p> <p>Note: Be careful if you run Elasticsearch in Docker, the directory must be mapped in host filesystem using <code>--volume</code> parameter (cf. Docker documentation).</p>"},{"location":"thehive/legacy/thehive3/admin/backup-restore/#2-register-a-snapshot-repository","title":"2. Register a snapshot repository","text":"<p>Create an Elasticsearch snapshot point named the_hive_backup with the following command (set the same path in the location setting as the one set in the configuration file):</p> <pre><code>$ curl -XPUT 'http://localhost:9200/_snapshot/the_hive_backup' -H 'Content-Type: application/json' -d '{\n    \"type\": \"fs\",\n    \"settings\": {\n        \"location\": \"/absolute/path/to/backup/directory\",\n        \"compress\": true\n    }\n}'\n</code></pre> <p>The result of the command should look like this :</p> <pre><code>{\"acknowledged\":true}\n</code></pre> <p>Since, everything is fine to backup and restore data.</p>"},{"location":"thehive/legacy/thehive3/admin/backup-restore/#3-backup-your-data","title":"3. Backup your data","text":"<p>Create a backup named snapshot_1 of all your data by executing the following command :</p> <p><pre><code>$ curl -XPUT 'http://localhost:9200/_snapshot/the_hive_backup/snapshot_1?wait_for_completion=true&amp;pretty' -H 'Content-Type: application/json' -d '{\n  \"indices\": \"&lt;INDEX&gt;\"\n}'\n</code></pre> This command terminates only when the backup is complete and the result of the command should look like this:</p> <pre><code>{\n  \"snapshots\": [{\n    \"snapshot\": \"snapshot_1\",\n    \"uuid\": \"ZQ3kv5-FQoeN3NFIhfKgMg\",\n    \"version_id\": 5060099,\n    \"version\": \"5.6.0\",\n    \"indices\": [\"the_hive_12\"],\n    \"state\": \"SUCCESS\",\n    \"start_time\": \"2018-01-29T14:41:51.580Z\",\n    \"start_time_in_millis\": 1517236911580,\n    \"end_time\": \"2018-01-29T14:42:05.216Z\",\n    \"end_time_in_millis\": 1517236925216,\n    \"duration_in_millis\": 13636,\n    \"failures\": [],\n    \"shards\": {\n      \"total\": 41,\n      \"failed\": 0,\n      \"successful\": 41\n    }\n  }]\n}\n</code></pre> <p>Note: You can backup the last index of TheHive (you can list indices in your Elasticsearch cluster with <code>curl -s http://localhost:9200/_cat/indices | cut -d ' '  -f3</code> ) or all indices with <code>_all</code> value.</p>"},{"location":"thehive/legacy/thehive3/admin/backup-restore/#4-restore-data","title":"4. Restore data","text":"<p>Restore will do the reverse actions : it reads the backup in your snapshot directory and loads indices into the Elasticsearch cluster. This operation is done with the following command : <pre><code>$ curl -XPOST 'http://localhost:9200/_snapshot/the_hive_backup/snapshot_1/_restore' -d '\n{\n  \"indices\": \"&lt;INDEX&gt;\"\n}'\n</code></pre></p> <p>The result of the command should look like this :</p> <pre><code>{\"accepted\":true}\n</code></pre> <p>Note: be sure to restore data from the same version of Elasticsearch.</p>"},{"location":"thehive/legacy/thehive3/admin/backup-restore/#5-moving-data-from-one-server-to-another","title":"5. Moving data from one server to another","text":"<p>If you want to move your data from one server from another: - Create your backup on the origin server (steps 1, 2, 3) - copy your backup directory from the origin server to the destination server - On the destination server :     - Register your backup repository in the Elasticsearch configuration (step 1)     - Register your snapshot repository with the same snapshot name (step 2)     - Restore your data (step 4)</p>"},{"location":"thehive/legacy/thehive3/admin/certauth/","title":"Single Sign-On on TheHive with X.509 Certificates","text":""},{"location":"thehive/legacy/thehive3/admin/certauth/#abstract","title":"Abstract","text":"<p>SSL managed by TheHive is known to have some stability problem. It is advise to not enable it in production and configure SSL on a reverse proxy, in front of TheHive. This make X509 certificate authentication non applicable.</p> <p>In order to do x509 authentication it is recommended to do it in the reverse proxy and then forward user identity to TheHive in a HTTP header. This feature has been added in version 3.2.</p> <p>WARNING This setup is valid only if nobody except the reverse proxy can connect to TheHive. Users must have to use the reverse proxy. Otherwise, an user would be able to choose his identity on TheHive.</p>"},{"location":"thehive/legacy/thehive3/admin/certauth/#setup-a-reverse-proxy","title":"Setup a reverse proxy","text":"<p>If you use nginx, the site configuration file should look like: <pre><code>  server {\n      listen 443 ssl;\n      server_name thehive.example.com;\n\n      ssl on;\n      ssl_certificate         ssl/thehive_cert.pem;\n      ssl_certificate_key     ssl/thehive_key.pem;\n\n      # Force client to have a certificate\n      ssl_verify_client       on;\n\n      proxy_connect_timeout   600;\n      proxy_send_timeout      600;\n      proxy_read_timeout      600;\n      send_timeout            600;\n      client_max_body_size    2G;\n      proxy_buffering off;\n      client_header_buffer_size 8k;\n\n      # Map certificate DN to user login stored in TheHive\n      map $ssl_client_s_dn $thehive_user\n      {\n        default \"\";\n        /C=FR/O=TheHive-Project/CN=Thomas toom;\n        /C=FR/O=TheHive-Project/CN=Georges bofh;\n      };\n\n      # Redirect all request to local TheHive\n      location / {\n          add_header              Strict-Transport-Security \"max-age=31536000; includeSubDomains\";\n          # Send the mapped user login to TheHive, in THEHIVE_USER HTTP header\n          proxy_set_header        THEHIVE_USER $thehive_user;\n          proxy_pass              http://127.0.0.1:9000/;\n          proxy_http_version      1.1;\n      }\n  }\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/certauth/#enable-authentication-delegation-in-thehive","title":"Enable authentication delegation in TheHive","text":"<p>Setup TheHive to identify user by the configured HTTP header (THEHIVE_USER):  <pre><code>auth {\n  method.header = true\n  header.name = THEHIVE_USER\n}\n\n# Listen only on localhost to prevent direct access to TheHive\nhttp.address=127.0.0.1\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/cluster/","title":"Cluster Configuration","text":"<p>Starting from version 3.1.0, TheHive can scale horizontally very easily. You can dynamically add nodes to your cluster to increase the performance of the platform. TheHive API is stateless to the exclusion of the stream (or real-time flow). For this reason, the cluster nodes need to communicate with each other.</p> <p>The first node of the cluster has a specific role: it must initiate the cluster creation. Any additional node only needs to contact at least one node of the cluster to join it. This is done by configuring so-called seed nodes.</p> <p>The first node must have itself in the seed node list. The other nodes must have at least one entry corresponding to a node that has already joined the seed node list.</p> <p>Note : all cluster nodes must share the same secret (<code>play.http.secret.key</code> in <code>application.conf</code>).</p>"},{"location":"thehive/legacy/thehive3/admin/cluster/#configuration","title":"Configuration","text":"<p>Define <code>node1</code> (for example with IP address <code>10.0.0.1</code>) as the first node of the cluster. The configuration section in <code>application.conf</code> should look like the following: <pre><code>akka {\n  remote {\n    netty.tcp {\n      hostname = \"10.0.0.1\"\n      port = 2552\n    }\n  }\n  # seed node is itself as it is the first node of the cluster\n  cluster.seed-nodes = [\"akka.tcp://application@10.0.0.1:2552\"]\n}\n</code></pre></p> <p>Then add another node. Let's call it <code>node2</code> and assume its IP address is <code>10.0.0.2</code> to our one-node cluster. You can see that it is referring to the first node in <code>cluster.seed-nodes</code>: <pre><code>akka {\n  remote {\n    netty.tcp {\n      hostname = \"10.0.0.2\"\n      port = 2552\n    }\n  }\n  # seed node list contains at least one active node\n  cluster.seed-nodes = [\"akka.tcp://application@10.0.0.1:2552\"]\n}\n</code></pre></p> <p>We recommend defining several seed nodes in the respective configuration files, except for the first one. For example:</p> node configured seed nodes node1 node1 node2 node1, node3 node3 node2, node4 node4 node1, node2, node3"},{"location":"thehive/legacy/thehive3/admin/cluster/#load-balancing","title":"Load Balancing","text":"<p>In front of TheHive cluster, you can add a load balancer which distributes HTTP requests to cluster nodes. One client does not need to always use the same node  as affinity is not required.</p> <p>Below is an non-optimized example of a haproxy configuration: <pre><code># Global standard configuration, nothing specific for TheHive\nglobal\n        log /dev/log    local0\n        log /dev/log    local1 notice\n        chroot /var/lib/haproxy\n        stats socket /run/haproxy/admin.sock mode 660 level admin\n        stats timeout 30s\n        user haproxy\n        group haproxy\n        daemon\n\n        ca-base /etc/ssl/certs\n        crt-base /etc/ssl/private\n\n        ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS\n        ssl-default-bind-options no-sslv3\n\ndefaults\n        log     global\n        mode    http\n        option  httplog\n        option  dontlognull\n        timeout connect 500\n        timeout client  50000\n        # server timeout must be at least the stream.refresh parameter in application.conf\n        timeout server  2m\n        errorfile 400 /etc/haproxy/errors/400.http\n        errorfile 403 /etc/haproxy/errors/403.http\n        errorfile 408 /etc/haproxy/errors/408.http\n        errorfile 500 /etc/haproxy/errors/500.http\n        errorfile 502 /etc/haproxy/errors/502.http\n        errorfile 503 /etc/haproxy/errors/503.http\n        errorfile 504 /etc/haproxy/errors/504.http\n\n\n# Listen on all interfaces, on port 9000/tcp\nfrontend http-in\n        bind *:9000\n        default_backend servers\n\n    # Configure all cluster node\n    backend servers\n        balance roundrobin\n        server node1 10.0.0.1:9000 check\n        server node2 10.0.0.2:9000 check\n        server node3 10.0.0.3:9000 check\n        server node4 10.0.0.4:9000 check\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/cluster/#troubleshooting","title":"Troubleshooting","text":"<p>Should you encounter troubles with your setup, you can enable debug messages with the following configuration: <pre><code>akka {\n  actor {\n    debug {\n      receive = on\n      autoreceive = on\n      lifecycle = on\n      unhandled = on\n    }\n  }\n}\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/cluster/#additional-information","title":"Additional Information","text":"<p>TheHive Leverages Akka Cluster. You can refer to the  Akka documentation for additional information.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/","title":"Configuration Guide","text":"<p>The configuration file of TheHive is <code>/etc/thehive/application.conf</code> by default. This file uses the HOCON format. All configuration parameters should go in this file.</p> <p>You can have a look at the default settings.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#table-of-contents","title":"Table of Contents","text":"<ul> <li>1. Database</li> <li>2. Datastore</li> <li>3. Authentication<ul> <li>3.1 LDAP/AD</li> <li>3.2 OAuth2/OpenID Connect</li> </ul> </li> <li>4. Streaming (a.k.a The Flow)</li> <li>5. Entity size limit</li> <li>6. Cortex</li> <li>7. MISP<ul> <li>7.1 Configuration</li> <li>7.2 Associate a Case Template to Alerts corresponding to MISP events</li> <li>7.3 Event Filters</li> </ul> </li> <li>7.4 MISP Purpose</li> <li>8. HTTP Client Configuration</li> <li>9. Monitoring and Performance Metrics (deprecated)</li> <li>10. HTTPS<ul> <li>10.1 HTTPS using a reverse proxy</li> <li>10.2 HTTPS without reverse proxy</li> <li>10.3 Strengthen security</li> </ul> </li> </ul>"},{"location":"thehive/legacy/thehive3/admin/configuration/#1-database","title":"1. Database","text":"<p>TheHive uses the Elasticsearch search engine to store all persistent data. Elasticsearch is not part of TheHive package. It must be installed and configured as a standalone instance which can be located on the same machine. For more information on how to set up Elasticsearch, please refer to Elasticsearch installation guide.</p> <p>Three settings are required to connect to Elasticsearch:  * the base name of the index  * the name of the cluster  * the address(es) and port(s) of the Elasticsearch instance</p> <p>The Defaults settings are:</p> <pre><code># Elasticsearch\nsearch {\n  ## Basic configuration\n  # Index name.\n  index = the_hive\n  # ElasticSearch instance address.\n  uri = \"http://127.0.0.1:9200/\"\n\n  # Scroll keepalive\n  keepalive = 1m\n  # Size of the page for scroll\n  pagesize = 50\n  # Number of shards\n  nbshards = 5\n  # Number of replicas\n  nbreplicas = 1\n  # Arbitrary settings\n  settings {\n    # Maximum number of nested fields\n    mapping.nested_fields.limit = 100\n  }\n\n  ## Authentication configuration\n  #search.username = \"\"\n  #search.password = \"\"\n\n  ## SSL configuration\n  #search.keyStore {\n  #  path = \"/path/to/keystore\"\n  #  type = \"JKS\" # or PKCS12\n  #  password = \"keystore-password\"\n  #}\n  #search.trustStore {\n  #  path = \"/path/to/trustStore\"\n  #  type = \"JKS\" # or PKCS12\n  #  password = \"trustStore-password\"\n  #}\n }\n</code></pre> <p>If you use a different configuration, modify the parameters accordingly in the <code>application.conf</code> file.</p> <p>If multiple Elasticsearch nodes are used as a cluster, you should add addresses of the master nodes in the url like this:</p> <pre><code>search {\n    uri = http://node1:9200,node2:9200/\n   ...\n</code></pre> <p>TheHive uses the http port of Elasticsearch (9200/tcp by default).</p> <p>TheHive versions index schema (mapping) in Elasticsearch. Version numbers are appended to the index base name (the 8th version of the schema uses the index <code>the_hive_8</code> if <code>search.index = the_hive</code>).</p> <p>When too many documents are requested to TheHive, it uses the scroll feature: the results are retrieved through pagination. You can specify the size of the page (<code>search.pagesize</code>) and how long pages are kept in Elasticsearch ((<code>search.keepalive</code>) before purging.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#2-datastore","title":"2. Datastore","text":"<p>TheHive stores attachments as Elasticsearch documents. They are split in chunks and each chunk sent to Elasticsearch is identified by the hash of the entire attachment and the associated chunk number.</p> <p>The chunk size (<code>datastore.chunksize</code>) can be changed but any change will only affect new attachments. Existing ones won't be changed.</p> <p>An attachment is identified by its hash. The algorithm used is configurable (<code>datastore.hash.main</code>) but must not be changed after the first attachment insertion. Otherwise, previous files cannot be retrieved.</p> <p>Extra hash algorithms can be configured using <code>datastore.hash.extra</code>. These hashes are not used to identify the attachment but are shown in the user interface (the hash associated to the main algorithm is also shown). If you change extra algorithms, you should inform TheHive and ask it to recompute all hashes. Please note that the associated API call is currently disabled in Buckfast (v 2.10). It will be reinstated in the next release.</p> <p>Observables can contain malicious data. When you try to download an attachment from an observable (typically a file), it is automatically zipped and the resulting ZIP file is password-protected. The default password is malware but it can be changed with the <code>datastore.attachment.password</code> setting.</p> <p>Default values are:</p> <pre><code># Datastore\ndatastore {\n  name = data\n  # Size of stored data chunks\n  chunksize = 50k\n  hash {\n    # Main hash algorithm /!\\ Don't change this value\n    main = \"SHA-256\"\n    # Additional hash algorithms (used in attachments)\n    extra = [\"SHA-1\", \"MD5\"]\n  }\n  attachment.password = \"malware\"\n}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/configuration/#3-authentication","title":"3. Authentication","text":"<p>TheHive supports local, LDAP, Active Directory (AD) or OAuth2/OpenID Connect for authentication. By default, it relies on local credentials stored in Elasticsearch.</p> <p>Authentication methods are stored in the <code>auth.provider</code> parameter, which is multi-valued. When a user logs in, each authentication method is tried in order until one succeeds. If no authentication method works, an error is returned and the user cannot log in.</p> <p>The default values within the configuration file are: <pre><code>auth {\n  # \"provider\" parameter contains authentication provider. It can be multi-valued (useful for migration)\n  # available auth types are:\n  # services.LocalAuthSrv : passwords are stored in user entity (in Elasticsearch). No configuration is required.\n  # ad : use ActiveDirectory to authenticate users. Configuration is under \"auth.ad\" key\n  # ldap : use LDAP to authenticate users. Configuration is under \"auth.ldap\" key\n  # oauth2 : use OAuth/OIDC to authenticate users. Configuration is under \"auth.oauth2\" and \"auth.sso\" keys\n  provider = [local]\n\n  # By default, basic authentication is disabled. You can enable it by setting \"method.basic\" to true.\n  #method.basic = true\n\n  ad {\n    # The Windows domain name in DNS format. This parameter is required if you do not use\n    # 'serverNames' below.\n    #domainFQDN = \"mydomain.local\"\n\n    # Optionally you can specify the host names of the domain controllers instead of using 'domainFQDN\n    # above. If this parameter is not set, TheHive uses 'domainFQDN'.\n    #serverNames = [ad1.mydomain.local, ad2.mydomain.local]\n\n    # The Windows domain name using short format. This parameter is required.\n    #domainName = \"MYDOMAIN\"\n\n    # If 'true', use SSL to connect to the domain controller.\n    #useSSL = true\n  }\n\n  ldap {\n    # The LDAP server name or address. The port can be specified using the 'host:port'\n    # syntax. This parameter is required if you don't use 'serverNames' below.\n    #serverName = \"ldap.mydomain.local:389\"\n\n    # If you have multiple LDAP servers, use the multi-valued setting 'serverNames' instead.\n    #serverNames = [ldap1.mydomain.local, ldap2.mydomain.local]\n\n    # Account to use to bind to the LDAP server. This parameter is required.\n    #bindDN = \"cn=thehive,ou=services,dc=mydomain,dc=local\"\n\n    # Password of the binding account. This parameter is required.\n    #bindPW = \"***secret*password***\"\n\n    # Base DN to search users. This parameter is required.\n    #baseDN = \"ou=users,dc=mydomain,dc=local\"\n\n    # Filter to search user in the directory server. Please note that {0} is replaced\n    # by the actual user name. This parameter is required.\n    #filter = \"(cn={0})\"\n\n    # If 'true', use SSL to connect to the LDAP directory server.\n    #useSSL = true\n  }\n\n  oauth2 {\n    # URL of the authorization server\n    #clientId = \"client-id\"\n    #clientSecret = \"client-secret\"\n    #redirectUri = \"https://my-thehive-instance.example/api/ssoLogin\"\n    #responseType = \"code\"\n    #grantType = \"authorization_code\"\n\n    # URL from where to get the access token\n    #authorizationUrl = \"https://auth-site.com/OAuth/Authorize\"\n    #tokenUrl = \"https://auth-site.com/OAuth/Token\"\n\n    # The endpoint from which to obtain user details using the OAuth token, after successful login\n    #userUrl = \"https://auth-site.com/api/User\"\n    #scope = [\"openid profile\"]\n  }\n\n  # Single-Sign On\n  sso {\n    # Autocreate user in database?\n    #autocreate = false\n\n    # Autoupdate its profile and roles?\n    #autoupdate = false\n\n    # Autologin user using SSO?\n    #autologin = false\n    # Attributes mappings\n    #attributes {\n    #  login = \"sub\"\n    #  name = \"name\"\n    #  groups = \"groups\"\n    #  #roles = \"roles\"\n    #}\n\n    # Name of mapping class from user resource to backend user ('simple' or 'group')\n    #mapper = group\n    # Default roles for users with no groups mapped (\"read\", \"write\", \"admin\")\n    #defaultRoles = []\n\n    #groups {\n    #  # URL to retrieve groups (leave empty if you are using OIDC)\n    #  #url = \"https://auth-site.com/api/Groups\"\n    #  # Group mappings, you can have multiple roles for each group: they are merged\n    #  mappings {\n    #    admin-profile-name = [\"admin\"]\n    #    editor-profile-name = [\"write\"]\n    #    reader-profile-name = [\"read\"]\n    #  }\n    #}\n  }\n}\n\n# Maximum time between two requests without requesting authentication\nsession {\n  warning = 5m\n  inactivity = 1h\n}\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#31-ldapad","title":"3.1. LDAP/AD","text":"<p>To enable authentication using AD or LDAP, edit the <code>application.conf</code> file and supply the values for your environment. Then you need to create an account on TheHive for each AD or LDAP user in <code>Administration &gt; Users</code> page (which can only be accessed by an administrator). This is required as TheHive needs to look up the role associated with the user and that role is stored locally by TheHive. Obviously, you don't need to supply a password as TheHive will check the credentials against the remote directory.</p> <p>In order to use SSL on LDAP or AD, TheHive must be able to validate remote certificates. To that end, the Java truststore must contain certificate authorities used to generate the AD and/or LDAP certificates. The Default JVM truststore contains the main official authorities but LDAP and AD certificates are probably not issued by them.</p> <p>Use keytool to create the truststore: <pre><code>keytool -import -file /path/to/your/ca.cert -alias InternalCA -keystore /path/to/your/truststore.jks\n</code></pre></p> <p>Then add <code>-Djavax.net.ssl.trustStore=/path/to/your/truststore.jks</code> parameter when you start TheHive or put it in the <code>JAVA_OPTS</code> environment variable before starting TheHive.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#32-oauth2openid-connect","title":"3.2. OAuth2/OpenID Connect","text":"<p>To enable authentication using OAuth2/OpenID Connect, edit the <code>application.conf</code> file and supply the values of <code>auth.oauth2</code> according to your environment. In addition, you need to supply:</p> <ul> <li><code>auth.sso.attributes.login</code>: name of the attribute containing the OAuth2 user's login in retreived user info (mandatory)</li> <li><code>auth.sso.attributes.name</code>: name of the attribute containing the OAuth2 user's name in retreived user info (mandatory)</li> <li><code>auth.sso.attributes.groups</code>: name of the attribute containing the OAuth2 user's groups (mandatory using groups mappings)</li> <li><code>auth.sso.attributes.roles</code>: name of the attribute containing the OAuth2 user's roles in retreived user info (mandatory using simple mapping)</li> </ul>"},{"location":"thehive/legacy/thehive3/admin/configuration/#important-notes","title":"Important notes","text":"<p>Authenticate the user using an external OAuth2 authenticator server. The configuration is:</p> <ul> <li>clientId (string) client ID in the OAuth2 server.</li> <li>clientSecret (string) client secret in the OAuth2 server.</li> <li>redirectUri (string) the url of TheHive AOuth2 page (.../api/ssoLogin).</li> <li>responseType (string) type of the response. Currently only \"code\" is accepted.</li> <li>grantType (string) type of the grant. Currently only \"authorization_code\" is accepted.</li> <li>authorizationUrl (string) the url of the OAuth2 server.</li> <li>authorizationHeader (string) prefix of the authorization header to get user info: Bearer, token, ...</li> <li>tokenUrl (string) the token url of the OAuth2 server.</li> <li>userUrl (string) the url to get user information in OAuth2 server.</li> <li>scope (list of string) list of scope.</li> </ul>"},{"location":"thehive/legacy/thehive3/admin/configuration/#example","title":"Example","text":"<pre><code>auth {\n\n  provider = [local, oauth2]\n\n  [..]\n\n  sso {\n    autocreate: false\n    autoupdate: false\n    mapper: \"simple\"\n    attributes {\n      login: \"login\"\n      name: \"name\"\n      roles: \"role\"\n    }\n    defaultRoles: [\"read\", \"write\"]\n    defaultOrganization: \"demo\"\n  }  \n  oauth2 {\n    name: oauth2\n    clientId: \"Client_ID\"\n    clientSecret: \"Client_ID\"\n    redirectUri: \"http://localhost:9000/api/ssoLogin\"\n    responseType: code\n    grantType: \"authorization_code\"\n    authorizationUrl: \"https://github.com/login/oauth/authorize\"\n    authorizationHeader: \"token\"\n    tokenUrl: \"https://github.com/login/oauth/access_token\"\n    userUrl: \"https://api.github.com/user\"\n    scope: [\"user\"]\n  }\n\n  [..]  \n}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/configuration/#321-roles-mappings","title":"3.2.1. Roles mappings","text":"<p>You can choose a roles mapping with the <code>auth.sso.mapper</code> parameter. The available options are <code>simple</code> and <code>group</code>:</p> <ul> <li>Using simple mapping, we assume that the user info retrieved from <code>auth.oauth2.userUrl</code> contains the roles associated to the OAuth2 user. They can be: <code>read</code>, <code>write</code> or <code>admin</code>.</li> <li>Using groups mappings, we assume the retrieved user info contains groups that have to be associated to internal roles. In that case, you have to define mapppings in <code>auth.sso.groups.mappings</code>. If a user has multiple groups, mapped roles are merged. If you need to retreive groups from another endpoint that the one used for user info, you can provide it in <code>auth.sso.groups.url</code>.</li> </ul> <p>The retrieved groups can be a valid JSON array or a string listing them: <pre><code>{\n  \"sub\":    \"userid1\",\n  \"name\":   \"User name 1\",\n  \"groups\": [\"admin-profile-name\", \"reader-profile-name\"]\n}\n\nOR\n\n{\n  \"sub\":    \"userid2\",\n  \"name\":   \"User name 2\",\n  \"groups\": \"[admin-profile-name, reader-profile-name, \\\"another profile\\\", 'a last group']\"\n}\n\nOR\n\n{\n  \"sub\":    \"userid3\",\n  \"name\":   \"User name 3\",\n  \"groups\": \"the-only-group-of-the-user\"\n}\n</code></pre></p> <p>Finally, you can setup default roles associated with user with no roles/groups retrieved, using the <code>auth.sso.defaultRoles</code> parameter.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#322-user-autocreation-autoupdate-and-autologin","title":"3.2.2. User autocreation, autoupdate and autologin","text":"<p>The main advantage of OAuth2/OpenID Connect authentication is you won't need to create an account on TheHive for each OAuth2 user if you set the config parameter <code>auth.sso.autocreate</code> to <code>true</code>. However, by default, OAuth2 users won't be updated on SSO login unless you set <code>auth.sso.autoupdate</code> to <code>true</code>. If you set this last parameter, roles and name will be fetched from retrieved user info and will be updated in local database on each login of the user.</p> <p>With <code>auth.sso.autologin</code> set to <code>true</code>, each user connecting to TheHive will automatically be redirected to <code>auth.oauth2.authorizationUrl</code>. The only way to authenticate in TheHive using a local user will be either:</p> <ul> <li>Connecting to TheHive using <code>https://my-hive-instance.com/index.html#!/login?code=BAD_CODE</code>. You will get an <code>Authentication Failure</code> but will then be able to authenticate.</li> <li>Connecting to TheHive using a real OAuth2 account, then disconnect. On disconnection, you won't be redirected to authorization URL.</li> </ul>"},{"location":"thehive/legacy/thehive3/admin/configuration/#323-debugging","title":"3.2.3. Debugging","text":"<p>To debug the OAuth2 feature, you can uncomment the following lines in <code>/etc/thehive/logback.xml</code>: <pre><code>&lt;!-- Uncomment the next lines to log debug information for OAuth/OIDC login --&gt;\n&lt;logger name=\"org.elastic4play.services.auth\" level=\"DEBUG\" /&gt;\n&lt;logger name=\"services.OAuth2Srv\" level=\"DEBUG\" /&gt;\n&lt;logger name=\"services.mappers\" level=\"DEBUG\" /&gt;\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#4-streaming-aka-the-flow","title":"4. Streaming (a.k.a The Flow)","text":"<p>The user interface is automatically updated when data is changed in the back-end. To do this, the back-end sends events to all the connected front-ends. The mechanism used to notify the front-end is called long polling and its settings are:</p> <ul> <li><code>refresh</code> : when there is no notification, close the connection after this duration (the default is 1 minute).</li> <li><code>cache</code> : before polling a session must be created, in order to make sure no event is lost between two polls. If there is no poll during the <code>cache</code> setting, the session is destroyed (the default is 15 minutes).</li> <li><code>nextItemMaxWait</code>, <code>globalMaxWait</code> :  when an event occurs, it is not immediately sent to the front-ends. The back-end waits <code>nextItemMaxWait</code> and up to <code>globalMaxWait</code> in case another event can be included in the notification. This mechanism saves many HTTP requests.</li> </ul> <p>Default values are: <pre><code># Streaming\nstream.longpolling {\n  # Maximum time a stream request waits for new element\n  refresh = 1m\n  # Lifetime of the stream session without request\n  cache = 15m\n  nextItemMaxWait = 500ms\n  globalMaxWait = 1s\n}\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#5-entity-size-limit","title":"5. Entity size limit","text":"<p>The Play framework used by TheHive sets the HTTP body size limit to 100KB by default for textual content (json, xml, text, form data) and 10MB for file uploads. This could be too small in most cases so you may want to change it with the following settings in the <code>application.conf</code> file:</p> <pre><code># Max textual content length\nplay.http.parser.maxMemoryBuffer=1M\n# Max file size\nplay.http.parser.maxDiskBuffer=1G\n</code></pre> <p>Note: if you are using a NGINX reverse proxy in front of TheHive, be aware that it doesn't distinguish between text data and a file upload. So, you should also set the <code>client_max_body_size</code> parameter in your NGINX server configuration to the highest value among the two: file upload and text size defined in TheHive <code>application.conf</code> file.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#6-cortex","title":"6. Cortex","text":"<p>TheHive can use one or several Cortex analysis engines to get additional information on observables. When configured, analyzers available in Cortex become usable on TheHive. First you must enable <code>CortexConnector</code>, choose an identifier then specify the URL for each Cortex server: <pre><code>## Enable the Cortex module\nplay.modules.enabled += connectors.cortex.CortexConnector\n\ncortex {\n  \"CORTEX-SERVER-ID\" {\n    # URL of the Cortex server\n    url = \"http://CORTEX_SERVER:CORTEX_PORT\"\n    # Key of the Cortex user, mandatory for Cortex 2\n    key = \"API key\"\n  }\n  # HTTP client configuration, more details in section 8\n  # ws {\n  #   proxy {}\n  #   ssl {}\n  # }\n  # Check job update time interval\n  refreshDelay = 1 minute\n  # Maximum number of successive errors before give up\n  maxRetryOnError = 3\n  # Check remote Cortex status time interval\n  statusCheckInterval = 1 minute\n}\n</code></pre></p> <p>If you connect TheHive with Cortex 2, you must create a user in Cortex with the <code>read, analyze</code> roles, set an API key and add this key in the Cortex server definition in TheHive <code>application.conf</code>. For Cortex 1, authentication is not required, the key is not used.</p> <p>To create a user with the <code>read, analyze</code> role in Cortex 2, you must have at least one organization configured then you can connect to the Cortex 2 Web UI using a <code>orgAdmin</code> account for that organization to create the user and generate their API key. Please refer to the Cortex Quick Start Guide for more information.</p> <p>Cortex analyzes observables and outputs reports in JSON format. TheHive shows the report as-is by default. In order to make reports more readable, we provide report templates which are in a separate package and must be installed manually:  - download the report template package from https://dl.bintray.com/thehive-project/binary/report-templates.zip  - log in TheHive using an administrator account  - go to <code>Admin</code> &gt; <code>Report templates</code> menu  - click on <code>Import templates</code> button and select the downloaded package</p> <p>HTTP client used by Cortex connector use global configuration (in <code>play.ws</code>) but can be overridden in Cortex section and in each Cortex server configuration. Refer to section 8 for more detail on how to configure HTTP client.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#7-misp","title":"7. MISP","text":"<p>TheHive has the ability to connect to one or several MISP instances in order to import and export events. Hence TheHive is able to:</p> <ul> <li>receive events as they are added or updated from multiple MISP instances. These events will appear within the <code>Alerts</code> pane.</li> <li>export cases as MISP events to one or several MISP instances. The exported cases will not be published automatically though as they need to be reviewed prior to publishing. We strongly advise you to review the categories and types of attributes at least, before publishing the corresponding MISP events.</li> </ul> <p>Note: Please note that only and all the observables marked as IOCs will be used to create the MISP event. Any other observable will not be shared. This is not configurable.</p> <p>Within the configuration file, you can register your MISP server(s) under the <code>misp</code> configuration keyword. Each server shall be identified using an arbitrary name, its <code>url</code>, the corresponding authentication <code>key</code> and optional <code>tags</code> to add each observable created from a MISP event. Any registered server will be used to import events as alerts. It can also be used to export cases to as MISP events, if the account used by TheHive on the MISP instance has sufficient rights.</p> <p>This means that TheHive can import events from configured MISP servers and export cases to the same configured MISP servers. Having different configuration for sources and destination servers is expected in a future version.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#important-notes_1","title":"Important Notes","text":"<p>TheHive requires MISP 2.4.73 or better. Make sure that your are using a compatible version of MISP before reporting problems. MISP 2.4.72 and below do not work correctly with TheHive.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#71-configuration","title":"7.1 Configuration","text":"<p>To sync with a MISP server and retrieve events or export cases, edit the <code>application.conf</code> file and adjust the example shown below to your setup:</p> <pre><code>## Enable the MISP module (import and export)\nplay.modules.enabled += connectors.misp.MispConnector\n\nmisp {\n  \"MISP-SERVER-ID\" {\n    # URL of the MISP instance.\n    url = \"&lt;The_URL_of_the_MISP_Server_goes_here&gt;\"\n\n    # Authentication key.\n    key = \"&lt;the_auth_key_goes_here&gt;\"\n\n    # Name of the case template created in TheHive that shall be used to import\n    # MISP events as cases by default.\n    caseTemplate = \"&lt;Template_Name_goes_here&gt;\"\n\n    # Tags to add to each observable imported from an event available on\n    # this instance.\n    tags = [\"misp-server-id\"]\n\n    # Truststore to use to validate the X.509 certificate  of  the  MISP\n    # instance if the default truststore is not sufficient.\n    #ws.ssl.trustManager.stores = [\n    #{\n    #  type: \"JKS\"\n    #  path: \"/path/to/truststore.jks\"\n    #}\n    #]\n\n    # HTTP client configuration, more details in section 8\n    # ws {\n    #   proxy {}\n    #   ssl {}\n    # }\n\n    # filters:\n    max-attributes = 1000\n    max-size = 1 MiB\n    max-age = 7 days\n    exclusion {\n     organisation = [\"bad organisation\", \"other orga\"]\n     tags = [\"tag1\", \"tag2\"]\n    }\n    whitelist.tags = [\"whitelist-tag1\", \"whitelist-tag2\"]\n\n    # MISP purpose defines if this instance can be used to import events (ImportOnly), export cases (ExportOnly) or both (ImportAndExport)\n    # Default is ImportAndExport\n    purpose = ImportAndExport\n  }\n\n  # Check remote TheHive status time interval\n  statusCheckInterval = 1 minute\n\n  # Interval between consecutive MISP event  imports  in  hours  (h)  or\n  # minutes (m).\n  interval = 1h\n}\n</code></pre> <p>The HTTP client used by the MISP connector uses a global configuration (in <code>play.ws</code>) but it can be overridden within the MISP section of the configuation file and/or in the configuration section of each MISP server (in <code>misp.MISP-SERVER-ID.ws</code>). Refer to section 8 for more details on how to configure the HTTP client.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#72-associate-a-case-template-to-alerts-corresponding-to-misp-events","title":"7.2 Associate a Case Template to Alerts corresponding to MISP events","text":"<p>As stated in the subsection above, TheHive is able to automatically import MISP events (they will appear as alerts within the <code>Alerts</code> pane) and create cases out of them. This operation leverages the template engine. Thus you'll need to create a case template prior to importing MISP events.</p> <p>First, create a case template. Let's call it MISP-EVENT.</p> <p></p> <p>Then update TheHive's configuration to add a 'caseTemplate' parameter as shown in the example below:</p> <pre><code>misp {\n  \"MISP-SERVER-ID\" {\n    # URL of the MISP server\n    url = \"&lt;The_URL_of_the_MISP_Server_goes_here&gt;\"\n    # authentication key\n    key = \"&lt;the_auth_key_goes_here&gt;\"\n    # tags that must be automatically added to the case corresponding to the imported event\n    tags = [\"misp\"]\n    # case template\n    caseTemplate = \"MISP-EVENT\"\n  }\n</code></pre> <p>Once the configuration file has been edited, restart TheHive. Every new import of a MISP event will generate a case using to the MISP-EVENT template by default. The template can be overridden though during the event import.</p> <p>MISP events will only be imported by TheHive if they have at least one attribute and were published.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#73-event-filters","title":"7.3 Event Filters","text":"<p>When you first connect TheHive to a MISP instance, you can be overwhelmed by the number of alerts that will be generated, particularly if the MISP instance contains a lot of events. Indeed, every event, even those that date back to the beginning of the Internet, will generate an alert. To avoid alert fatigue, and starting from TheHive 3.0.4 (Cerana 0.4), you can exclude MISP events using different filters:</p> <ul> <li>the maximum number of attributes (max-attributes)</li> <li>the maximum size of the event's JSON message (max-size)</li> <li>the maximum age of the last publication (max-age)</li> <li>the organisation is black-listed (exclusion.organisation)</li> <li>one of the tags is black-listed (exclusion.tags)</li> <li>doesn't contain one of the whitelist tag (whitelist.tags)</li> </ul> <p>Please note that MISP event filters can be adapted to the configuration associated to each MISP server TheHive is connected with. As regards the <code>max-age</code> filter, it applies to the publication date of MISP events and not to the creation date.</p> <p>In the example below, the following MISP events won't generate alerts in TheHive:</p> <ul> <li>events that have more than 1000 attributes</li> <li>events which JSON message size is greater than 1MB</li> <li>events that have been published more than one week from the current date</li> <li>events that have been created by <code>bad organisation</code> or <code>other orga</code></li> <li>events that contain <code>tag1</code> or <code>tag2</code></li> </ul> <pre><code>    # filters:\n    max-attributes = 1000\n    max-size = 1 MiB\n    max-age = 7 days\n    exclusion {\n     organisation = [\"bad organisation\", \"other orga\"]\n     tags = [\"tag1\", \"tag2\"]\n    }\n</code></pre> <p>Of course, you can omit some of the filters or all of them.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#74-misp-purpose","title":"7.4 MISP Purpose","text":"<p>TheHive can interact with MISP in two ways: import a MISP event to create a case in TheHive and export a TheHive case to create a MISP event. By default, any MISP instance that is added to TheHive's configuration will be used for importing events and exporting cases (<code>ImportAndExport</code>). If you want to use MISP in only one way, you can set its purpose in the configuration as <code>ImportOnly</code> or <code>ExportOnly</code>.</p> <p>Starting from TheHive 3.3, when exporting a case to a MISP instance, you can export all its tags to the freshly created MISP event. This behaviour is not enabled by default. If you want to enable it you must set the <code>exportCaseTags</code> variable to <code>true</code> as shown below:</p> <pre><code>misp {\n  \"local\" {\n    url = \"http://127.0.0.1\"\n    key = \"&lt;the_auth_key_goes_here&gt;\"\n    exportCaseTags = true\n    [...] # additional parameters go here\n  }\n}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/configuration/#8-http-client-configuration","title":"8. HTTP Client Configuration","text":"<p>HTTP client can be configured by adding <code>ws</code> key in sections that needs to connect to remote HTTP service. The key can contain configuration items defined in play WS configuration:</p> <ul> <li><code>ws.followRedirects</code>: Configures the client to follow 301 and 302 redirects (default is true).</li> <li><code>ws.useragent</code>: To configure the User-Agent header field.</li> <li><code>ws.compressionEnabled</code>: Set it to true to use gzip/deflater encoding (default is false).</li> </ul>"},{"location":"thehive/legacy/thehive3/admin/configuration/#timeouts","title":"Timeouts","text":"<p>There are 3 different timeouts in WS. Reaching a timeout causes the WS request to interrupt.  - <code>ws.timeout.connection</code>: The maximum time to wait when connecting to the remote host (default is 120 seconds).  - <code>ws.timeout.idle</code>: The maximum time the request can stay idle (connection is established but waiting for more data) (default is 120 seconds).  - <code>ws.timeout.request</code>: The total time you accept a request to take (it will be interrupted even if the remote host is still sending data) (default is 120 seconds).</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#proxy","title":"Proxy","text":"<p>Proxy can be used. By default, the proxy configured in JVM is used but one can configured specific configurations for each HTTP client.  - <code>ws.useProxyProperties</code>: To use the JVM system\u2019s HTTP proxy settings (http.proxyHost, http.proxyPort) (default is true). This setting is ignored if <code>ws.proxy</code> settings is present.  - <code>ws.proxy.host</code>: The hostname of the proxy server.  - <code>ws.proxy.post</code>: The port of the proxy server.  - <code>ws.proxy.protocol</code>: The protocol of the proxy server.  Use \"http\" or \"https\".  Defaults to \"http\" if not specified.  - <code>ws.proxy.user</code>: The username of the credentials for the proxy server.  - <code>ws.proxy.password</code>: The password for the credentials for the proxy server.  - <code>ws.proxy.ntlmDomain</code>: The password for the credentials for the proxy server.  - <code>ws.proxy.encoding</code>: The realm's charset.  - <code>ws.proxy.nonProxyHosts</code>: The list of hosts on which proxy must not be used.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#ssl","title":"SSL","text":"<p>SSL of HTTP client can be completely configured in <code>application.conf</code> file.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#certificate-manager","title":"Certificate manager","text":"<p>Certificate manager is used to store client certificates and certificate authorities.</p> <p><code>keyManager</code> indicates which certificate HTTP client can use to authenticate itself on remote host (when certificate based authentication is used) <pre><code>  ws.ssl.keyManager {\n    stores = [\n      {\n        type: \"pkcs12\" // JKS or PEM\n        path: \"mycert.p12\"\n        password: \"password1\"\n      }\n    ]\n  }\n</code></pre> Certificate authorities are configured using <code>trustManager</code> key. It is used to establish a secure connection with remote host. Server certificate must be signed by a trusted certificate authority. <pre><code>  ws.ssl.trustManager {\n    stores = [\n      {\n        type: \"JKS\" // JKS or PEM\n        path: \"keystore.jks\"\n        password: \"password1\"\n      }\n    ]\n  }\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#debugging","title":"Debugging","text":"<p>To debug the key manager / trust manager, set the following flags: <pre><code>  ws.ssl.debug = {\n    ssl = true\n    trustmanager = true\n    keymanager = true\n    sslctx = true\n    handshake = true\n    verbose = true\n    data = true\n    certpath = true\n  }\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#protocols","title":"Protocols","text":"<p>If you want to define a different default protocol, you can set it specifically in the client: <pre><code>ws.ssl.protocol = \"TLSv1.2\"\n</code></pre> If you want to define the list of enabled protocols, you can do so explicitly: <pre><code>ws.ssl.enabledProtocols = [\"TLSv1.2\", \"TLSv1.1\", \"TLSv1\"]\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#ciphers","title":"Ciphers","text":"<p>Cipher suites can be configured using <code>ws.ssl.enabledCipherSuites</code>: <pre><code>ws.ssl.enabledCipherSuites = [\n  \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\",\n  \"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n  \"TLS_DHE_RSA_WITH_AES_256_GCM_SHA384\",\n  \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n]\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#9-monitoring-and-performance-metrics-deprecated","title":"9. Monitoring and Performance Metrics (deprecated)","text":"<p>Performance metrics (response time, call rate to Elasticsearch and HTTP request, throughput, memory used...) can be collected if enabled in configuration.</p> <p>Enable it by editing the <code>application.conf</code> file, and add:</p> <pre><code># Register module for dependency injection\nplay.modules.enabled += connectors.metrics.MetricsModule\n\nmetrics.enabled = true\n</code></pre> <p>These metrics can optionally be sent to an external database (graphite, ganglia or influxdb) in order to monitor the health of the platform. This feature is disabled by default.</p> <pre><code>metrics {\n    name = default\n    enabled = true\n    rateUnit = SECONDS\n    durationUnit = SECONDS\n    showSamples = false\n    jvm = true\n    logback = true\n\n    graphite {\n        enabled = false\n        host = \"127.0.0.1\"\n        port = 2003\n        prefix = thehive\n        rateUnit = SECONDS\n        durationUnit = MILLISECONDS\n        period = 10s\n    }\n\n    ganglia {\n        enabled = false\n        host = \"127.0.0.1\"\n        port = 8649\n        mode = UNICAST\n        ttl = 1\n        version = 3.1\n        prefix = thehive\n        rateUnit = SECONDS\n        durationUnit = MILLISECONDS\n        tmax = 60\n        dmax = 0\n        period = 10s\n    }\n\n    influx {\n        enabled = false\n        url = \"http://127.0.0.1:8086\"\n        user = root\n        password = root\n        database = thehive\n        retention = default\n        consistency = ALL\n        #tags = {\n        #    tag1 = value1\n        #    tag2 = value2\n        #}\n        period = 10s\n    }\n}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/configuration/#10-https","title":"10. HTTPS","text":"<p>You can enable HTTPS on TheHive application or add a reverse proxy in front of TheHive. The latter solution is recommended.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#101-https-using-a-reverse-proxy","title":"10.1 HTTPS using a reverse proxy","text":"<p>You can choose any reverse proxy to add SSL on TheHive. Below an example of NGINX configuration: <pre><code>    server {\n            listen 443 ssl;\n            server_name thehive.example.com;\n\n            ssl_certificate         ssl/thehive_cert.pem;\n            ssl_certificate_key     ssl/thehive_key.pem;\n\n            proxy_connect_timeout   600;\n            proxy_send_timeout      600;\n            proxy_read_timeout      600;\n            send_timeout            600;\n            client_max_body_size    2G;\n            proxy_buffering off;\n            client_header_buffer_size 8k;\n\n            location / {\n                    add_header              Strict-Transport-Security \"max-age=31536000; includeSubDomains\";\n                    proxy_pass              http://127.0.0.1:9000/;\n                    proxy_http_version      1.1;\n                    proxy_set_header Connection \"\"; # cf. https://github.com/akka/akka/issues/19542\n            }\n    }\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#102-https-without-reverse-proxy","title":"10.2 HTTPS without reverse proxy","text":"<p>This is not supported.</p>"},{"location":"thehive/legacy/thehive3/admin/configuration/#103-strengthen-security","title":"10.3 Strengthen security","text":"<p>When SSL is enable (with reverse proxy or not), you can configure cookie to be \"secure\" (usable only with HTTPS protocol). This is done by adding <code>play.http.session.secure=true</code> in the application.conf file.</p> <p>You can also enable HSTS. This header must be configured on the SSL termination component. For NGINX, use <code>add_header</code> directive, as show above.</p>"},{"location":"thehive/legacy/thehive3/admin/default-configuration/","title":"Default configuration","text":"<p>You can find the default configuration settings of TheHive below:</p> <pre><code># maximum number of similar cases\nmaxSimilarCases = 100\n\n# ElasticSearch\nsearch {\n  # Name of the index\n  index = the_hive\n  # Name of the ElasticSearch cluster\n  cluster = hive\n  # Address of the ElasticSearch instance\n  host = [\"127.0.0.1:9300\"]\n  # Scroll keepalive\n  keepalive = 1m\n  # Size of the page for scroll\n  pagesize = 50\n  # Arbitrary settings\n  settings {\n    # Maximum number of nested fields\n    mapping.nested_fields.limit = 50\n  }\n}\n\n# Datastore\ndatastore {\n  # Size of stored data chunks\n  chunksize = 50k\n  hash {\n    # Main hash algorithm /!\\ Don't change this value\n    main = \"SHA-256\"\n    # Additional hash algorithms (used in attachments)\n    extra = [\"SHA-1\", \"MD5\"]\n  }\n  attachment.password = \"malware\"\n}\n\nauth {\n    # \"provider\" parameter contains authentication provider. It can be multi-valued (useful for migration)\n    # available auth types are:\n    # local : passwords are stored in user entity (in ElasticSearch). No configuration are required.\n    # ad : use ActiveDirectory to authenticate users. Configuration is under \"auth.ad\" key\n    # ldap : use LDAP to authenticate users. Configuration is under \"auth.ldap\" key\n    provider = [local]\n\n    ad {\n        # The name of the Microsoft Windows domaine using the DNS format. This parameter is required.\n        #domainFQDN = \"mydomain.local\"\n\n    # Optionally you can specify the host names of the domain controllers. If not set, TheHive uses \"domainFQDN\".\n    #serverNames = [ad1.mydomain.local, ad2.mydomain.local]\n\n        # The Microsoft Windows domain name using the short format. This parameter is required.\n        #domainName = \"MYDOMAIN\"\n\n        # Use SSL to connect to the domain controller(s).\n        #useSSL = true\n    }\n\n    ldap {\n        # LDAP server name or address. Port can be specified (host:port). This parameter is required.\n        #serverName = \"ldap.mydomain.local:389\"\n\n    # If you have multiple ldap servers, use the multi-valued settings.\n    #serverNames = [ldap1.mydomain.local, ldap2.mydomain.local]\n\n        # Use SSL to connect to directory server\n        #useSSL = true\n\n        # Account to use to bind on LDAP server. This parameter is required.\n        #bindDN = \"cn=thehive,ou=services,dc=mydomain,dc=local\"\n\n        # Password of the binding account. This parameter is required.\n        #bindPW = \"***secret*password***\"\n\n        # Base DN to search users. This parameter is required.\n        #baseDN = \"ou=users,dc=mydomain,dc=local\"\n\n        # Filter to search user {0} is replaced by user name. This parameter is required.\n        #filter = \"(cn={0})\"\n    }\n}\n\n# Maximum time between two requests without requesting authentication\nsession {\n  warning = 5m\n  inactivity = 1h\n}\n\n# Streaming\nstream.longpolling {\n  # Maximum time a stream request waits for new element\n  refresh = 1m\n  # Lifetime of the stream session without request\n  cache = 15m\n  nextItemMaxWait = 500ms\n  globalMaxWait = 1s\n}\n\n# Cortex configuration\n########\n\ncortex {\n  #\"CORTEX-SERVER-ID\" {\n  #  # URL of MISP server\n  #  url = \"\"\n  #  #HTTP client configuration, more details in section 8\n  #  ws {\n  #    ws.useProxyProperties = true\n  #    proxy {\n  #      # The hostname of the proxy server.\n  #      #host = \"\"\n  #      # The port of the proxy server.\n  #      #post = 0\n  #      # The protocol of the proxy server.  Use \"http\" or \"https\".  Defaults to \"http\" if not specified.\n  #      #protocol = \"http\"\n  #      # The username of the credentials for the proxy server.\n  #      #user = \"\"\n  #      # The password for the credentials for the proxy server.\n  #      #password = \"\"\n  #      # The password for the credentials for the proxy server.\n  #      #ntlmDomain = \"\"\n  #      # The realm's charset.\n  #      #encoding = \"\"\n  #      # The list of host on which proxy must not be used.\n  #      #nonProxyHosts = \"\"\n  #    }\n  #    ssl {\n  #      keyManager { # used for client certificate authentication\n  #        stores = [{\n  #          type: \"pkcs12\" // JKS or PEM\n  #          path: \"mycert.p12\"\n  #          password: \"password1\"\n  #        }]\n  #      }\n  #      # Add certificate authorities to trust remote certificate  \n  #      trustManager {\n  #        stores = [{\n  #          type: \"JKS\" // JKS or PEM\n  #          path: \"keystore.jks\"\n  #          password: \"password1\"\n  #        }]\n  #     }\n  #     debug = {\n  #       ssl = false\n  #       trustmanager = false\n  #       keymanager = false\n  #       sslctx = false\n  #       handshake = false\n  #       verbose = false\n  #       data = false\n  #       certpath = false\n  #     }\n  #\n  #     # default SSL protocol\n  #     #protocol = \"TLSv1.2\"\n  #\n  #     # list of enabled SSL protocols\n  #     #ws.ssl.enabledProtocols = [\"TLSv1.2\", \"TLSv1.1\", \"TLSv1\"]\n  #\n  #     # SSL Cipher suite\n  #     #enabledCipherSuites = [\n  #     #  \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\",\n  #     #  \"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n  #     #  \"TLS_DHE_RSA_WITH_AES_256_GCM_SHA384\",\n  #     #  \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n  #     #]\n  #    }\n  #  }\n  #}\n}\n\n# MISP configuration\n########\n\nmisp {\n  #\"MISP-SERVER-ID\" {\n  #  # URL of MISP server\n  #  url = \"\"\n  #  # authentication key\n  #  key = \"\"\n  #  #tags to be added to imported artifact\n  #  tags = [\"misp\"]\n  #\n  #  # filters:\n  #  # the maximum number of attributes (max-attributes)\n  #  #max-attributes = 1000\n  #  # the maximum size of the event json message\n  #  #max-size = 1 MiB\n  #  # the age of the last publication\n  #  #max-age = 7 days\n  #  exclusion {\n  #  # the organisation is black-listed  \n  #  #organisation = [\"bad organisation\", \"other orga\"]\n  #  # one of the tags is black-listed\n  #  #tags = [\"tag1\", \"tag2\"]\n  #  }\n  #\n  #  ws {\n  #    ws.useProxyProperties = true\n  #    proxy {\n  #      # The hostname of the proxy server.\n  #      #host = \"\"\n  #      # The port of the proxy server.\n  #      #post = 0\n  #      # The protocol of the proxy server.  Use \"http\" or \"https\".  Defaults to \"http\" if not specified.\n  #      #protocol = \"http\"\n  #      # The username of the credentials for the proxy server.\n  #      #user = \"\"\n  #      # The password for the credentials for the proxy server.\n  #      #password = \"\"\n  #      # The password for the credentials for the proxy server.\n  #      #ntlmDomain = \"\"\n  #      # The realm's charset.\n  #      #encoding = \"\"\n  #      # The list of host on which proxy must not be used.\n  #      #nonProxyHosts = \"\"\n  #    }\n  #\n  #    ssl {\n  #      keyManager { # used for client certificate authentication\n  #        stores = [{\n  #          type: \"pkcs12\" // JKS or PEM\n  #          path: \"mycert.p12\"\n  #          password: \"password1\"\n  #        }]\n  #      }\n  #      # Add certificate authorities to trust remote certificate  \n  #      trustManager {\n  #        stores = [{\n  #          type: \"JKS\" // JKS or PEM\n  #          path: \"keystore.jks\"\n  #          password: \"password1\"\n  #        }]\n  #     }\n  #     debug = {\n  #       ssl = false\n  #       trustmanager = false\n  #       keymanager = false\n  #       sslctx = false\n  #       handshake = false\n  #       verbose = false\n  #       data = false\n  #       certpath = false\n  #     }\n  #\n  #     # default SSL protocol\n  #     #protocol = \"TLSv1.2\"\n  #\n  #     # list of enabled SSL protocols\n  #     #ws.ssl.enabledProtocols = [\"TLSv1.2\", \"TLSv1.1\", \"TLSv1\"]\n  #\n  #     # SSL Cipher suite\n  #     #enabledCipherSuites = [\n  #     #  \"TLS_DHE_RSA_WITH_AES_128_GCM_SHA256\",\n  #     #  \"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\n  #     #  \"TLS_DHE_RSA_WITH_AES_256_GCM_SHA384\",\n  #     #  \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\n  #     #]\n  #    }\n  #  }\n\n  #}\n\n  # Interval between two MISP event import\n  interval = 1h\n\n}\n\n# Metrics configuration\n########\n\nmetrics {\n  name = default\n  enabled = false\n  rateUnit = SECONDS\n  durationUnit = SECONDS\n  jvm = true\n  logback = true\n\n  graphite {\n    enabled = false\n    host = \"127.0.0.1\"\n    port = 2003\n    prefix = thehive\n    rateUnit = SECONDS\n    durationUnit = MILLISECONDS\n    period = 10s\n  }\n\n  ganglia {\n    enabled = false\n    host = \"127.0.0.1\"\n    port = 8649\n    mode = UNICAST\n    ttl = 1\n    version = 3.1\n    prefix = thehive\n    rateUnit = SECONDS\n    durationUnit = MILLISECONDS\n    tmax = 60\n    dmax = 0\n    period = 10s\n  }\n\n  influx {\n    enabled = false\n    url = \"http://127.0.0.1:8086\"\n    user = root\n    password = root\n    database = thehive\n    retention = default\n    consistency = ALL\n    #tags = {\n    #   tag1 = value1\n    #   tag2 = value2\n    #}\n    period = 10s\n  }\n}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/schema_version/","title":"Schema version","text":"<p>The data of TheHive is stored in an ElasticSearch index. The name of the index is suffixed by the revision of the schema. When the schema of TheHive database changes, a new one is created and the version is incremented. By default, index base name is \"the_hive\" but can be configured (<code>index.index</code> in application.conf).</p> <p>The following table show for each version of TheHive the default name of the index:</p> TheHive version Index name 2.9.1 the_hive_7 2.9.2 the_hive_7 2.10.0 the_hive_8 2.10.1 the_hive_8 2.10.2 the_hive_8 2.11.0 the_hive_9 2.11.1 the_hive_9 2.11.2 the_hive_9 2.11.3 the_hive_9 2.12.0 the_hive_10 2.12.1 the_hive_10 2.13.0 the_hive_10 2.13.1 the_hive_10 2.13.2 the_hive_11 3.0.0 the_hive_12 3.0.1 the_hive_12 3.0.2 the_hive_12 3.0.3 the_hive_12 3.0.4 the_hive_13"},{"location":"thehive/legacy/thehive3/admin/updating/","title":"Update TheHive","text":"<p>TheHive is simple to update. You only need to replace your current package files by new ones. If the schema of the data changes between the two versions, the first request to the application asks the user to start a data migration. In this case, authentication is not required.</p> <p></p> <p>This process creates a new index in ElasticSearch (suffixed by the version of the schema) and copies all the data on it (before adapting its format). It is always possible to rollback to the previous version but all modifications done on the new version will be lost.</p>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/","title":"Upgrade to thehive 3 4 and es 6 x","text":"<p>This document is related to upgrading TheHive and Elasticsearch on Ubuntu 16.04.</p>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#upgrade-thehive-to-version-34","title":"Upgrade TheHive to version 3.4","text":""},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#perform-a-backup-of-data","title":"Perform a backup of data","text":"<pre><code>curl -XPUT 'http://localhost:9200/_snapshot/the_hive_backup' -d '{\n    \"type\": \"fs\",\n    \"settings\": {\n        \"location\": \"/absolute/path/to/backup/directory\",\n        \"compress\": true\n    }\n}'\n</code></pre> <p>For example: </p> <pre><code>curl -XPUT 'http://localhost:9200/_snapshot/the_hive_backup' -d '{\n    \"type\": \"fs\",\n    \"settings\": {\n        \"location\": \"/opt/backup\",\n        \"compress\": true\n    }\n}'\n</code></pre> <p>Next:</p> <pre><code>curl -XPUT 'http://localhost:9200/_snapshot/the_hive_backup/snapshot_1?wait_for_completion=true&amp;pretty' -d '{\n  \"indices\": \"&lt;INDEX&gt;\"\n}'\n</code></pre> <p>For example:</p> <pre><code>curl -XPUT 'http://localhost:9200/_snapshot/the_hive_backup/the_hive_152019060701_1?wait_for_completion=true&amp;pretty' -d '{\n  \"indices\": \"the_hive_15\"\n}'\n</code></pre> <p>Output example:</p> <pre><code>{\n\"snapshot\" : {\n\"snapshot\" : \"the_hive_152019060701_1\",\n\"uuid\" : \"ZKhBL2BHTAS2g71Xby2OgQ\",\n\"version_id\" : 5061699,\n\"version\" : \"5.6.16\",\n\"indices\" : [\n\"the_hive_15\"\n],\n\"state\" : \"SUCCESS\",\n\"start_time\" : \"2019-06-07T13:07:38.844Z\",\n\"start_time_in_millis\" : 1559912858844,\n\"end_time\" : \"2019-06-07T13:07:40.640Z\",\n\"end_time_in_millis\" : 1559912860640,\n\"duration_in_millis\" : 1796,\n\"failures\" : [ ],\n\"shards\" : {\n\"total\" : 5,\n\"failed\" : 0,\n\"successful\" : 5\n}\n}\n}\n</code></pre> <p>You can find more information about backup and restore in the dedicated documentation. </p>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#stop-thehive-service","title":"Stop TheHive service","text":"<pre><code>service thehive stop\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#update-thehive-configuration","title":"Update TheHive configuration","text":"<p>Current <code>/etc/thehive/application.conf</code></p> <pre><code># Elasticsearch\nsearch {\n  ## Basic configuration\n  # Index name.\n  index = the_hive\n  # ElasticSearch cluster name.\n  cluster = hive\n  # ElasticSearch instance address.\n  #host = [\"127.0.0.1:9300\"]\n[..]\n}\n</code></pre> <p>New /etc/thehive/application.conf :</p> <pre><code> Elasticsearch\nsearch {\n  ## Basic configuration\n  # Index name.\n  index = the_hive\n  # ElasticSearch instance address.\n  uri = \"http://127.0.0.1:9200\"\n  []\n}\n\ncluster {\n  name = hive\n}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#upgrade-thehive","title":"Upgrade TheHive","text":"<pre><code>apt upgrade thehive\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#restart-thehive-service","title":"Restart TheHive service","text":"<p>Ensure everything is working.</p>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#upgrade-elasticsearch-from-version-5x-to-6x","title":"Upgrade Elasticsearch from version 5.x to 6.x","text":"<p>This is greatly inspired by the official documentation : https://www.elastic.co/guide/en/elasticsearch/reference/6.0/rolling-upgrades.html with additional info we had to set up to make everything work.</p> <p>Upgrading from earlier 5.x versions requires a full cluster restart. </p>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#disable-shard-allocation","title":"Disable shard allocation","text":"<pre><code>curl -X PUT \"localhost:9200/_cluster/settings\" -H 'Content-Type: application/json' -d'\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.enable\": \"none\"\n  }\n}\n'\n</code></pre> <p>Output:</p> <pre><code>{\"acknowledged\":true,\"persistent\":{\"cluster\":{\"routing\":{\"allocation\":{\"enable\":\"none\"}}}},\"transient\":{}}\n</code></pre> <pre><code>curl -X POST \"localhost:9200/_flush/synced\"\n</code></pre> <p>Output :</p> <pre><code>{\"_shards\":{\"total\":60,\"successful\":30,\"failed\":0},\"cortex_4\":{\"total\":10,\"successful\":5,\"failed\":0},\"cortex_2\":{\"total\":10,\"successful\":5,\"failed\":0},\"cortex_3\":{\"total\":10,\"successful\":5,\"failed\":0},\"the_hive_13\":{\"total\":10,\"successful\":5,\"failed\":0},\"the_hive_15\":{\"total\":10,\"successful\":5,\"failed\":0},\"the_hive_14\":{\"total\":10,\"successful\":5,\"failed\":0}}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#shut-down-a-single-node","title":"shut down a single node","text":"<pre><code>sudo -i service elasticsearch stop\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#upgrade-the-node-you-shut-down","title":"Upgrade the node you shut down","text":"<pre><code>wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -\nsudo apt-get install apt-transport-https\necho \"deb https://artifacts.elastic.co/packages/6.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list\nsudo apt-get update &amp;&amp; sudo apt-get install elasticsearch\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#upgrade-plugins","title":"Upgrade plugins","text":"<pre><code>/usr/share/elasticsearch/bin/elasticsearch-plugin list\n## for all plugin:\n/usr/share/elasticsearch/bin/elasticsearch-plugin install $plugin\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#update-elasticsearch-configuration","title":"Update Elasticsearch configuration","text":"<p>Add <code>path.logs</code> and <code>path.data</code> in `/etc/elasticsearch/elasticsearch.yml:</p> <pre><code>http.host: 127.0.0.1\ntransport.host: 127.0.0.1\ncluster.name: hive\nthread_pool.index.queue_size: 100000\nthread_pool.search.queue_size: 100000\nthread_pool.bulk.queue_size: 100000\npath.repo: [\"/opt/backup\"]\npath.logs: \"/var/log/elasticsearch\"\npath.data: \"/var/lib/elasticsearch\"\n</code></pre> <p>Set <code>$JAVA_HOME</code> in <code>/etc/default/elasticsearch</code> for example:</p> <pre><code>[..]\nJAVA_HOME=/usr/lib/jvm/java-8-oracle/\n[..]\n</code></pre> <p>On Ubuntu 16.04 we had to set read persmissions manually to this file: </p> <pre><code>chmod o+r /etc/default/elasticsearch\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#restart-the-node","title":"Restart the node","text":"<pre><code>sudo update-rc.d elasticsearch defaults 95 10\nsudo -i service elasticsearch start\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#check-that-elasticsearch-is-running","title":"Check that elasticsearch is running","text":"<pre><code>curl -X GET \"localhost:9200/\"\ncurl -X GET \"localhost:9200/_cat/nodes\"\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#reenable-shard-allocation","title":"Reenable shard allocation","text":"<p>Once the node has joined the cluster:</p> <pre><code>curl -X PUT \"localhost:9200/_cluster/settings\" -H 'Content-Type: application/json' -d'\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.enable\": null\n  }\n}\n'\n</code></pre> <p>Output:</p> <pre><code>{\"acknowledged\":true,\"persistent\":{},\"transient\":{}}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#wait-for-the-node-to-recover","title":"Wait for the node to recover","text":"<p>Before upgrading the next node, wait for the cluster to finish shard allocation. You can check progress by submitting a <code>_cat/health</code> request:</p> <pre><code>curl -X GET \"localhost:9200/_cat/health?v\"\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_4_and_es_6_x/#resources","title":"Resources","text":"<ul> <li>https://www.elastic.co/guide/en/elasticsearch/reference/6.0/rolling-upgrades.html</li> <li>https://www.elastic.co/guide/en/elasticsearch/reference/6.0/restart-upgrade.html</li> <li>https://www.elastic.co/guide/en/elasticsearch/reference/6.0/deb.html</li> </ul>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/","title":"Migration from Elasticsearch 6.8.2 to ES 7.x","text":"<p>\u26a0\ufe0f IMPORTANT NOTE</p> <ul> <li>This migration process is intended for single node of Elasticsearch database</li> <li>The current version of this document is provided for testing purpose ONLY! </li> <li>This guide has been written and tested to migrate data from ES 6.8.2 to ES 7.8.1, and TheHive 3.4.2 to TheHive 3.5.0-RC1 only!</li> <li>This guide starts with Elasticsearch version 6.8.2  up and running, indexes and data. To test this guide, we recommend using a backup of you production server. (see Backup and Restore page for more information)</li> <li>This guide is illustrated with TheHive index. The process is identical for Cortex, you just have to adjust index names.</li> </ul>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#prerequisite","title":"Prerequisite","text":"<p>The software <code>jq</code> is required to manipulate JSON and create new indexes. More information at https://stedolan.github.io/jq/. </p>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#identify-if-your-index-should-be-reindexed","title":"Identify if your index should be reindexed","text":"<p>You can easily identify if indexes should be reindexed or not. On the index named <code>the_hive_15</code> run the following command: </p> <pre><code>curl -s http://127.0.0.1:9200/the_hive_15?human | jq '.the_hive_15.settings.index.version.created'\n</code></pre> <p>if the output is similar to <code>\"5xxxxxx\"</code>  then reindexing is required, you should follow this guide. </p> <p>If it is   <code>\"6xxxxxx\"</code> then the index can be read by Elasticsearch 7.8.x. Upgrade Elasticsearch, and TheHive-3.5.0.</p>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#migration-guide","title":"Migration guide","text":""},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#current-status","title":"Current status","text":"<p>Current context is:  - Elasticsearch 6.8.2 - TheHive 3.4.2</p> <p>All up and running. </p> <p>Start by identifying indices on you Elasticsearch instance.</p> <pre><code>curl  http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   the_hive_15     Oap-I61ySgyv6EAI1ZUTFQ   5   0      30977           36     33.2mb \n</code></pre> <p>The index name is <code>the_hive_15</code>. Record this somewhere.</p>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#stop-services","title":"Stop services","text":"<p>Before starting updating the database, lets stop applications:</p> <pre><code>sudo service thehive stop \n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#create-a-new-index","title":"Create a new index","text":"<p>The First operation lies in creating a new index named <code>new_the_hive_15</code> with settings from current index <code>the_hive_15</code> (ensure to keep index version, needed for future upgrade).</p> <pre><code>curl -XPUT 'http://localhost:9200/new_the_hive_15' \\\n-H 'Content-Type: application/json' \\\n-d \"$(curl http://localhost:9200/the_hive_15 |\\\njq '.the_hive_15 |\n   del(.settings.index.provided_name,\n    .settings.index.creation_date,\n    .settings.index.uuid,\n    .settings.index.version,\n    .settings.index.mapping.single_type,\n    .mappings.doc._all)'\n)\"\n</code></pre> <p>Check the new index is well created: </p> <pre><code>curl -XGET http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\nyellow open   new_the_hive_15 A2KLoZPpSXygutlfy_RNCQ   5   1          0            0      1.1kb          1.1kb\ngreen  open   the_hive_15     Oap-I61ySgyv6EAI1ZUTFQ   5   0      30977           36     33.2mb         33.2mb\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#proceed-to-reindex","title":"Proceed to Reindex","text":"<p>Next operation lies in running the reindex command in the newly created index:</p> <pre><code>curl -XPOST -H 'Content-Type: application/json' http://localhost:9200/_reindex -d '{\n  \"conflicts\": \"proceed\",\n  \"source\": {\n    \"index\": \"the_hive_15\"\n  },\n  \"dest\": {\n    \"index\": \"new_the_hive_15\"\n  }\n}'\n</code></pre> <p>After a moment, you should get a similar output:  </p> <pre><code>{\n\"took\": 5119,\n\"timed_out\": false,\n\"total\": 5889,\n\"updated\": 0,\n\"created\": 5889,\n\"deleted\": 0,\n\"batches\": 6,\n\"version_conflicts\": 0,\n\"noops\": 0,\n\"retries\": {\n\"bulk\": 0,\n\"search\": 0\n},\n\"throttled_millis\": 0,\n\"requests_per_second\": -1.0,\n\"throttled_until_millis\": 0,\n\"failures\": []\n}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#ensure-new-index-has-been-created","title":"Ensure new index has been created","text":"<p>Run the following command, and ensure the new index is like the current one (size can vary):</p> <pre><code>curl -XGET http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   new_the_hive_15 GV-3Y8QjTjWw0F-p2sjW6Q   5   0      30977            0       26mb           26mb\ngreen  open   the_hive_15     Oap-I61ySgyv6EAI1ZUTFQ   5   0      30977           36     33.2mb         33.2mb\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#delete-old-indices","title":"Delete old indices","text":"<p>This is the thrilling part.  Now the new index <code>new_the_hive_15</code> is created and similar the_hive_15,  older indexes should be completely deleted from the database. To delete index named <code>the_hive_15</code>, run the following command:  </p> <pre><code>curl -XDELETE http://localhost:9200/the_hive_15\n</code></pre> <p>Run the same command for older indexes if exist (the_hive_14, the_hive_13....). Elasticsearch 7.x cannot run with index created with Elasticsearch 5.x.</p>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#create-an-alias","title":"Create an alias","text":"<p>Before stopping Elasticsearch service, let\u2019s create an alias to keep index names in the future.  </p> <pre><code>curl -XPOST -H 'Content-Type: application/json'  'http://localhost:9200/_aliases' -d '{\n    \"actions\": [\n        {\n            \"add\": {\n                \"index\": \"new_the_hive_15\",\n                \"alias\": \"the_hive_15\"\n            }\n        }\n    ]\n}'\n</code></pre> <p>Doing so will allow TheHive 3.5.0 to find the index without updating the configuration file. </p> <p>Check the alias has been well created by running the following command</p> <pre><code>curl -XGET http://localhost:9200/_alias?pretty\n</code></pre> <p>The output should look like:</p> <pre><code>{\n\"new_the_hive_15\" : {\n\"aliases\" : {\n\"the_hive_15\" : { }\n}\n}\n}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#stop-elasticsearch-version-682","title":"Stop Elasticsearch version 6.8.2","text":"<pre><code>sudo service elasticsearch stop </code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#update-elasticsearch","title":"Update Elasticsearch","text":"<p>Update the configuration of Elastisearch. Configuration file should look like this:</p> <pre><code>[..]\nhttp.host: 127.0.0.1\ndiscovery.type: single-node\ncluster.name: hive\nscript.allowed_types: inline\nthread_pool.search.queue_size: 100000\nthread_pool.write.queue_size: 10000    \n</code></pre> <p>Now, upgrade Elasticsearch to version 7.x following the documentation for your Operating System, and ensure the service start successfully.</p>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#install-or-update-to-thehive-350","title":"Install or update to TheHive 3.5.0","text":""},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#deb-package","title":"DEB package","text":"<p>If using Debian based Linux operating system, configure it to follow our beta repository:</p> <p><pre><code>curl https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY | sudo apt-key add -\necho 'deb https://deb.thehive-project.org release main' | sudo tee -a /etc/apt/sources.list.d/thehive-project.list\nsudo apt-get update\n</code></pre> Then install it by running:</p> <pre><code>sudo apt install thehive\n</code></pre> <p>or</p> <pre><code>sudo apt install thehive=3.5.0-1\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#rpm","title":"RPM","text":"<p>Setup your system to connect the RPM repository. Create and edit the file  <code>/etc/yum.repos.d/thehive-project.repo</code> :</p> <pre><code>[thehive-project]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=http://rpm.thehive-project.org/release/noarch\ngpgcheck=1\n</code></pre> <p>Then install it by running:</p> <pre><code>sudo yum install thehive\n</code></pre> <p>or </p> <pre><code>sudo yum install thehive-3.5.0-1\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#install-binaries","title":"Install binaries","text":"<pre><code>cd /opt\nwget https://download.thehive-project.org/thehive-3.5.0-1.zip\nunzip thehive-3.5.0-1.zip\nln -s thehive-3.5.0-1 thehive\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#docker-images","title":"Docker images","text":"<p>Docker images are also provided on Dockerhub. </p> <pre><code>docker pull thehiveproject/thehive:3.5.0-1\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/upgrade_to_thehive_3_5_and_es_7_x/#update-database","title":"Update Database","text":"<p>Connect to TheHive, the maintenance page should ask to update. </p> <p></p> <p>Once updated, ensure a new index named <code>the_hive_16</code> has been created.</p> <pre><code>curl -XGET http://localhost:9200/_cat/indices\\?v\n</code></pre> <p>The output should look like this: </p> <pre><code>health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\ngreen  open   new_the_hive_15 GV-3Y8QjTjWw0F-p2sjW6Q   5   0      30977            0       26mb           26mb\nyellow open   the_hive_16     Nz0vCKqhRK2xkx1t_WF-0g   5   1      30977            0     26.1mb         26.1mb\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/webhooks/","title":"WebHooks","text":"<p>Starting from version 2.13, TheHive supports webhooks. When enabled, TheHive will send each action that has been performed on it (add case, update case, add task, ...), in real time, to an HTTP endpoint. You can then create a program or application on the HTTP endpoint to react on specific events.</p> <ul> <li>Configuration</li> <li>Data Sent to the HTTP Endpoint</li> <li>Sample Webhook Server Application<ul> <li>Dependencies</li> <li>Python Script</li> <li>Run</li> </ul> </li> </ul>"},{"location":"thehive/legacy/thehive3/admin/webhooks/#configuration","title":"Configuration","text":"<p>Webhooks are configured using the <code>webhook</code> key in the configuration file (<code>/etc/thehive/application.conf</code> by default). A minimal configuration contains an arbitrary name and an URL. The URL corresponds to the HTTP endpoint: <pre><code>webhooks {\n  myLocalWebHook {\n    url = \"http://my_HTTP_endpoint/webhook\"\n  }\n}\n</code></pre></p> <p>Proxy and SSL configuration can be added in the same manner as for MISP or Cortex:</p> <pre><code>webhooks {\n  securedWebHook {\n    url = \"https://my_HTTP_endpoint/webhook\"\n    ws {\n      ssl.trustManager {\n        stores = [\n          {\n            type: \"JKS\" // JKS or PEM\n            path: \"keystore.jks\"\n            password: \"password1\"\n          }\n        ]\n      }\n      proxy {\n        host: \"10.1.0.1\"\n        port: 3128\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/webhooks/#data-sent-to-the-http-endpoint","title":"Data Sent to the HTTP Endpoint","text":"<p>For each action performed on it, TheHive sends an audit trail entry in JSON format to the HTTP endpoint. Here is an example corresponding to the creation of a case:</p> <pre><code>{\n  \"operation\": \"Creation\",                                        # Creation, Update or Delete\n  \"objectType\": \"case\",                                           # Type of object\n  \"objectId\": \"AV6FZsTj0KeanEfOQfd_\",                             # Object ID\n  \"startDate\": 1505476659427,                                     # When the operation has been done\n  \"requestId\": \"13b17ff13d1cfc56:2b7b048b:15e84f42c33:-8000:426\", # HTTP request ID which has done the operation\n  \"details\": {                                                    # Attributes used for creation of update\n    \"customFields\": {},\n    \"metrics\": {},\n    \"description\": \"Example of case creation\",\n    \"flag\": false,\n    \"title\": \"Test case for webhook\",\n    \"status\": \"Open\",\n    \"owner\": \"me\",\n    \"caseId\": 1445,\n    \"severity\": 2,\n    \"tlp\": 2,\n    \"startDate\": 1505476620000,\n    \"tags\": []\n  },\n  \"base\": true,                                                   # Internal information used to determine the main operation when there are several operations for the same request\n  \"rootId\": \"AV6FZsTj0KeanEfOQfd_\",                               # ID of the root parent of the object (internal use)\n  \"object\": {                                                     # The object after the operation\n    \"customFields\": {},\n    \"metrics\": {},\n    \"createdBy\": \"me\",\n    \"description\": \"Example of case creation\",\n    \"flag\": false,\n    \"user\": \"me\",\n    \"title\": \"Test case for webhook\",\n    \"status\": \"Open\",\n    \"owner\": \"me\",\n    \"createdAt\": 1505476658289,\n    \"caseId\": 1445,\n    \"severity\": 2,\n    \"tlp\": 2,\n    \"startDate\": 1505476620000,\n    \"tags\": [],\n    \"id\": \"AV6FZsTj0KeanEfOQfd_\",\n    \"_type\": \"case\"\n  }\n}\n</code></pre> <p>For an update, the data will look like: <pre><code>{\n  \"operation\": \"Update\",\n  \"details\": {\n    \"severity\": 3\n  },\n  \"objectType\": \"case\",\n  \"objectId\": \"AV6FZsTj0KeanEfOQfd_\",\n  \"base\": true,\n  \"startDate\": 1505477372601,\n  \"rootId\": \"AV6FZsTj0KeanEfOQfd_\",\n  \"requestId\": \"13b17ff13d1cfc56:2b7b048b:15e84f42c33:-8000:446\",\n  \"object\": {\n    \"customFields\": {},\n    \"metrics\": {},\n    \"createdBy\": \"me\",\n    \"description\": \"Example of case creation\",\n    \"flag\": false,\n    \"user\": \"me\",\n    \"title\": \"Test case for webhook\",\n    \"status\": \"Open\",\n    \"owner\": \"me\",\n    \"createdAt\": 1505476658289,\n    \"caseId\": 1445,\n    \"severity\": 3,\n    \"tlp\": 2,\n    \"startDate\": 1505476620000,\n    \"tags\": [],\n    \"updatedBy\": \"me\",\n    \"updatedAt\": 1505477372246,\n    \"id\": \"AV6FZsTj0KeanEfOQfd_\",\n    \"_type\": \"case\"\n  }\n}\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/admin/webhooks/#sample-webhook-server-application","title":"Sample Webhook Server Application","text":"<p>The following application is a sample intended to help you get started with webhooks. It is very basic as it listens to a local port and displays the contents of the received POST JSON data.</p>"},{"location":"thehive/legacy/thehive3/admin/webhooks/#dependencies","title":"Dependencies","text":"<p>Install dependencies: <code>sudo pip install flask</code></p>"},{"location":"thehive/legacy/thehive3/admin/webhooks/#python-script","title":"Python Script","text":"<p>Create a simple Python script (e.g. <code>webhooktest.py</code>):</p> <pre><code>from flask import Flask, request\nimport json\n\napp = Flask(__name__)\n\n@app.route('/',methods=['POST'])\ndef foo():\n   data = json.loads(request.data)\n   print(json.dumps(data, indent=4))\n   return \"OK\"\n\nif __name__ == '__main__':\n   app.run()\n</code></pre>"},{"location":"thehive/legacy/thehive3/admin/webhooks/#run","title":"Run","text":"<p>Run the server: <code>python webhooktest.py</code></p>"},{"location":"thehive/legacy/thehive3/api/","title":"TheHive API","text":"<p>TheHive exposes REST APIs through JSON over HTTP.</p> <ul> <li>HTTP request format</li> <li>Authentication</li> <li>Model</li> <li>Alert</li> <li>Case</li> <li>Observable</li> <li>Task</li> <li>Log</li> <li>User</li> <li>Connectors</li> </ul>"},{"location":"thehive/legacy/thehive3/api/alert/","title":"Alert","text":""},{"location":"thehive/legacy/thehive3/api/alert/#model-definition","title":"Model definition","text":"<p>Required attributes:  - <code>title</code> (text) : title of the alert  - <code>description</code> (text) : description of the alert  - <code>severity</code> (number) : severity of the alert (1: low; 2: medium; 3: high) default=2  - <code>date</code> (date) : date and time when the alert was raised default=now  - <code>tags</code> (multi-string) : case tags default=empty  - <code>tlp</code> (number) : TLP (<code>0</code>: <code>white</code>; <code>1</code>: <code>green</code>; <code>2: amber</code>;  <code>3: red</code>) default=2  - <code>status</code> (AlertStatus) : status of the alert (New, Updated, Ignored, Imported) default=New  - <code>type</code> (string) : type of the alert (read only)  - <code>source</code> (string) : source of the alert (read only)  - <code>sourceRef</code> (string) : source reference of the alert (read only)  - <code>artifacts</code> (multi-artifact) : artifact of the alert. It is a array of JSON object containing artifact attributes  default=empty  - <code>follow</code> (boolean) : if true, the alert becomes active when updated default=true</p> <p>Optional attributes:  - <code>caseTemplate</code> (string) : case template to use when a case is created from this alert. If the alert specifies a non-existent case template or doesn't supply one, TheHive will import the alert into a case using a case template that has the exact same name as the alert's type if it exists. For example, if you raise an alert with a type value of <code>splunk</code> and you do not provide the <code>caseTemplate</code> attribute or supply a non-existent one (for example <code>splink</code>), TheHive will import the alert using the case template called <code>splunk</code> if it exists. Otherwise, the alert will be imported using an empty case (i.e. from scratch).</p> <p>Attributes generated by the backend:  - <code>lastSyncDate</code> (date) : date of the last synchronization  - <code>case</code> (string) : id of the case, if created</p> <p>Alert ID is computed from <code>type</code>, <code>source</code> and<code>sourceRef</code>.</p>"},{"location":"thehive/legacy/thehive3/api/alert/#alert-manipulation","title":"Alert Manipulation","text":""},{"location":"thehive/legacy/thehive3/api/alert/#alert-methods","title":"Alert methods","text":"HTTP Method URI Action GET /api/alert List alerts POST /api/alert/_search Find alerts PATCH /api/alert/_bulk Update alerts in bulk POST /api/alert/_stats Compute stats on alerts POST /api/alert Create an alert GET /api/alert/:alertId Get an alert PATCH /api/alert/:alertId Update an alert DELETE /api/alert/:alertId Delete an alert POST /api/alert/:alertId/markAsRead Mark an alert as read POST /api/alert/:alertId/markAsUnread Mark an alert as unread POST /api/alert/:alertId/createCase Create a case from an alert POST /api/alert/:alertId/follow Follow an alert POST /api/alert/:alertId/unfollow Unfollow an alert POST /api/alert/:alertId/merge/:caseId Merge an alert in a case POST /api/alert/merge/_bulk Merge several alerts in one case"},{"location":"thehive/legacy/thehive3/api/alert/#get-an-alert","title":"Get an alert","text":"<p>An alert's details can be retrieve using the url: <pre><code>GET     /api/alert/:alertId\n</code></pre> The alert ID is obtained by List alerts or Find alerts API.</p> <p>If the parameter <code>similarity</code> is set to \"1\" or \"true\", this API returns information on cases which have similar observables. With this feature, output will contain the <code>similarCases</code> attribute which list case details with:  - artifactCount: number of observables in the original case  - iocCount: number of observables marked as IOC in original case  - similarArtifactCount: number of observables which are in alert and in case  - similarIocCount: number of IOCs which are in alert and in case</p> <p>warning IOCs are observables</p>"},{"location":"thehive/legacy/thehive3/api/alert/#examples","title":"Examples","text":"<p>Get alert without similarity data: <pre><code>curl -H 'Authorization: Bearer ***API*KEY***' http://127.0.0.1:9000/api/alert/ce2c00f17132359cb3c50dfbb1901810\n</code></pre> It returns: <pre><code>{\n    \"_id\": \"ce2c00f17132359cb3c50dfbb1901810\",\n    \"_type\": \"alert\",\n    \"artifacts\": [],\n    \"createdAt\": 1495012062014,\n    \"createdBy\": \"myuser\",\n    \"date\": 1495012062016,\n    \"description\": \"N/A\",\n    \"follow\": true,\n    \"id\": \"ce2c00f17132359cb3c50dfbb1901810\",\n    \"lastSyncDate\": 1495012062016,\n    \"severity\": 2,\n    \"source\": \"instance1\",\n    \"sourceRef\": \"alert-ref\",\n    \"status\": \"New\",\n    \"title\": \"New Alert\",\n    \"tlp\": 2,\n    \"type\": \"external\",\n    \"user\": \"myuser\"\n}\n</code></pre></p> <p>Get alert with similarity data: <pre><code>curl -H 'Authorization: Bearer ***API*KEY***' http://127.0.0.1:9000/api/alert/ce2c00f17132359cb3c50dfbb1901810?similarity=1\n</code></pre> It returns: <pre><code>{\n    \"_id\": \"ce2c00f17132359cb3c50dfbb1901810\",\n    \"_type\": \"alert\",\n    \"artifacts\": [],\n    \"createdAt\": 1495012062014,\n    \"createdBy\": \"myuser\",\n    \"date\": 1495012062016,\n    \"description\": \"N/A\",\n    \"follow\": true,\n    \"id\": \"ce2c00f17132359cb3c50dfbb1901810\",\n    \"lastSyncDate\": 1495012062016,\n    \"severity\": 2,\n    \"source\": \"instance1\",\n    \"sourceRef\": \"alert-ref\",\n    \"status\": \"New\",\n    \"title\": \"New Alert\",\n    \"tlp\": 2,\n    \"type\": \"external\",\n    \"user\": \"myuser\",\n    \"similarCases\": [\n        {\n            \"_id\": \"AVwwrym-Rw5vhyJUfdJW\",\n            \"artifactCount\": 5,\n            \"endDate\": null,\n            \"id\": \"AVwwrym-Rw5vhyJUfdJW\",\n            \"iocCount\": 1,\n            \"resolutionStatus\": null,\n            \"severity\": 1,\n            \"similarArtifactCount\": 2,\n            \"similarIocCount\": 1,\n            \"startDate\": 1495465039000,\n            \"status\": \"Open\",\n            \"tags\": [\n                \"src:MISP\"\n            ],\n            \"caseId\": 1405,\n            \"title\": \"TEST TheHive\",\n            \"tlp\": 2\n        }\n    ]\n}\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/api/alert/#create-an-alert","title":"Create an alert","text":"<p>An alert can be created using the following url: <pre><code>POST     /api/alert\n</code></pre> Required case attributes (cf. models) must be provided.</p> <p>If an alert with the same tuple <code>type</code>, <code>source</code> and <code>sourceRef</code> already exists, TheHive will refuse to create it.</p> <p>This call returns attributes of the created alert.</p>"},{"location":"thehive/legacy/thehive3/api/alert/#examples_1","title":"Examples","text":"<p>Creation of a simple alert: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' -H 'Content-Type: application/json' http://127.0.0.1:9000/api/alert -d '{\n  \"title\": \"New Alert\",\n  \"description\": \"N/A\",\n  \"type\": \"external\",\n  \"source\": \"instance1\",\n  \"sourceRef\": \"alert-ref\"\n}'\n</code></pre> It returns: <pre><code>{\n    \"_id\": \"ce2c00f17132359cb3c50dfbb1901810\",\n    \"_type\": \"alert\",\n    \"artifacts\": [],\n    \"createdAt\": 1495012062014,\n    \"createdBy\": \"myuser\",\n    \"date\": 1495012062016,\n    \"description\": \"N/A\",\n    \"follow\": true,\n    \"id\": \"ce2c00f17132359cb3c50dfbb1901810\",\n    \"lastSyncDate\": 1495012062016,\n    \"severity\": 2,\n    \"source\": \"instance1\",\n    \"sourceRef\": \"alert-ref\",\n    \"status\": \"New\",\n    \"title\": \"New Alert\",\n    \"tlp\": 2,\n    \"type\": \"external\",\n    \"user\": \"myuser\"\n}\n</code></pre></p> <p>Creation of another alert: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' -H 'Content-Type: application/json' http://127.0.0.1:9000/api/alert -d '{\n  \"title\": \"Other alert\",\n  \"description\": \"alert description\",\n  \"type\": \"external\",\n  \"source\": \"instance1\",\n  \"sourceRef\": \"alert-ref\",\n  \"severity\": 3,\n  \"tlp\": 3,\n  \"artifacts\": [\n    { \"dataType\": \"ip\", \"data\": \"127.0.0.1\", \"message\": \"localhost\" },\n    { \"dataType\": \"domain\", \"data\": \"thehive-project.org\", \"tags\": [\"home\", \"TheHive\"] },\n    { \"dataType\": \"file\", \"data\": \"logo.svg;image/svg+xml;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\", \"message\": \"logo\" }\n  ],\n  \"caseTemplate\": \"external-alert\"\n}'\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/api/alert/#merge-an-alert","title":"Merge an alert","text":"<p>An alert can be merge in a case using the URL: <pre><code>POST     /api/alert/:alertId/merge/:caseId\n</code></pre> Each observable of the alert will be added to the case if it doesn't exist in the case. The description of the alert will be appended to the case's description.</p> <p>The HTTP response contains the updated case.</p>"},{"location":"thehive/legacy/thehive3/api/alert/#example","title":"Example","text":"<p>Merge the alert <code>ce2c00f17132359cb3c50dfbb1901810</code> in case <code>AVXeF-pZmeHK_2HEYj2z</code>: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' http://127.0.0.1:9000/api/alert/ce2c00f17132359cb3c50dfbb1901810/merge/AVXeF-pZmeHK_2HEYj2z\n</code></pre> The call returns: <pre><code>{\n  \"severity\": 3,\n  \"createdBy\": \"myuser\",\n  \"createdAt\": 1488918582777,\n  \"caseId\": 1,\n  \"title\": \"My first case\",\n  \"startDate\": 1488918582836,\n  \"owner\": \"myuser\",\n  \"status\": \"Open\",\n  \"description\": \"This case has been created by my custom script\n\n  ### Merged with alert #10 my alert title\n\n  This is my alert description\",\n  \"user\": \"myuser\",\n  \"tlp\": 2,\n  \"flag\": false,\n  \"id\": \"AVXeF-pZmeHK_2HEYj2z\",\n  \"_id\": \"AVXeF-pZmeHK_2HEYj2z\",\n  \"_type\":\"case\"\n}\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/api/alert/#bulk-merge-alert","title":"Bulk merge alert","text":"<p>This API merge several alerts with one case: <pre><code>POST     /api/alert/merge/_bulk\n</code></pre> The observable of each alert listed in <code>alertIds</code> field will be imported into the case (identified by <code>caseId</code> field). The description of the case is not modified.</p> <p>The HTTP response contains the case.</p>"},{"location":"thehive/legacy/thehive3/api/alert/#example_1","title":"Example","text":"<p>Merge the alerts <code>ce2c00f17132359cb3c50dfbb1901810</code> and <code>a97148693200f731cfa5237ff2edf67b</code> in case <code>AVXeF-pZmeHK_2HEYj2z</code>: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' -H 'Content-Type: application/json' http://127.0.0.1:9000/api/alert/merge/_bulk -d '{\n  \"caseId\": \"AVXeF-pZmeHK_2HEYj2z\",\n  \"alertIds\": [\"ce2c00f17132359cb3c50dfbb1901810\", \"a97148693200f731cfa5237ff2edf67b\"]\n}'\n</code></pre> The call returns: <pre><code>{\n  \"severity\": 3,\n  \"createdBy\": \"myuser\",\n  \"createdAt\": 1488918582777,\n  \"caseId\": 1,\n  \"title\": \"My first case\",\n  \"startDate\": 1488918582836,\n  \"owner\": \"myuser\",\n  \"status\": \"Open\",\n  \"description\": \"This case has been created by my custom script\",\n  \"user\": \"myuser\",\n  \"tlp\": 2,\n  \"flag\": false,\n  \"id\": \"AVXeF-pZmeHK_2HEYj2z\",\n  \"_id\": \"AVXeF-pZmeHK_2HEYj2z\",\n  \"_type\":\"case\"\n}\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/api/artifact/","title":"Observable","text":""},{"location":"thehive/legacy/thehive3/api/artifact/#model-definition","title":"Model definition","text":"<p>Required attributes:</p> <ul> <li><code>data</code> (string) : content of the observable (read only). An observable can't contain data and attachment attributes</li> <li><code>attachment</code> (attachment) : observable file content (read-only). An observable can't contain data and attachment  attributes</li> <li><code>dataType</code> (enumeration) : type of the observable (read only)</li> <li><code>message</code> (text) : description of the observable in the context of the case</li> <li><code>startDate</code> (date) : date of the observable creation default=now</li> <li><code>tlp</code> (number) : TLP (<code>0</code>: <code>white</code>; <code>1</code>: <code>green</code>; <code>2</code>: <code>amber</code>;  <code>3</code>: <code>red</code>) default=2</li> <li><code>ioc</code> (boolean) : indicates if the observable is an IOC default=false</li> <li><code>status</code> (artifactStatus) : status of the observable (Ok or Deleted) default=Ok</li> </ul> <p>Optional attributes:  - <code>tags</code> (multi-string) : observable tags</p>"},{"location":"thehive/legacy/thehive3/api/artifact/#observable-manipulation","title":"Observable manipulation","text":""},{"location":"thehive/legacy/thehive3/api/artifact/#observable-methods","title":"Observable methods","text":"HTTP Method URI Action POST /api/case/artifact/_search Find observables POST /api/case/artifact/_stats Compute stats on observables POST /api/case/:caseId/artifact Create an observable GET /api/case/artifact/:artifactId Get an observable DELETE /api/case/artifact/:artifactId Remove an observable PATCH /api/case/artifact/:artifactId Update an observable GET /api/case/artifact/:artifactId/similar Get list of similar observables PATCH /api/case/artifact/_bulk Update observables in bulk"},{"location":"thehive/legacy/thehive3/api/artifact/#list-observables-of-a-case","title":"List Observables of a Case","text":"<p>Complete observable list of a case can be retrieved by performing a search: <pre><code>POST     /api/case/artifact/_search\n</code></pre> Parameters:  - <code>query</code>: <code>{ \"_parent\": { \"_type\": \"case\", \"_query\": { \"_id\": \"&lt;&lt;caseId&gt;&gt;\" } } }</code>  - <code>range</code>: <code>all</code></p> <p>\\&lt;\\&lt;caseId&gt;&gt; must be replaced by case id (not the case number !)</p>"},{"location":"thehive/legacy/thehive3/api/authentication/","title":"Authentication","text":"<p>Most API calls require authentication. Credentials can be provided using a session cookie, an API key or directly using HTTP basic authentication (when enabled).</p> <p>Session cookie is suitable for browser authentication, not for a dedicated tool. The easiest solution if you want to write a tool that leverages TheHive's API is to use API key authentication. API keys can be generated using the Web interface of the product, under the user admin area. For example, to list cases, use the following curl command: <pre><code># Using API key\ncurl -H 'Authorization: Bearer ***API*KEY***' http://127.0.0.1:9000/api/case\n</code></pre></p> <p>TheHive also supports basic authentication (disabled by default). You can enable it by adding <code>auth.method.basic=true</code> in the configuration file. <pre><code># Using basic authentication\ncurl -u mylogin:mypassword http://127.0.0.1:9000/api/case\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/api/case/","title":"Case","text":""},{"location":"thehive/legacy/thehive3/api/case/#model-definition","title":"Model definition","text":"<p>Required attributes:  - <code>title</code> (text) : title of the case  - <code>description</code> (text) : description of the case  - <code>severity</code> (number) : severity of the case (1: low; 2: medium; 3: high) default=2  - <code>startDate</code> (date) : date and time of the begin of the case default=now  - <code>owner</code> (string) : user to whom the case has been assigned default=use who create the case  - <code>flag</code> (boolean) : flag of the case default=false  - <code>tlp</code> (number) : TLP (<code>0</code>: <code>white</code>; <code>1</code>: <code>green</code>; <code>2: amber</code>;  <code>3: red</code>) default=2  - <code>tags</code> (multi-string) : case tags default=empty</p> <p>Optional attributes:  - <code>resolutionStatus</code> (caseResolutionStatus) : resolution status of the case (Indeterminate, FalsePositive,  TruePositive, Other or Duplicated)  - <code>impactStatus</code> (caseImpactStatus) : impact status of the case (NoImpact, WithImpact or NotApplicable)  - <code>summary</code> (text) : summary of the case, to be provided when closing a case  - <code>endDate</code> (date) : resolution date  - <code>metrics</code> (metrics) : list of metrics</p> <p>Attributes generated by the backend:  - <code>status</code> (caseStatus) : status of the case (Open, Resolved or Deleted) default=Open  - <code>caseId</code> (number) : Id of the case (auto-generated)  - <code>mergeInto</code> (string) : ID of the case created by the merge  - <code>mergeFrom</code> (multi-string) :  IDs of the cases that were merged</p>"},{"location":"thehive/legacy/thehive3/api/case/#case-manipulation","title":"Case Manipulation","text":""},{"location":"thehive/legacy/thehive3/api/case/#case-methods","title":"Case methods","text":"HTTP Method URI Action GET /api/case List cases POST /api/case/_search Find cases PATCH /api/case/_bulk Update cases in bulk POST /api/case/_stats Compute stats on cases POST /api/case Create a case GET /api/case/:caseId Get a case PATCH /api/case/:caseId Update a case DELETE /api/case/:caseId Remove a case GET /api/case/:caseId/links Get list of cases linked to this case POST /api/case/:caseId1/_merge/:caseId2 Merge two cases"},{"location":"thehive/legacy/thehive3/api/case/#create-a-case","title":"Create a Case","text":"<p>A case can be created using the following url : <pre><code>POST     /api/case\n</code></pre> Required case attributes (cf. models) must be provided.</p> <p>This call returns attributes of the created case.</p>"},{"location":"thehive/legacy/thehive3/api/case/#examples","title":"Examples","text":"<p>Creation of a simple case: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' -H 'Content-Type: application/json' http://127.0.0.1:9000/api/case -d '{\n  \"title\": \"My first case\",\n  \"description\": \"This case has been created by my custom script\"\n}'\n</code></pre> It returns: <pre><code>{\n  \"severity\": 3,\n  \"createdBy\": \"myuser\",\n  \"createdAt\": 1488918582777,\n  \"caseId\": 1,\n  \"title\": \"My first case\",\n  \"startDate\": 1488918582836,\n  \"owner\": \"myuser\",\n  \"status\": \"Open\",\n  \"description\": \"This case has been created by my custom script\",\n  \"user\": \"myuser\",\n  \"tlp\": 2,\n  \"flag\": false,\n  \"id\": \"AVqqdpY2yQ6w1DNC8aDh\",\n  \"_id\": \"AVqqdpY2yQ6w1DNC8aDh\",\n  \"_type\":\"case\"\n}\n</code></pre></p> <p>Creation of another case: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' -H 'Content-Type: application/json' http://127.0.0.1:9000/api/case -d '{\n  \"title\": \"My second case\",\n  \"description\": \"This case has been created by my custom script, its severity is high, tlp is red and it contains tags\",\n  \"severity\": 3,\n  \"tlp\": 3,\n  \"tags\": [\"automatic\", \"creation\"]\n}'\n</code></pre></p> <p>Creating a case with Tasks &amp; Customfields: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' -H 'Content-Type: application/json' http://127.0.0.1:9000/api/case -d '{\n    \"title\": \"My first case\",\n    \"description\": \"This case has been created by my custom script\"\n    \"tasks\": [{\n        \"title\": \"mytask\",\n        \"description\": \"description of my task\"\n    }],\n    \"customFields\": {\n        \"cvss\": {\n            \"number\": 9,\n        },\n        \"businessImpact\": {\n            \"string\": \"HIGH\"\n        }\n    }\n}'\n</code></pre> For the <code>customFields</code> object, the attribute names should correspond to the <code>ExternalReference</code> (cvss and businessImpact in the example above) not to the name of custom fields.</p>"},{"location":"thehive/legacy/thehive3/api/log/","title":"Log","text":""},{"location":"thehive/legacy/thehive3/api/log/#model-definition","title":"Model definition","text":"<p>Required attributes:  - <code>message</code> (text) : content of the Log  - <code>startDate</code> (date) : date of the log submission default=now  - <code>status</code> (logStatus) : status of the log (Ok or Deleted) default=Ok</p> <p>Optional attributes:  - <code>attachment</code> (attachment) : file attached to the log</p>"},{"location":"thehive/legacy/thehive3/api/log/#log-manipulation","title":"Log manipulation","text":""},{"location":"thehive/legacy/thehive3/api/log/#log-methods","title":"Log methods","text":"HTTP Method URI Action GET /api/case/task/:taskId/log Get logs of the task POST /api/case/task/:taskId/log/_search Find logs in specified task POST /api/case/task/log/_search Find logs POST /api/case/task/:taskId/log Create a log PATCH /api/case/task/log/:logId Update a log DELETE /api/case/task/log/:logId Remove a log GET /api/case/task/log/:logId Get a log"},{"location":"thehive/legacy/thehive3/api/log/#create-a-log","title":"Create a log","text":"<p>The URL used to create a task is: <pre><code>POST /api/case/task/&lt;&lt;taskId&gt;&gt;/log\n</code></pre> \\&lt;\\&lt;taskId&gt;&gt; must be replaced by task id</p> <p>Required log attributes (cf. models) must be provided.</p> <p>This call returns attributes of the created log.</p>"},{"location":"thehive/legacy/thehive3/api/log/#examples","title":"Examples","text":"<p>Creation of a simple log in task <code>AVqqeXc9yQ6w1DNC8aDj</code>: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' -H 'Content-Type: application/json' http://127.0.0.1:9000/api/case/task/AVqqeXc9yQ6w1DNC8aDj/log -d '{\n  \"message\": \"Some message\"\n}'\n</code></pre> It returns: <pre><code>{\n  \"startDate\": 1488919949497,\n  \"createdBy\": \"admin\",\n  \"createdAt\": 1488919949495,\n  \"user\": \"myuser\",\n  \"message\":\"Some message\",\n  \"status\": \"Ok\",\n  \"id\": \"AVqqi3C-yQ6w1DNC8aDq\",\n  \"_id\": \"AVqqi3C-yQ6w1DNC8aDq\",\n  \"_type\":\"case_task_log\"\n}\n</code></pre></p> <p>If log contains an attachment, the request must be in multipart format: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' http://127.0.0.1:9000/api/case/task/AVqqeXc9yQ6w1DNC8aDj/log -F '_json={\"message\": \"Screenshot of fake site\"};type=application/json' -F 'attachment=@screenshot1.png;type=image/png'\n</code></pre> It returns: <pre><code>{\n  \"createdBy\": \"myuser\",\n  \"message\": \"Screenshot of fake site\",\n  \"createdAt\": 1488920587391,\n  \"startDate\": 1488920587394,\n  \"user\": \"myuser\",\n  \"status\": \"Ok\",\n  \"attachment\": {\n    \"name\": \"screenshot1.png\",\n    \"hashes\": [\n      \"086541e99743c6752f5fd4931e256e6e8d5fc7afe47488fb9e0530c390d0ca65\",\n      \"8b81e038ae0809488f20b5ec7dc91e488ef601e2\",\n      \"c5883708f42a00c3ab1fba5bbb65786c\"\n    ],\n    \"size\": 15296,\n    \"contentType\": \"image/png\",\n    \"id\": \"086541e99743c6752f5fd4931e256e6e8d5fc7afe47488fb9e0530c390d0ca65\"\n  },\n  \"id\": \"AVqqlSy0yQ6w1DNC8aDx\",\n  \"_id\": \"AVqqlSy0yQ6w1DNC8aDx\",\n  \"_type\": \"case_task_log\"\n}\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/api/model/","title":"TheHive Model Definition","text":""},{"location":"thehive/legacy/thehive3/api/model/#field-types","title":"Field Types","text":"<ul> <li><code>string</code> : textual data (example \"malware\").</li> <li><code>text</code> : textual data. The difference between <code>string</code> and <code>text</code> is in the way content can be searched.<code>string</code> is  searchable as-is whereas <code>text</code>,  words (token) are searchable, not the whole content (example \"Ten users have received  this ransomware\").</li> <li><code>date</code> : date and time using timestamps with milliseconds format.</li> <li><code>boolean</code> : true or false</li> <li><code>number</code> : numeric value</li> <li><code>metrics</code> : JSON object that contains only numbers</li> </ul> <p>Field can be prefixed with <code>multi-</code> in order to indicate that multiple values can be provided.</p>"},{"location":"thehive/legacy/thehive3/api/model/#common-attributes","title":"Common Attributes","text":"<p>All entities share the following attributes:  - <code>createdBy</code> (text) : login of the user who created the entity  - <code>createdAt</code> (date) : date and time of the creation  - <code>updatedBy</code> (text) : login of the user who last updated the entity  - <code>upadtedAt</code> (date) : date and time of the last update  - <code>user</code> (text) : same value as <code>createdBy</code> (this field is deprecated) These attributes are handled by the back-end and can't be directly updated.</p>"},{"location":"thehive/legacy/thehive3/api/request/","title":"Request","text":""},{"location":"thehive/legacy/thehive3/api/request/#request-formats","title":"Request formats","text":"<p>TheHive accepts several parameter formats within a HTTP request. They can be used indifferently. Input data can be: - a query string - URL-encoded form - multi-part - JSON</p> <p>Hence, the requests below are equivalent.</p>"},{"location":"thehive/legacy/thehive3/api/request/#query-string","title":"Query String","text":"<pre><code>curl -XPOST 'http://127.0.0.1:9000/api/login?user=me&amp;password=secret'\n</code></pre>"},{"location":"thehive/legacy/thehive3/api/request/#url-encoded-form","title":"URL-encoded Form","text":"<pre><code>curl -XPOST 'http://127.0.0.1:9000/api/login' -d user=me -d password=secret\n</code></pre>"},{"location":"thehive/legacy/thehive3/api/request/#json","title":"JSON","text":"<pre><code>curl -XPOST http://127.0.0.1:9000/api/login -H 'Content-Type: application/json' -d '{\n  \"user\": \"me\",\n  \"password\": \"secret\"\n}'\n</code></pre>"},{"location":"thehive/legacy/thehive3/api/request/#multi-part","title":"Multi-part","text":"<pre><code>curl -XPOST http://127.0.0.1:9000/api/login -F '_json=&lt;-;type=application/json' &lt;&lt; _EOF_\n{\n  \"user\": \"me\",\n  \"password\": \"secret\"\n}\n_EOF_\n</code></pre>"},{"location":"thehive/legacy/thehive3/api/request/#responseformat","title":"ResponseFormat","text":"<p>TheHive outputs JSON data.</p>"},{"location":"thehive/legacy/thehive3/api/task/","title":"Task","text":""},{"location":"thehive/legacy/thehive3/api/task/#model-definition","title":"Model definition","text":"<p>Required attributes:  - <code>title</code> (text) : title of the task  - <code>status</code> (taskStatus) : status of the task (Waiting, InProgress, Completed or Cancel) default=Waiting  - <code>flag</code> (boolean) : flag of the task default=false</p> <p>Optional attributes:  - <code>owner</code> (string) : user who owns the task. This is automatically set to current user when status is set to  InProgress  - <code>description</code> (text) : task details  - <code>startDate</code> (date) : date of the beginning of the task. This is automatically set when status is set to Open  - <code>endDate</code> (date) : date of the end of the task. This is automatically set when status is set to Completed</p>"},{"location":"thehive/legacy/thehive3/api/task/#task-manipulation","title":"Task manipulation","text":""},{"location":"thehive/legacy/thehive3/api/task/#task-methods","title":"Task methods","text":"HTTP Method URI Action POST /api/case/:caseId/task/_search Find tasks in a case (deprecated) POST /api/case/task/_search Find tasks POST /api/case/task/_stats Compute stats on tasks GET /api/case/task/:taskId Get a task PATCH /api/case/task/:taskId Update a task POST /api/case/:caseId/task Create a task"},{"location":"thehive/legacy/thehive3/api/task/#create-a-task","title":"Create a task","text":"<p>The URL used to create a task is: <pre><code>POST /api/case/&lt;&lt;caseId&gt;&gt;/task\n</code></pre> \\&lt;\\&lt;caseId&gt;&gt; must be replaced by case id (not the case number !)</p> <p>Required task attributes (cf. models) must be provided.</p> <p>This call returns attributes of the created task.</p>"},{"location":"thehive/legacy/thehive3/api/task/#examples","title":"Examples","text":"<p>Creation of a simple task in case <code>AVqqdpY2yQ6w1DNC8aDh</code>: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' -H 'Content-Type: application/json' http://127.0.0.1:9000/api/case/AVqqdpY2yQ6w1DNC8aDh/task -d '{\n  \"title\": \"Do something\"\n}'\n</code></pre> It returns: <pre><code>{\n  \"createdAt\": 1488918771513,\n  \"status\": \"Waiting\",\n  \"createdBy\": \"myuser\",\n  \"title\": \"Do something\",\n  \"order\": 0,\n  \"user\": \"myuser\",\n  \"flag\": false,\n  \"id\":\"AVqqeXc9yQ6w1DNC8aDj\",\n  \"_id\":\"AVqqeXc9yQ6w1DNC8aDj\",\n  \"_type\":\"case_task\"\n}\n</code></pre></p> <p>Creation of another task: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' -H 'Content-Type: application/json' http://127.0.0.1:9000/api/case/AVqqdpY2yQ6w1DNC8aDh/task -d '{\n  \"title\": \"Analyze the malware\",\n  \"description\": \"The malware XXX is analyzed using sandbox ...\",\n  \"owner\": \"Joe\",\n  \"status\": \"InProgress\"\n}'\n</code></pre></p>"},{"location":"thehive/legacy/thehive3/api/user/","title":"User","text":""},{"location":"thehive/legacy/thehive3/api/user/#model-definition","title":"Model definition","text":"<p>Required attributes:  - <code>login</code> / <code>id</code> (string) : login of the user  - <code>userName</code> (text) : Full name of the user  - <code>roles</code> (multi-userRole) : Array containing roles of the user (<code>read</code>, <code>write</code> or <code>admin</code>)  - <code>status</code> (userStatus) : <code>Ok</code> or <code>Locked</code> default=Ok  - <code>preference</code> (string) : JSON object containing user preference default={}</p> <p>Optional attributes:  - <code>avatar</code> (string) : avatar of user. It is an image encoded in base 64  - <code>password</code> (string) : user password if local authentication is used</p> <p>Attributes generated by the backend:  - <code>key</code> (uuid) : API key to authenticate this user (deprecated)</p>"},{"location":"thehive/legacy/thehive3/api/user/#user-manipulation","title":"User Manipulation","text":""},{"location":"thehive/legacy/thehive3/api/user/#user-methods","title":"User methods","text":"HTTP Method URI Action GET /api/logout Logout POST /api/login User login GET /api/user/current Get current user POST /api/user/_search Find user POST /api/user Create a user GET /api/user/:userId Get a user DELETE /api/user/:userId Delete a user PATCH /api/user/:userId Update user details POST /api/user/:userId/password/set Set password POST /api/user/:userId/password/change Change password <ul> <li><code>with-key</code> (boolean)</li> </ul>"},{"location":"thehive/legacy/thehive3/api/user/#create-a-user","title":"Create a User","text":"<p>A user can be created using the following URL: <pre><code>POST     /api/user\n</code></pre> Required case attributes (cf. models) must be provided.</p> <p>This call returns attributes of the created user.</p> <p>This call is authenticated and requires admin role.</p>"},{"location":"thehive/legacy/thehive3/api/user/#examples","title":"Examples","text":"<p>Creation of a user: <pre><code>curl -XPOST -H 'Authorization: Bearer ***API*KEY***' -H 'Content-Type: application/json' http://127.0.0.1:9000/api/user -d '{\n  \"login\": \"georges\",\n  \"name\": \"Georges Abitbol\",\n  \"roles\": [\"read\", \"write\"],\n  \"password\": \"La classe\"\n}'\n</code></pre> It returns: <pre><code>{\n  \"createdBy\": \"myuser\",\n  \"name\":\"Georges Abitbol\",\n  \"roles\": [\"read\", \"write\" ],\n  \"_id\": \"georges\",\n  \"user\": \"myuser\",\n  \"createdAt\": 1496561862924,\n  \"status\": \"Ok\",\n  \"id\": \"georges\",\n  \"_type\": \"user\",\n  \"has-key\":false\n}\n</code></pre> If external authentication is used (LDAP or AD) password field must not be provided.</p>"},{"location":"thehive/legacy/thehive3/api/connectors/","title":"Connectors API","text":"<p>TheHive offers an API to manipulate its various connectors</p> <ul> <li>Cortex</li> <li>MISP</li> <li>Metrics</li> </ul>"},{"location":"thehive/legacy/thehive3/api/connectors/cortex/","title":"Cortex manipulation through TheHive","text":"<p>Cortex can be manipulated through TheHive with JSON over HTTP</p> <ul> <li>Job</li> <li>Analyzer</li> </ul>"},{"location":"thehive/legacy/thehive3/api/connectors/cortex/analyzer/","title":"Analyzer","text":"<p>Author : R\u00e9mi ALLAIN (rallain@cyberprotect.fr) - Cyberprotect, SDN International</p>"},{"location":"thehive/legacy/thehive3/api/connectors/cortex/analyzer/#analyzer","title":"Analyzer","text":""},{"location":"thehive/legacy/thehive3/api/connectors/cortex/analyzer/#model-definition","title":"Model definition","text":"<p>Attributes:  - <code>id</code> (string) : Analyzer id  - <code>name</code> (string) : Analyzer name  - <code>version</code> (string) : Analyzer version  - <code>description</code> (text) : Analyzer description  - <code>dataTypeList</code> (multi-string) : List of data type this analyzer can manage  - <code>cortexIds</code> (string) : List of Cortex server id</p>"},{"location":"thehive/legacy/thehive3/api/connectors/cortex/analyzer/#analyzer-manipulation","title":"Analyzer manipulation","text":""},{"location":"thehive/legacy/thehive3/api/connectors/cortex/analyzer/#analyzer-methods","title":"Analyzer methods","text":"HTTP Method URI Action GET /api/connector/cortex/analyzer List all analyzers GET /api/connector/cortex/analyzer/:analyzerId Get details of an analyzer GET /api/connector/cortex/analyzer/type/:dataType List analyzers matching the dataType"},{"location":"thehive/legacy/thehive3/api/connectors/cortex/job/","title":"Job","text":""},{"location":"thehive/legacy/thehive3/api/connectors/cortex/job/#model-definition","title":"Model definition","text":"<p>Required attributes: - <code>analyzerId</code> (string): identifier of the analyzer used by the job - <code>status</code> (enumeration): status of the job (<code>InProgress</code>, <code>Success</code>, <code>Failure</code>) default=<code>InProgress</code> - <code>artifactId</code> (string): identifier of the artifact to analyze - <code>startDate</code> (date): job start date</p> <p>Optional attributes: - <code>endDate</code> (date): job end date - <code>report</code> (string): raw content of the report sent back by the analyzer - <code>cortexId</code> (string): identifier of the cortex server - <code>cortexJobId</code> (string): identifier of the job in the cortex server</p>"},{"location":"thehive/legacy/thehive3/api/connectors/cortex/job/#job-manipulation","title":"Job manipulation","text":""},{"location":"thehive/legacy/thehive3/api/connectors/cortex/job/#job-methods","title":"Job methods","text":"HTTP Method URI Action POST /api/connector/cortex/job Create a new Cortex job GET /api/connector/cortex/job/:jobId Get a cortex job POST /api/connector/cortex/job/_search \u00a0Search for cortex jobs"},{"location":"thehive/legacy/thehive3/api/connectors/cortex/job/#create-a-new-cortex-job","title":"Create a new Cortex job","text":"<p>Creating a new job can be done by performing the following query <pre><code>POST  /api/connector/cortex/job\n</code></pre> Parameters: - <code>cortexId</code>: identifier of the Cortex server - <code>artifactId</code>: identifier of the artifact as found with an artifact search - <code>analyzerId</code>: name of the analyzer used by the job</p>"},{"location":"thehive/legacy/thehive3/api/connectors/misp/","title":"MISP connector","text":"<p>MISP and TheHive can interact between each other in both ways: * TheHive is able to import events from a MISP instance as alerts and create cases from them * TheHive is able to export a case into MISP as an event and update it with the artifacts flagged as IOC as MISP attributes</p> <p>It is possible to use the API to control those behaviours.</p>"},{"location":"thehive/legacy/thehive3/api/connectors/misp/#misp-imports","title":"MISP imports","text":""},{"location":"thehive/legacy/thehive3/api/connectors/misp/#api-methods","title":"API methods","text":"HTTP Method URI Action GET /api/connector/misp/_syncAlerts Synchronize from all MISP instances all MISP events published since the last synchronization GET /api/connector/misp/_syncAllAlerts Synchronize from all MISP instances all MISP published events since the beginning GET /api/connector/misp/_syncArtifacts Synchronize all artifacts from already imported alerts from all MISP instances"},{"location":"thehive/legacy/thehive3/api/connectors/misp/#misp-exports","title":"MISP exports","text":""},{"location":"thehive/legacy/thehive3/api/connectors/misp/#api-methods_1","title":"API methods","text":"HTTP Method URI Action POST /api/connector/misp/export/:caseId/:mispName Export a case to MISP"},{"location":"thehive/legacy/thehive3/api/connectors/misp/#exporting-a-case-to-misp","title":"Exporting a case to MISP","text":"<p>Exporting a case to MISP can be done by performing the following query <pre><code>POST /api/connector/misp/export/:caseId/:mispName\n</code></pre> With: * caseId: the elasticsearch id of the case * mispName: the name given to the MISP instance in TheHive configuration</p> <p>No parameters need to be sent in the query body.</p> <p>The response of this query will be a JSON table containing all artifacts sent as attributes in the MISP event.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/","title":"Installation Guide","text":"<p>\u26a0\ufe0f Please read carrefully this documentation. Depending on you make a fresh installation or update an existing version, install version 3 or version 4, repository or packages names may vary.</p> <p>Current supported versions of TheHive are: - Version 3.5.0 and later that supports only Elasticsearch 7.x. - Version 4.0 and later.</p> <p>Instruction to  install TheHive supporting Elasticsearch 6.x (EoL in Nov. 2020) are still detailled in this documentation. </p> <p>Before installing TheHive, you need to choose the installation option which suits your environment as described below. Once you have a chosen an option and installed the software, read the Configuration Guide. We also advise reading the Administration Guide.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation Options<ul> <li>RPM</li> <li>DEB</li> <li>Docker</li> <li>Binary</li> <li>Build it Yourself</li> </ul> </li> <li>Elasticsearch Installation<ul> <li>System Package</li> <li>Start the Service</li> <li>Elasticsearch inside a Docker</li> </ul> </li> </ul>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#installation-options","title":"Installation Options","text":"<p>TheHive is available as:</p> <ul> <li>an RPM package</li> <li>a DEB package</li> <li>a Docker image</li> <li>a binary package</li> </ul> <p>In addition, TheHive can be also be built from the source code.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#rpm","title":"RPM","text":"<p>RPM packages are published on a our RPM repository. All packages are signed using our GPG key 562CBC1C. Its fingerprint is:</p> <p><code>0CD5 AC59 DE5C 5A8E 0EE1 3849 3D99 BB18 562C BC1C</code></p> <p>Run the following command to import the GPG key :</p> <pre><code>sudo rpm --import https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY\n</code></pre>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#release-versions","title":"Release versions","text":"<p>The release repository contains packages for TheHive 3.5.0+ and TheHive 4.0.0+</p> <p>Setup your system to connect the RPM repository. Create and edit the file <code>/etc/yum.repos.d/thehive-project.repo</code>:</p> <pre><code>[thehive-project]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=https://rpm.thehive-project.org/release/noarch\ngpgcheck=1\n</code></pre> <p>Then you will able to install  TheHive 3.5.0+  the package using <code>yum</code>:</p> <pre><code>yum install thehive\n</code></pre> <p>or  install TheHive 4.0.0+:</p> <pre><code>yum install thehive4\n</code></pre>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#stable-versions-or-legacy-versions","title":"Stable versions (or legacy versions)","text":"<p>The Stable repository  is a legacy repository and contains packages for TheHive 3.4.4 that does not support Elasticsearch version 7.x**, but version 6.x.</p> <p>Setup your system to connect the RPM repository. Create and edit the file <code>/etc/yum.repos.d/thehive-project.repo</code>:</p> <pre><code>[thehive-project]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=https://rpm.thehive-project.org/stable/noarch\ngpgcheck=1\n</code></pre> <p>Then you will able to install TheHive 3.4.4 package using <code>yum</code>:</p> <pre><code>yum install thehive\n</code></pre>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#following-beta-versions","title":"Following beta versions","text":"<p>To follow beta versions of TheHive, use the following setup:</p> <p>And setup your system to connect the RPM repository. Create and edit the file <code>/etc/yum.repos.d/thehive-project.repo</code>:</p> <pre><code>[thehive-project]\nenabled=1\npriority=1\nname=TheHive-Project RPM repository\nbaseurl=https://rpm.thehive-project.org/beta/noarch\ngpgcheck=1\n</code></pre> <p>Then you will able to install  beta version of  TheHive 3.x   package using <code>yum</code>:</p> <pre><code>yum install thehive\n</code></pre> <p>or  install beta version of TheHive 4.x:</p> <pre><code>yum install thehive4\n</code></pre> <p>\u26a0\ufe0f We do not recommend that configuration for production servers</p> <p>Once the package is installed, proceed to the configuration using the Configuration Guide. For additional configuration options, please refer to the Administration Guide.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#deb","title":"DEB","text":"<p>Debian packages are published on a our DEB packages repository. All packages are signed using our GPG key 562CBC1C. Its fingerprint is:</p> <p><code>0CD5 AC59 DE5C 5A8E 0EE1  3849 3D99 BB18 562C BC1C</code></p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#release-versions_1","title":"Release versions","text":"<p>The release repository contains packages for TheHive 3.5.0+ and TheHive 4.0.0+</p> <p>Setup apt configuration  with the <code>release</code> repository:</p> <pre><code>curl https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY | sudo apt-key add -\necho 'deb https://deb.thehive-project.org release main' | sudo tee -a /etc/apt/sources.list.d/thehive-project.list\nsudo apt-get update\n</code></pre> <p>Then you will able to install  TheHive 3.5.0+  the package using <code>apt</code> command:</p> <pre><code>apt install thehive\n</code></pre> <p>or  install TheHive 4.0.0+:</p> <pre><code>apt install thehive4\n</code></pre>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#stable-versions-or-legacy-versions_1","title":"Stable versions (or legacy versions)","text":"<p>The main repository  is a legacy repository and contains packages for TheHive 3.4.4 that does not support Elasticsearch version 7.x, but version 6.x.</p> <p>Setup apt configuration  with the <code>main</code> repository:</p> <pre><code>curl https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY | sudo apt-key add -\necho 'deb https://deb.thehive-project.org stable main' | sudo tee -a /etc/apt/sources.list.d/thehive-project.list\nsudo apt-get update\n</code></pre> <p>Then you will able to install  TheHive 3.4.4   package using <code>apt</code> command:</p> <pre><code>apt install thehive\n</code></pre>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#beta-versions","title":"Beta versions","text":"<p>To follow beta versions of TheHive, use the following commands:</p> <pre><code>curl https://raw.githubusercontent.com/TheHive-Project/TheHive/master/PGP-PUBLIC-KEY | sudo apt-key add -\necho 'deb https://deb.thehive-project.org beta main' | sudo tee -a /etc/apt/sources.list.d/thehive-project.list\nsudo apt-get update\nsudo apt-get install thehive\n</code></pre> <p>\u26a0\ufe0f We do not recommend that configuration for production servers</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#docker","title":"Docker","text":"<p>To use the Docker image, you must use Docker (courtesy of Captain Obvious).</p> <p>TheHive requires Elasticsearch to run. You can use <code>docker-compose</code> to start them together in Docker or install and configure Elasticsearch manually.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#use-docker-compose","title":"Use Docker-compose","text":"<p>Docker-compose can start multiple dockers and link them together.</p> <p>The following docker-compose.yml file starts Elasticsearch and TheHive: <pre><code>version: \"2\"\nservices:\n  elasticsearch:\n    image: elasticsearch:7.9.1\n    environment:\n      - http.host=0.0.0.0\n      - discovery.type=single-node\n    ulimits:\n      nofile:\n        soft: 65536\n        hard: 65536\n  cortex:\n    image: thehiveproject/cortex:3.1.0-1\n    depends_on:\n      - elasticsearch\n    ports:\n      - \"0.0.0.0:9001:9001\"\n  thehive:\n    image: thehiveproject/thehive:3.5.0-1\n    depends_on:\n      - elasticsearch\n      - cortex\n    ports:\n      - \"0.0.0.0:9000:9000\"\n    command: --cortex-port 9001\n</code></pre></p> <p>Put this file in an empty folder and run <code>docker-compose up</code>. TheHive is exposed on 9000/tcp port and Cortex on 9001/tcp. These ports can be changed by modifying the <code>docker-compose</code> file.</p> <p>You can specify a custom TheHive configuration file (<code>application.conf</code>) by adding the following lines in the <code>thehive</code> section of your docker-compose file:</p> <pre><code>volumes:\n    - /path/to/application.conf:/etc/thehive/application.conf\n</code></pre> <p>To take effect, be sure that: - '/path/to/application.conf' is readable for the user who runs the docker daemon (typically 644) - you specified <code>command: --no-config</code> in your <code>docker-compose.yml</code> file</p> <p>You should define where the data (i.e. the Elasticsearch database) will be located on your operating system by adding the following lines in the <code>elasticsearch</code> section of your docker-compose file: <pre><code>volumes:\n    - /path/to/data:/usr/share/elasticsearch/data\n</code></pre></p> <p>Running ElasticSearch in production mode requires a minimum <code>vm.max_map_count</code> of 262144. ElasticSearch documentation provides instructions on how to query and change this value.</p> <p>If you want to make Cortex be available on TheHive, you must create an account on Cortex, define an API key for it and provide that key to TheHive container using parameter <code>--cortex-key</code> or environment <code>TH_CORTEX_KEY</code>.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#manual-installation-of-elasticsearch","title":"Manual Installation of Elasticsearch","text":"<p>Elasticsearch can be installed on the same server as TheHive or on a different one. You can then configure TheHive according to the documentation and run TheHive docker as follow:</p> <pre><code>docker run --volume /path/to/thehive/application.conf:/etc/thehive/application.conf thehiveproject/thehive:latest --no-config\n</code></pre> <p>You can add the <code>--publish</code> docker option to expose TheHive HTTP service.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#customize-the-docker-image","title":"Customize the Docker Image","text":"<p>By default, the TheHive Docker image has minimal configuration:  - choose a random secret (<code>play.http.secret.key</code>)  - search for the Elasticsearch instance (host named <code>elasticsearch</code>) and add it to configuration  - search for a Cortex instance (host named <code>cortex</code>) and add it to configuration</p> <p>This behavior can be disabled by adding <code>--no-config</code> to the Docker command line:</p> <p><code>docker run thehiveproject/thehive:latest --no-config</code></p> <p>Or by adding the line <code>command: --no-config</code> in the <code>thehive</code> section of docker-compose file.</p> <p>It is possible to start database migration at startup with the parameter <code>--auto-migration</code>. If the initial administrator doesn't exist yet, you can request its creation with <code>--create-admin</code> followed by the user login and its password. You can also create a normal user with <code>--create-user</code> followed by the user login and its roles and its password.</p> <p>The image accepts more options. All options are available using environment variables. For boolean variable, <code>1</code> means true and other value means false. For multivalued variables, values are separated by coma. This is possible only with <code>--create-admin</code>.</p> Option Env variable Description <code>--no-config</code> TH_NO_CONFIG Do not try to configure TheHive (add the secret and Elasticsearch) <code>--no-config-secret</code> TH_NO_CONFIG_SECRET Do not add the random secret to the configuration <code>--secret &lt;secret&gt;</code> TH_SECRET Cryptographic secret needed to secure sessions <code>--show-secret</code> TH_SHOW_SECRET Show the generated secret <code>--no-config-es</code> TH_NO_CONFIG_ES Do not add the Elasticsearch hosts to configuration <code>--es-uri &lt;uri&gt;</code> TH_CONFIG_ES Use this string to configure elasticsearch hosts (format: http(s)://host:port,host:port(/prefix)?querystring) <code>--es-hostname &lt;host&gt;</code> TH_ES_HOSTNAME Resolve this hostname to find Elasticsearch instances <code>--no-config-cortex</code> TH_NO_CONFIG_CORTEX Do not add Cortex configuration <code>--cortex-proto &lt;proto&gt;</code> TH_CORTEX_PROTO Define the protocol to connect to Cortex (default: <code>http</code>) <code>--cortex-port &lt;port&gt;</code> TH_CORTEX_PORT Define the port to connect to Cortex (default: <code>9001</code>) <code>--cortex-url &lt;url&gt;</code> TH_CORTEX_URL Add the Cortex connection <code>--cortex-hostname &lt;host&gt;</code> TH_CORTEX_HOSTNAME Resolve this hostname to find the Cortex instance <code>--cortex-key &lt;key&gt;</code> TH_CORTEX_KEY Define Cortex key <code>--auto-migration</code> TH_AUTO_MIGRATION Migrate the database, if needed <code>--create-admin &lt;user&gt; &lt;password</code> TH_CREATE_ADMIN_LOGIN TH_CREATE_ADMIN_PASSWORD Create the first admin user, if not exist yet <code>--create-user &lt;user&gt; &lt;role&gt; &lt;password&gt;</code> TH_CREATE_USER_LOGIN TH_CREATE_USER_ROLE TH_CREATE_USER_PASSWORD Create a user, only in conjunction with admin creation <p>Note: please remember that you must install and configure Elasticsearch.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#what-to-do-next","title":"What to Do Next?","text":"<p>Once the Docker image is up and running, proceed to the configuration using the Configuration Guide. For additional configuration options, please refer to the Administration Guide.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#pre-release-versions","title":"Pre-release Versions","text":"<p>If you would like to use pre-release, beta versions of our Docker images and help us find bugs to the benefit of the whole community, please use <code>thehiveproject/thehive:version-RCx</code>. For example <code>thehiveproject/thehive:3.1.0-RC1</code>.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#binary","title":"Binary","text":"<p>The following section contains the instructions to manually install TheHive using binaries on Ubuntu 20.04 LTS.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#1-minimal-ubuntu-installation","title":"1. Minimal Ubuntu Installation","text":"<p>Install a minimal Ubuntu 20.04 system with the following software:</p> <ul> <li>Java runtime environment 1.8+ (JRE)</li> <li>Elasticsearch 7.x</li> </ul> <p>Make sure your system is up-to-date:</p> <pre><code>sudo apt-get update\nsudo apt-get upgrade\n</code></pre>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#2-install-a-java-virtual-machine","title":"2. Install a Java Virtual Machine","text":"<p>You can install either Oracle Java or OpenJDK. The latter is recommended.</p> <pre><code>sudo apt-get install openjdk-11-jre-headless\n</code></pre>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#3-install-elasticsearch","title":"3. Install Elasticsearch","text":"<p>To install Elasticsearch, please read the Elasticsearch Installation section below.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#4-install-thehive","title":"4. Install TheHive","text":"<p>Binary packages can be downloaded from Bintray. The latest version is called thehive-latest.zip.</p> <p>Download and unzip the chosen binary package. TheHive files can be installed wherever you want on the filesystem. In this guide, we assume you have chosen to install them under <code>/opt</code>.</p> <pre><code>cd /opt\nwget https://download.thehive-project.org/thehive-latest.zip\nunzip thehive-latest.zip\nln -s thehive-x.x.x thehive\n</code></pre> <p>Note: if you would like to use pre-release, beta versions of and help us find bugs to the benefit of the whole community, please download <code>https://download.thehive-project.org/thehive-version-RCx.zip</code>. For example <code>https://download.thehive-project.org/thehive-3.5.0-RC1-1.zip</code>.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#5-first-start","title":"5. First start","text":"<p>It is recommended to use a dedicated, non-privileged user account to start TheHive. If so, make sure that the chosen account can create log files in <code>/opt/thehive/logs</code>.</p> <p>If you'd rather start the application as a service, use the following commands:</p> <pre><code>sudo addgroup thehive\nsudo adduser --system thehive\nsudo cp /opt/thehive/package/thehive.service /usr/lib/systemd/system\nsudo chown -R thehive:thehive /opt/thehive\nsudo chgrp thehive /etc/thehive/application.conf\nsudo chmod 640 /etc/thehive/application.conf\nsudo systemctl enable thehive\nsudo service thehive start\n</code></pre> <p>The only required parameter in order to start TheHive is the key of the server (<code>play.http.secret.key</code>). This key is used to authenticate cookies that contain data. If TheHive runs in cluster mode, all instances must share the same key. You can generate the minimal configuration with the following commands (they assume that you have created a dedicated user for TheHive, named <code>thehive</code>):</p> <pre><code>sudo mkdir /etc/thehive\n(cat &lt;&lt; _EOF_\n# Secret key\n# ~~~~~\n# The secret key is used to secure cryptographics functions.\n# If you deploy your application to several instances be sure to use the same key!\nplay.http.secret.key=\"$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 64 | head -n 1)\"\n_EOF_\n) | sudo tee -a /etc/thehive/application.conf\n</code></pre> <p>Now you can start TheHive. To do so, change your current directory to the TheHive installation directory (<code>/opt/thehive</code> in this guide), then execute:</p> <pre><code>bin/thehive -Dconfig.file=/etc/thehive/application.conf\n</code></pre> <p>Please note that the service may take some time to start. Once it is started, you may launch your browser and connect to <code>http://YOUR_SERVER_ADDRESS:9000/</code>.</p> <p>Please note that the service may take some time to start.</p> <p>The first time you connect you will have to create the database schema. Click \"Migrate database\" to create the DB schema.</p> <p></p> <p>Once done, you should be redirected to the page for creating the administrator's account.</p> <p></p> <p>Once created, you should be redirected to the login page.</p> <p></p> <p>Warning: at this stage, if you missed the creation of the admin account, you will not be able to do it unless you delete TheHive's index from Elasticsearch. In the case you made a mistake, first find out what is the current index of TheHive by running the following command on a host where the Elasticsearch DB used by TheHive is located:</p> <pre><code>$ curl http://127.0.0.1:9200/_cat/indices?v\n</code></pre> <p>The indexes that TheHive uses always start with<code>the_hive_</code> following by a number. Let's assume that the output of the command is:</p> <pre><code>health status index       uuid                   pri rep docs.count docs.deleted store.size pri.store.size\nyellow open   cortex_1    PC_pLFGBS5G2TNQYr4ajgw   5   1        609            6      2.1mb          2.1mb\nyellow open   the_hive_13 ft7GGTfhTr-4lSzZw5r1DQ   5   1     180131            3     51.3mb         51.3mb\n</code></pre> <p>The index used by TheHive is <code>the_hive_13</code>. To delete it, run the following command:</p> <pre><code>$ curl -X DELETE http://127.0.0.1:9200/the_hive_13\n</code></pre> <p>Then reload the page or restart TheHive.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#6-update","title":"6. Update","text":"<p>To update TheHive from binaries, just stop the service, download the latest package, rebuild the link <code>/opt/thehive</code> and restart the service.</p> <pre><code>service thehive stop\ncd /opt\nwget https://download.thehive-project.org/thehive-latest.zip\nunzip thehive-latest.zip\nrm /opt/thehive &amp;&amp; ln -s thehive-x.x.x thehive\nchown -R thehive:thehive /opt/thehive /opt/thehive-x.x.x\nservice thehive start\n</code></pre>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#7-configuration","title":"7. Configuration","text":"<p>To configure TheHive, read the Configuration Guide. For additional configuration options, please refer to the Administration Guide.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#build-it-yourself","title":"Build it Yourself","text":"<p>The following section contains a step-by-step guide to build TheHive from its sources.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#1-pre-requisites","title":"1. Pre-requisites","text":"<p>The following software are required to download and build TheHive:</p> <ul> <li>Java Development Kit 11 (JDK)</li> <li>git: use the system package or download it</li> <li>Node.js with its package manager (NPM)</li> <li>Grunt: after installing Node.js, run <code>sudo npm install -g grunt-cli</code></li> <li>Bower: after installing Node.js, run <code>sudo npm install -g bower</code></li> <li>Elasticsearch 5.6</li> </ul>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#2-build","title":"2. Build","text":"<p>To install the requirements and build TheHive from sources, please follow the instructions below depending on your operating system.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#21-centosrhel","title":"2.1. CentOS/RHEL","text":"<p>Packages</p> <pre><code>sudo yum -y install git bzip2\n</code></pre> <p>Installation of OpenJDK</p> <pre><code>sudo yum -y install java-11-openjdk-devel\n</code></pre> <p>Installation of Node.js</p> <p>Install the EPEL repository. You should have the extras repository enabled, then:</p> <pre><code>sudo yum -y install epel-release\n</code></pre> <p>Then, you can install Node.js, Grunt, and Bower:</p> <pre><code>sudo yum -y install nodejs\nsudo npm install -g grunt-cli bower\n</code></pre> <p>Installation of Elasticsearch</p> <p>To install Elasticsearch, please read the Elasticsearch Installation section below.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#22-ubuntu","title":"2.2. Ubuntu","text":"<p>Packages</p> <pre><code>sudo apt-get install git wget\n</code></pre> <p>Installation of Oracle JDK</p> <pre><code>sudo apt install openjdk-11-jdk-headless\n</code></pre> <p>Installation of Node.js, Grunt and Bower</p> <pre><code>sudo apt-get install curl\ncurl -sL https://deb.nodesource.com/setup_11.x | sudo -E bash -\nsudo apt-get install -y nodejs\nsudo npm install -g grunt-cli bower\n</code></pre> <p>Installation of Elasticsearch</p> <p>To install Elasticsearch, please read the Elasticsearch Installation section below.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#23-thehive","title":"2.3. TheHive","text":"<p>Download The Source</p> <pre><code>git clone https://github.com/TheHive-Project/TheHive.git\n</code></pre> <p>Build the Project</p> <pre><code>cd TheHive\n./sbt clean stage\n</code></pre> <p>This operation may take some time to complete as it will download all dependencies  then build the back-end. This command cleans previous build files and creates an autonomous package in the <code>target/universal/stage</code> directory. This packages contains TheHive binaries with required libraries (<code>/lib</code>), configuration files (<code>/conf</code>) and startup scripts (<code>/bin</code>).</p> <p>Binaries are built and stored in <code>TheHive/target/universal/stage/</code>. You can install them in <code>/opt/thehive</code> for example.</p> <pre><code>sudo cp -r TheHive/target/universal/stage /opt/thehive\n</code></pre> <p>Configure TheHive, read the Configuration Guide. For additional configuration options, please refer to the Administration Guide.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#24-configure-and-start-elasticsearch","title":"2.4 Configure and Start Elasticsearch","text":"<p>Edit <code>/etc/elasticsearch/elasticsearch.yml</code> and add the following lines:</p> <pre><code>http.host: 127.0.0.1\ndiscovery.type: single-node\ncluster.name: hive\nthread_pool.search.queue_size: 100000\n</code></pre> <p>Start the service:</p> <pre><code>service elasticsearch restart\n</code></pre>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#3-first-start","title":"3. First start","text":"<p>Follow the first start section of the binary installation method above to start using TheHive.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#4-build-the-front-end-only","title":"4. Build the Front-end Only","text":"<p>Building the back-end builds also the front-end, so you don't need to build it separately. This section is useful only for troubleshooting or for installing the front-end on a reverse proxy.</p> <p>Go to the front-end directory: <pre><code>cd TheHive/ui\n</code></pre></p> <p>Install Node.js libraries, which are required by this step, bower libraries (JavaScript libraries downloaded by the browser). Then build the front-end : <pre><code>npm install\nbower install\ngrunt build\n</code></pre></p> <p>This step generates static files (HTML, JavaScript and related resources) in  the <code>dist</code> directory. They can be readily imported on a HTTP server.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#elasticsearch-installation","title":"Elasticsearch Installation","text":"<p>If, for some reason, you need to install Elasticsearch, it can be installed using a system package or a Docker image. Version 5.X must be used. From version 6, Elasticsearch drops mapping type.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#system-package","title":"System Package","text":"<p>Install the Elasticsearch package provided by Elastic</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#debian-ubuntu","title":"Debian, Ubuntu","text":"<pre><code># PGP key installation\nsudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-key D88E42B4\n\n# Alternative PGP key installation\n# wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -\n\n# Debian repository configuration\necho \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list\n\n# Install https support for apt\nsudo apt install apt-transport-https\n\n# Elasticsearch installation\nsudo apt update &amp;&amp; sudo apt install elasticsearch\n</code></pre> <p>The Debian package does not start up the service by default,  to prevent the instance from accidentally joining a cluster, without being configured appropriately.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#centos-redhat-opensuse","title":"CentOS, RedHat, OpenSuSE","text":"<pre><code># PGP key installation\nsudo rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch\n</code></pre> <p>Create the file <code>elasticsearch.repo</code> in <code>/etc/yum.repos.d/</code> for RedHat and CentOS, or in <code>/etc/zypp/repos.d/</code> for OpenSuSE distributions, and add the following lines:</p> <pre><code>[elasticsearch-5.x]\nname=Elasticsearch repository for 7.x packages\nbaseurl=https://artifacts.elastic.co/packages/7.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n</code></pre> <p>Then, you can use the following command:</p> <pre><code># On CentOS and older Red Hat based distributions.\nsudo yum install elasticsearch\n\n# On Fedora and other newer Red Hat distributions.\nsudo dnf install elasticsearch\n\n# On OpenSUSE based distributions.\nsudo zypper install elasticsearch\n</code></pre> <p>If you prefer using Elasticsearch inside a docker, see Elasticsearch inside a Docker.</p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#configuration","title":"Configuration","text":"<p>It is highly recommended to avoid exposing this service to an untrusted zone.</p> <p>If Elasticsearch and TheHive run on the same host (and not in a docker), edit <code>/etc/elasticsearch/elasticsearch.yml</code> and set <code>network.host</code> parameter with <code>127.0.0.1</code>. TheHive use dynamic scripts to make partial updates. Hence, they must be activated using <code>script.inline: true</code>.</p> <p>The cluster name must also be set (<code>hive</code> for example). Threadpool queue size must be set with a high value (<code>100000</code>). The default size will get the queue easily overloaded.</p> <p>Edit <code>/etc/elasticsearch/elasticsearch.yml</code> and add the following lines:</p> <pre><code>http.host: 127.0.0.1\ncluster.name: hive\nthread_pool.search.queue_size: 100000\n</code></pre>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#start-the-service","title":"Start the Service","text":"<p>Now that Elasticsearch is configured, start it as a service and check whether it's running: <pre><code>sudo systemctl enable elasticsearch.service\nsudo systemctl start elasticsearch.service\nsudo systemctl status elasticsearch.service\n</code></pre></p> <p>The status should be <code>active (running)</code>. If it's not running, you can check for the reason in the logs: <pre><code>sudo journalctl -u elasticsearch.service\n</code></pre></p> <p>Note that by default, the database is stored in <code>/var/lib/elasticsearch</code> and the logs in <code>/var/log/elasticsearch</code></p>"},{"location":"thehive/legacy/thehive3/installation/install-guide/#elasticsearch-inside-a-docker","title":"Elasticsearch inside a Docker","text":"<p>You can also start Elasticsearch inside a docker. Use the following command and do not forget to specify the absolute path for persistent data on your host :</p> <pre><code>docker run \\\n  --name elasticsearch \\\n  --hostname elasticsearch \\\n  --rm \\\n  --publish 127.0.0.1:9200:9200 \\\n      --volume ***DATA_DIR***:/usr/share/elasticsearch/data \\\n    -e \"http.host=0.0.0.0\" \\\n    -e \"discovery.type=single-node\" \\\n    -e \"xpack.security.enabled=false\" \\\n    -e \"cluster.name=hive\" \\\n  -e \"script.inline=true\" \\\n  -e \"thread_pool.index.queue_size=100000\" \\\n  -e \"thread_pool.search.queue_size=100000\" \\\n  -e \"thread_pool.bulk.queue_size=100000\" \\\n    docker.elastic.co/elasticsearch/elasticsearch:7.9.1\n</code></pre>"},{"location":"thehive/operations/backup-restore/","title":"Backup and restore","text":"<p>This guide has only been tested on single node Cassandra server</p> <p>Note</p> <ul> <li>https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/operations/opsBackupRestore.html</li> </ul>"},{"location":"thehive/operations/backup-restore/#overview","title":"Overview","text":"<p>To be restored successfully, TheHive requires following data beeing saved: </p> <ul> <li>The database</li> <li>Files</li> <li>optionnally, the index. </li> </ul>"},{"location":"thehive/operations/backup-restore/#cassandra","title":"Cassandra","text":""},{"location":"thehive/operations/backup-restore/#pre-requisites","title":"Pre requisites","text":"<p>To backup or export database from Cassandra, following information are required: </p> <ul> <li>Cassandra admin password</li> <li>keyspace used by thehive (default = <code>thehive</code>). This can be checked in the <code>application.conf</code>configuration file, in the database configuration in storage, cql and <code>keyspace</code> attribute. </li> </ul> <p>Tip</p> <p>This information can be found in TheHive configuration: </p> <pre><code>[..]\ndb.janusgraph {\n    storage {\n    backend: cql\n    hostname: [\"127.0.0.1\"]\n\n    cql {\n        cluster-name: thp\n        keyspace: thehive \n    }\n    }\n[..]\n</code></pre>"},{"location":"thehive/operations/backup-restore/#backup","title":"Backup","text":"<p>Following actions should be performed to backup the data successfully: </p> <ul> <li>Save the database schema</li> <li>Create a snapshot</li> <li>Save the data and the schema</li> </ul>"},{"location":"thehive/operations/backup-restore/#save-the-database-schema","title":"Save the database schema","text":"<p>This can be done with the following command: </p> <pre><code>cqlsh -u cassandra -p &lt;CASSANDRA_PASSWORD&gt; &lt;SERVER_IP&gt; -e \"DESCRIBE KEYSPACE &lt;KEYSPACE&gt;\" &gt; schema.cql\n</code></pre>"},{"location":"thehive/operations/backup-restore/#create-a-snapshot-and-an-archive","title":"Create a snapshot and an archive","text":"<p>Considering that your keyspace is <code>thehive</code> and <code>backup_name</code> is the name of the snapshot, run the following commands:</p> <ol> <li> <p>Before taking snapshots</p> <pre><code>nodetool cleanup thehive\n</code></pre> </li> <li> <p>Take a snapshot</p> <pre><code>nodetool snapshot thehive -t backup_name\n</code></pre> </li> <li> <p>Create and archive with the snapshot data: </p> <pre><code>tar cjf backup.tbz /var/lib/cassandra/data/thehive/*/snapshots/backup_name/\n</code></pre> </li> <li> <p>Remove old snapshots (if necessary)</p> <pre><code>nodetool -h localhost -p 7199 clearsnapshot -t &lt;snapshotname&gt;\n</code></pre> </li> </ol>"},{"location":"thehive/operations/backup-restore/#example","title":"Example","text":"<p>Example of script to generate backups of TheHive keyspace</p> <pre><code>#!/bin/bash\n\n## Create a CQL file with the schema of the KEYSPACE\n## and an tbz archive containing the snapshot\n\n## Complete variables before running:\n## KEYSPACE: Identify the right keyspace to save in cassandra\n## SNAPSHOT: choose a name for the backup\n\nIP=10.1.1.1\nSOURCE_KEYSPACE=thehive\nSNAPSHOT=thehive_20211124\nSNAPSHOT_INDEX=1\n\n# Backup Cassandra\n\nnodetool cleanup ${SOURCE_KEYSPACE}\n\nnodetool snapshot ${SOURCE_KEYSPACE}  -t ${SNAPSHOT}_${SNAPSHOT_INDEX}\n\necho -n \"Cassandra admin password\":\nread -s CASSANDRA_PASSWORD\n\n## Save schema\ncqlsh -u cassandra -p ${CASSANDRA_PASSWORD} ${IP} -e \"DESCRIBE KEYSPACE ${SOURCE_KEYSPACE}\" &gt; schema_${SNAPSHOT}_${SNAPSHOT_INDEX}.cql\n\n## Create archive\nif [[ $? == 0 ]]\nthen\ntar cjf ${SNAPSHOT}_${SNAPSHOT_INDEX}.tbz /var/lib/cassandra/data/${SOURCE_KEYSPACE}/*/snapshots/${SNAPSHOT}_${SNAPSHOT_INDEX}/\nfi\n</code></pre>"},{"location":"thehive/operations/backup-restore/#restore-data","title":"Restore data","text":""},{"location":"thehive/operations/backup-restore/#pre-requisites_1","title":"Pre requisites","text":"<p>Following data is required to restore TheHive database successfully: </p> <ul> <li>The database schema (example: <code>schema.cql</code>)</li> <li>A backup of the database (example: <code>backup.tbz</code>)</li> <li>Keyspace to restore does not exist in the database (or it will be overwritten)</li> </ul>"},{"location":"thehive/operations/backup-restore/#restore","title":"Restore","text":"<ol> <li> <p>Restore keyspace</p> <pre><code>cqlsh -u cassandra -p &lt;CASSANDRA_PASSWORD&gt; &lt;IP&gt; -e \"source 'schema.cql';\"\n</code></pre> </li> <li> <p>Unarchive backup files: </p> <pre><code>tar jxf /PATH/TO/backup.tbz -C /tmp/cassandra_backup\n</code></pre> </li> <li> <p>And restore snapshots files:</p> <pre><code>cd /var/lib/cassandra/data/thehive\n\nfor I in `ls /tmp/cassandra/var/lib/cassandra/data/&lt;KEYSPACE&gt;`  ; do cp /tmp/cassandra/var/lib/cassandra/data/&lt;KEYSPACE&gt;/$I/snapshots/&lt;BACKUP_NAME&gt;/* /var/lib/cassandra/data/&lt;KEYSPACE&gt;/$I/ ; done\n</code></pre> </li> <li> <p>Ensure Cassandra user keep ownership on the files: </p> <pre><code>chown -R cassandra:cassandra /var/lib/cassandra/data/&lt;KEYSPACE&gt;\n</code></pre> </li> <li> <p>Refresh tables</p> <pre><code>for TABLE in `ls /var/lib/cassandra/data/&lt;KEYSPACE&gt;`\ndo sstableloader -d &lt;IP&gt; /var/lib/cassandra/data/&lt;KEYSPACE&gt;/&lt;TABLE&gt;\ndone\n</code></pre> </li> </ol> <p>Ensure no Commitlog file exist before restarting Cassandra service. (<code>/var/lib/cassandra/commitlog</code>)</p> <p>Example of script to restore TheHive keyspace in Cassandra</p> <pre><code>#!/bin/bash\n\n## Restore a KEYSPACE and its data from a CQL file with the schema of the\n## KEYSPACE and an tbz archive containing the snapshot\n\n## Complete variables before running:\n## IP: IP of cassandra server\n## TMP: choose a TMP folder !!! this folder will be removed if exists.\n## SOURCE_KEYSPACE: KEYSPACE used in the backup\n## TARGET_KEYSPACE: new KEYSPACE name ; use same name of SOURCE_KEYSPACE if no changes\n## SNAPSHOT: choose a name for the backup\n## SNAPSHOT_INDEX: index of the snapshot (1, 20210401 ...)\n\nIP=10.1.1.1\nTMP=/tmp/cassandra_backup\nSOURCE_KEYSPACE=\"thehive\"\nTARGET_KEYSPACE=\"\"\nSNAPSHOT=\"thehive_20211124\"\nSNAPSHOT_INDEX=\"1\"\n\n## Uncompress data in TMP folder\nrm -rf ${TMP} &amp;&amp; mkdir ${TMP} \ntar jxf ${SNAPSHOT}_${SNAPSHOT_INDEX}.tbz -C ${TMP}\n\n## Read Cassandra password\necho -n \"Cassandra admin password: \" read -s CASSANDRA_PASSWORD\n\n## Define new KEYSPACE NAME\nsed -i \"s/${SOURCE_KEYSPACE}/${TARGET_KEYSPACE}/g\" schema_${SNAPSHOT}_${SNAPSHOT_INDEX}.cql\n\n## Restore keyspace\ncqlsh -u cassandra -p ${CASSANDRA_PASSWORD} cassandra --file schema_${SNAPSHOT}_${SNAPSHOT_INDEX}.cql\n\n## Restore data\nfor TABLE in `cqlsh -u cassandra -p ${CASSANDRA_PASSWORD} ${IP} -e \"use ${TARGET_KEYSPACE}; DESC tables ;\"`\ndo\ncp -r ${TMP}/var/lib/cassandra/data/${SOURCE_KEYSPACE}/${TABLE}-*/snapshots/${SNAPSHOT}_${SNAPSHOT_INDEX}/* /var/lib/cassandra/data/${TARGET_KEYSPACE}/$TABLE-*/\ndone\n\n## Change ownership\nchown -R cassandra:cassandra /var/lib/cassandra/data/${TARGET_KEYSPACE}\n\n\n## sstableloader\nfor TABLE in `ls /var/lib/cassandra/data/${TARGET_KEYSPACE}`\ndo sstableloader -d ${IP} /var/lib/cassandra/data/${TARGET_KEYSPACE}/${TABLE}\ndone\n</code></pre>"},{"location":"thehive/operations/backup-restore/#files","title":"Files","text":""},{"location":"thehive/operations/backup-restore/#backup_1","title":"Backup","text":"<p>Wether you use local or distributed files system storage, copy the content of the folder/bucket.</p>"},{"location":"thehive/operations/backup-restore/#restore_1","title":"Restore","text":"<p>Restore the saved files into the destination folder/bucket that will be used by TheHive.</p>"},{"location":"thehive/operations/cassandra-security/","title":"Security in Apache Cassandra","text":"<p>References</p> <p>Internal authentication</p> <ul> <li>https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/configuration/secureInternalAuthenticationTOC.html</li> </ul> <p>Node to node encryption</p> <ul> <li>https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/configuration/secureSSLNodeToNode.html</li> </ul> <p>Client to node encryption</p> <ul> <li>https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/configuration/secureSSLClientToNode.html</li> <li>https://docs.janusgraph.org/basics/configuration-reference/#storagecqlssl</li> </ul>"},{"location":"thehive/operations/cassandra-security/#authentication-with-cassandra","title":"Authentication with Cassandra","text":"<ul> <li>Create an account and grant permissions on keyspace</li> </ul> <pre><code>CREATE ROLE thehive WITH PASSWORD = 'thehive1234' AND LOGIN = true;\nGRANT ALL PERMISSIONS ON KEYSPACE thehive TO thehive;\n</code></pre> <ul> <li>Configure TheHive with the account </li> </ul> <p>Update <code>/etc/thehive/application.conf</code> accordingly: </p> <pre><code>db.janusgraph {\n  storage {\n    ## Cassandra configuration\n    # More information at https://docs.janusgraph.org/basics/configuration-reference/#storagecql\n    backend: cql\n    hostname: [\"xxx.xxx.xxx.xxx\"]\n    # Cassandra authentication (if configured)\n    username: \"thehive\" \n    password: \"thehive1234\" \n    cql {\n      cluster-name: thp\n      keyspace: thehive\n    }\n  }\n</code></pre>"},{"location":"thehive/operations/cassandra-security/#cassandra-node-to-node-encryption","title":"Cassandra node to node encryption","text":"<p>This document addresses communication between Cassandra servers, when a Cassandra cluster contains several nodes. </p> <pre><code>server_encryption_options:\ninternode_encryption: all\nkeystore: /path/to/keystore.jks\nkeystore_password: keystorepassword\ntruststore: /path/to/truststore.jks\ntruststore_password: truststorepassword\n# More advanced defaults below:\nprotocol: TLS\nalgorithm: SunX509\nstore_type: JKS\ncipher_suites: [TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_DHE_RSA_WITH_\nAES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_R\nSA_WITH_AES_256_CBC_SHA]\nrequire_client_auth: false\n</code></pre>"},{"location":"thehive/operations/cassandra-security/#cassandra-dedicated-port-for-ssl-optional","title":"Cassandra dedicated port for SSL (optional)","text":"<p>Optionally, you can setup a dedicated port for SSL communication. Update <code>/etc/cassandra/cassandra.yml</code> configuration file on each node: </p> <pre><code>native_transport_port_ssl: 9142\n</code></pre> <p>Note</p> <p>By doing so, all SSL communications will be done using this port. Without this parameter, SSL is setup on <code>native_transport_port</code>. (everything is explained in the <code>cassandra.yaml</code> configuration file).</p>"},{"location":"thehive/operations/cassandra-security/#client-to-node-encryption","title":"Client to node encryption","text":"<p>This guide explains how to secure connection between Cassandra server and Cassandra clients (TheHive). This document doesn\u2019t address communication between Cassandra servers, when a Cassandra cluster contains several nodes. </p>"},{"location":"thehive/operations/cassandra-security/#requirements","title":"Requirements","text":"<p>The setup requires a valid X509 certificate for the Cassandra service. It must have standard properties of server certificate:</p> <ul> <li>key usage: Digital Signature, Non Repudiation, Key Encipherment, Key Agreement</li> <li>Extended Key Usage: TLS Web Server Authentication</li> <li>Cert Type: SSL Server</li> </ul> <p>It also must have a \"Subject Alternative Name\" with the identifier (DNS name or/and IP address) of the Cassandra server seen by the client. The format of the certificate file is PKCS12 (file with extention p12).</p> <p>Then create a truststore containing the certificate authority used to generate the certificate for Cassandra. The truststore must be in Java format (JKS). If you CA file is ca.crt, you can generate the truststore file with the following command:</p> <pre><code>keytool -import -file /path/to/ca.crt -alias CA -keystore ca.jks\n</code></pre> <p>This command ask a password for file integrity checking.</p> <p>The command <code>keytool</code> is available in any JDK distribution.</p>"},{"location":"thehive/operations/cassandra-security/#configuring-cassandra","title":"Configuring Cassandra","text":"<p>Locate the section <code>client_encryption_options</code> and set the following options:</p> <p><pre><code>client_encryption_options:\nenabled: true\n# If enabled and optional is set to true encrypted and unencrypted connections are handled.\noptional: false\nkeystore: /pat/to/keystore.jks\nkeystore_password: keystorepassword\nrequire_client_auth: false\n# Set trustore and truststore_password if require_client_auth is true\n# truststore: conf/.truststore\n# truststore_password: cassandra\n# More advanced defaults below:\nprotocol: TLS\nalgorithm: SunX509\nstore_type: JKS\ncipher_suites: [TLS_RSA_WITH_AES_128_CBC_SHA,TLS_RSA_WITH_AES_256_CBC_SHA,TLS_DHE_RSA_WITH_\nAES_128_CBC_SHA,TLS_DHE_RSA_WITH_AES_256_CBC_SHA,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA,TLS_ECDHE_R\nSA_WITH_AES_256_CBC_SHA]\n</code></pre> Then the service cassandra must be restarted.</p>"},{"location":"thehive/operations/cassandra-security/#configuring-thehive","title":"Configuring TheHive","text":"<p><pre><code>db.janusgraph {\n  storage {\n    ## Cassandra configuration\n    # More information at https://docs.janusgraph.org/basics/configuration-reference/#storagecql\n    backend: cql\n    hostname: [\"ip_node_1\", \"ip_node_2\", \"ip_node_3\"]\n    # Cassandra authentication (if configured)\n    username: \"thehive\"\n    password: \"thehive1234\"\n    port: 9142 # if alternative port has been set in Cassandra configuration\n    cql {\n      cluster-name: thp\n      keyspace: thehive\n      ssl {\n        enabled: true\n        truststore {\n          location: \"/path/to/truststore.jks\"\n          password: \"truststorepassword\"\n        }\n      }\n    }\n  }\n</code></pre> Then the service thehive must be restarted.</p>"},{"location":"thehive/operations/fail2ban/","title":"Fail2ban","text":""},{"location":"thehive/operations/fail2ban/#adding-thehive-into-fail2ban","title":"Adding TheHive into Fail2Ban","text":"<p>Considering TheHive logs sit in <code>/var/log/thehive/application.log</code> and fail2ban  configuration is in <code>/etc/fail2ban</code>:</p> <ol> <li> <p>Add a filter file in <code>/etc/fail2ban/filter.d</code> named <code>thehive.conf</code> with the following content: </p> <pre><code>[INCLUDES]\nbefore = common.conf\n\n[Definition]\nfailregex = ^.*- &lt;HOST&gt; (?:POST \\/api\\/login|GET .*) .*returned 401.*$\nignoreregex =\n</code></pre> </li> <li> <p>Add a jail file in <code>/etc/fail2ban/jail.d/</code>named <code>thehive.local</code> with the following content: </p> <pre><code>[thehive]\nenabled = true\nport = 80,443\nfilter = thehive\naction = iptables-multiport[name=thehive, port=\"80,443\"]\nlogpath = /var/log/thehive/application.log\nmaxretry = 5\nbantime = 14400\nfindtime = 1200\n</code></pre> <p>This will ban any IP address for 4 hours after 5 failed authentication are identified during a period of 20 min. </p> </li> <li> <p>Reload the configuration with the command <code>fail2ban-client reload</code></p> </li> </ol>"},{"location":"thehive/operations/fail2ban/#manage-banned-ip-addresses","title":"Manage banned IP addresses","text":"<ul> <li> <p>Review banned IP addresses: </p> <pre><code>fail2ban-client status thehive\n</code></pre> </li> <li> <p>Unban an IP address: </p> <pre><code>fail2ban-client set thehive unbanip &lt;IP ADDRESS&gt;\n</code></pre> </li> </ul>"},{"location":"thehive/operations/migration/","title":"Migration to TheHive 4","text":"<p>TheHive 4.x is delivered with a tool to migrate your data from TheHive 3.x. stored in Elasticsearch. </p>"},{"location":"thehive/operations/migration/#supported-versions","title":"Supported versions","text":"<p>Starting with TheHive 4.1.17, the migration tool supports migrating data from both TheHive 3.4.x and 3.5.x. </p> Migrating from Possible target version TheHive 3.4.x + Elasticsearch 6.x TheHive 4.1.17+ TheHive 3.5.x + Elasticsearch 7.x TheHive 4.1.17+"},{"location":"thehive/operations/migration/#how-it-works","title":"How it works","text":"<p>All packages of TheHive4 distributed come with the migration program which can be used to import data from TheHive 3.4.0+. By default, it is installed in <code>/opt/thehive/bin/migrate</code>. </p>"},{"location":"thehive/operations/migration/#pre-requisite","title":"Pre-requisite","text":"<p>In order to migrate the data: </p> <ul> <li> <p>TheHive 4 must be installed on the system running the migration tool; </p> </li> <li> <p>TheHive4 must be configured ; in particular database, index, and file storage ;  </p> </li> <li>The service <code>thehive</code> must be stopped (<code>service thehive stop</code>) on the target server. </li> </ul> <p>This tools must also have access to Elasticsearch database (http://ES:9200) used by TheHive 3, and the configuration file of TheHive 3.x instance. </p>"},{"location":"thehive/operations/migration/#configuration-of-thehive-4","title":"Configuration of TheHive 4","text":"<p>Warning</p> <p>In TheHive4, users are identified by their email addresses. Thus, a domain will be appended to usernames in order to migrate users from TheHive 3. </p> <p>TheHive 4.x comes with a default domain named <code>thehive.local</code>. Starting the migration without explicitely specifying a domain name will result in migrating all users with a username formatted like  <code>user@thehive.local</code>. </p> <p>Change the default domain name used to import existing users in the configuration file of TheHive4 (<code>/etc/thehive/application.conf</code>) ;  add or update the setting named  <code>auth.defaultUserDomain</code>: </p> <pre><code>auth.defaultUserDomain: \"mydomain.com\"\n</code></pre> <p>This way, the domain <code>mydomain.com</code> will be appended to user accounts imported from TheHive 3.4+ (<code>user@mydomain.com</code>).</p>"},{"location":"thehive/operations/migration/#run-the-migration","title":"Run the migration","text":"<p>Prepare, install and configure your new instance of TheHive 4.x by following the associated guides.</p> <p>Once TheHive4 configuration file (<code>/etc/thehive/application.conf</code>) is correctly filled the <code>migrate</code> command ca be executed.</p> <p>Info</p> <p>This recommended to run this program as the user in charge of running TheHive service ( <code>thehive</code> if you are installing the application with DEB or RPM package)</p> <p>The program comes with a large set of options: </p> <pre><code># /opt/thehive/bin/migrate --help\nTheHive migration tool 4.1.17-1\nUsage: migrate [options]\n\n  -v, --version\n  -h, --help\n  -l, --logger-config &lt;file&gt;\n                           logback configuration file\n  -c, --config &lt;file&gt;      global configuration file\n  -i, --input &lt;file&gt;       TheHive3 configuration file\n  -o, --output &lt;file&gt;      TheHive4 configuration file\n  -d, --drop-database      Drop TheHive4 database before migration\n  -r, --resume             Resume migration (or migrate on existing database)\n  -m, --main-organisation &lt;organisation&gt;\n  -u, --es-uri http://ip1:port,ip2:port\n                           TheHive3 ElasticSearch URI\n  -e, --es-index &lt;index&gt;   TheHive3 ElasticSearch index name\n  -x, --es-index-version &lt;index&gt;\n                           TheHive3 ElasticSearch index name version number (default: autodetect)\n  -a, --es-keepalive &lt;duration&gt;\n                           TheHive3 ElasticSearch keepalive\n  -p, --es-pagesize &lt;value&gt;\n                           TheHive3 ElasticSearch page size\n  -s, --es-single-type &lt;bool&gt;\n                           Elasticsearch single type\n  -y, --transaction-pagesize &lt;value&gt;\n                           page size for each transaction\n  -t, --thread-count &lt;value&gt;\n                           number of threads\n  --max-case-age &lt;duration&gt;\n                           migrate only cases whose age is less than &lt;duration&gt;\n  --min-case-age &lt;duration&gt;\n                           migrate only cases whose age is greater than &lt;duration&gt;\n  --case-from-date &lt;date&gt;  migrate only cases created from &lt;date&gt;\n  --case-until-date &lt;date&gt;\n                           migrate only cases created until &lt;date&gt;\n  --case-from-number &lt;number&gt;\n                           migrate only cases from this case number\n  --case-until-number &lt;number&gt;\n                           migrate only cases until this case number\n  --max-alert-age &lt;duration&gt;\n                           migrate only alerts whose age is less than &lt;duration&gt;\n  --min-alert-age &lt;duration&gt;\n                           migrate only alerts whose age is greater than &lt;duration&gt;\n  --alert-from-date &lt;date&gt;\n                           migrate only alerts created from &lt;date&gt;\n  --alert-until-date &lt;date&gt;\n                           migrate only alerts created until &lt;date&gt;\n  --include-alert-types &lt;type&gt;,&lt;type&gt;...\n                           migrate only alerts with this types\n  --exclude-alert-types &lt;type&gt;,&lt;type&gt;...\n                           don't migrate alerts with this types\n  --include-alert-sources &lt;source&gt;,&lt;source&gt;...\n                           migrate only alerts with this sources\n  --exclude-alert-sources &lt;source&gt;,&lt;source&gt;...\n                           don't migrate alerts with this sources\n  --max-audit-age &lt;duration&gt;\n                           migrate only audits whose age is less than &lt;duration&gt;\n  --min-audit-age &lt;duration&gt;\n                           migrate only audits whose age is greater than &lt;duration&gt;\n  --audit-from-date &lt;date&gt;\n                           migrate only audits created from &lt;date&gt;\n  --audit-until-date &lt;date&gt;\n                           migrate only audits created until &lt;date&gt;\n  --include-audit-actions &lt;value&gt;\n                           migration only audits with this action (Update, Creation, Delete)\n  --exclude-audit-actions &lt;value&gt;\n                           don't migration audits with this action (Update, Creation, Delete)\n  --include-audit-objectTypes &lt;value&gt;\n                           migration only audits with this objectType (case, case_artifact, case_task, ...)\n  --exclude-audit-objectTypes &lt;value&gt;\n                           don't migration audits with this objectType (case, case_artifact, case_task, ...)\n  --case-number-shift &lt;value&gt;\n                           transpose case number by adding this value\nAccepted date formats are \"yyyyMMdd[HH[mm[ss]]]\" and \"MMdd\"\nThe Format for duration is: &lt;length&gt; &lt;unit&gt;.\nAccepted units are:\n  DAY:         d, day\n  HOUR:        h, hr, hour\n  MINUTE:      m, min, minute\n  SECOND:      s, sec, second\n  MILLISECOND: ms, milli, millisecond\n</code></pre> <p>Most of these options are filters you can apply to the program. For example, you could decide to import only some of the Cases/Alerts from your old instance: </p> <ul> <li>Import Cases/Alerts not older than X days/hours,</li> <li>Import Cases/Alerts with the ID number,</li> <li>Import part of Audit trail</li> <li>...</li> </ul> <p>Taking the assumption that you are migrating a database hosted in a remote server, with TheHive 3, a basic command line to migrate data to a new instance will be like: </p> <pre><code>/opt/thehive/bin/migrate \\\n--output /etc/thehive/application.conf \\\n--main-organisation myOrganisation \\\n--es-uri http://ELASTICSEARCH_IP_ADDRESS:9200 \\\n--es-index the_hive\n</code></pre> <p>with: </p> Option Description <code>--output</code> specifies the configuration file of TheHive 4.0 (the one that has previously been configured with at least, the database and file storage) <code>--main-organisation</code> specifies the Organisation named myOrganisation to create during the migration. The tool will then create Users, Cases and Alerts from TheHive3 under that organisation; <code>--es-uri</code> specifies the URL of the Elasticsearch server. If using authentication on Elasticsearch, <code>--input</code> option with a configuration file for TheHive3 is required <code>--es-index</code> specifies the index used in Elasticsearch. <p>Info</p> <p>The migration process can be very long, from several hours to several days, depending on the volume of data to migrate. We highly recommand to not start the application during the migration.</p>"},{"location":"thehive/operations/migration/#using-authentication-on-cassandra","title":"Using authentication on Cassandra","text":"<p>if you are using a dedicated account on Cassandra to access TheHive 4 data, this user must have permissions to create keyspaces on the database: </p> <pre><code>GRANT CREATE on ALL KEYSPACES to username;\n</code></pre>"},{"location":"thehive/operations/migration/#migration-logs","title":"Migration logs","text":"<p>The migration tool generates some logs during the process. By default, every 10 sec. a log is generated with information regarding the situation of the migration: </p> <pre><code>[info] o.t.t.m.Migrate - [Migrate cases and alerts] CaseTemplate/Task:32 Organisation:1/1 Case/Task:160/201 Case:31/52 Job:103/138 ObservableType:3/17 Alert:25/235 Audit:3207/2986 CaseTemplate:6/6 Alert/Observable:700(52ms) Case/Observable:1325/1665 User:9/9 CustomField:13/13 Case/Task/Log:20/27\n</code></pre> <p>Numbers of Observables, Cases and others are estimations and not a definite value as computing these number can be very tedious. </p> <p>Files from MISP imported with TheHive 2.13 and earlier</p> <p>It is important to notice that migrating Cases/Alerts containing MISP event that were imported with TheHive 2.13 (Sept 2017) or older, will cause observable files not being imported in TheHive 4. </p> <p>Indeed, until this version, TheHive referenced the file to the <code>AttributeId</code> in MISP and was not automatically downloaded. It then could generate a log like this: </p> <pre><code>[warn] o.t.t.m.t.Input - Pre 2.13 file observables are ignored in MISP alert ffa3a8503ab0cd4f99fc6937a8e9b827\n</code></pre>"},{"location":"thehive/operations/migration/#starting-thehive-4","title":"Starting TheHive 4","text":"<p>Once the migration process is sucessfully completed, TheHive4 can be started. </p> <p>Warning</p> <p>During the first start data are indexed and service is not available ; this can take some time. Do not stop or restart the service at this time. </p>"},{"location":"thehive/operations/troubleshooting/","title":"Troubleshooting","text":"<p>For some issues, we need extra information in logs to troubleshoot and understand to root causes. To gather and share this, please read carefully and follow these steps.  </p> <p>Warning</p> <p>ENABLING TRACE LOGS HAS SIGNIFICANT IMPACT ON PERFORMANCES. DO NOT ENABLE IT ON PRODUCTION SERVERS. </p>"},{"location":"thehive/operations/troubleshooting/#stop-thehive-service-and-ensure-it-is-stopped","title":"Stop TheHive service and ensure it is stopped","text":"<pre><code>service thehive stop\n</code></pre> <p>Ensure the service is stopped with the following command: </p> <pre><code>service thehive status\n</code></pre>"},{"location":"thehive/operations/troubleshooting/#renew-applicationlog-file","title":"Renew <code>application.log</code> file","text":"<ul> <li>in <code>/var/log/thehive</code> move the file <code>application.log</code> to <code>application.log.bak</code></li> </ul> <pre><code>mv /var/log/thehive/application.log /var/log/thehive/application.log.bak\n</code></pre>"},{"location":"thehive/operations/troubleshooting/#update-log-configuration","title":"Update log configuration","text":"<ul> <li>Edit the file <code>/etc/thehive/logback.xml</code>. Look for the line containing <code>&lt;logger name=\"org.thp\" level=\"INFO\"/&gt;</code> and update it to have following lines:</li> </ul> <pre><code>    [..]\n    &lt;logger name=\"org.thp\" level=\"TRACE\"/&gt;\n[..]\n</code></pre> <ul> <li>Save the file.</li> </ul>"},{"location":"thehive/operations/troubleshooting/#restart-the-service","title":"Restart the service","text":"<pre><code>service thehive start\n</code></pre> <p>A new log file <code>/var/log/thehive/application.log</code> should be created and filed with a huge amount of logs. </p> <p>Wait for the issue to appear and/or the application stop.</p>"},{"location":"thehive/operations/troubleshooting/#save-the-logs","title":"Save the logs","text":"<p>Copy the log file in a safe place. </p> <pre><code>cp /var/log/thehive/application.log /root\n</code></pre>"},{"location":"thehive/operations/troubleshooting/#share-it-with-us","title":"Share it with us","text":"<p>Create an issue on Github and please share context and symptoms with the log file. Please add information regarding:</p> <ul> <li>Context:  </li> <li>instance (single node/cluster, backend type, index engine)</li> <li>System: Operating System, amount of RAM, #CPU for each server/node</li> <li>Symptoms: </li> <li>what you did, how you you come to this situation,  what happened</li> <li>The log file with traces</li> </ul>"},{"location":"thehive/operations/troubleshooting/#revert","title":"Revert","text":"<p>To get back a to normal log configuration, stop thehive, update <code>logback.xml</code> file with the previous configuration, and restart the application.</p>"},{"location":"thehive/operations/update/","title":"Update guides","text":""},{"location":"thehive/operations/update/#update-from-thehive-40x-to-thehive-410","title":"Update from TheHive 4.0.x to TheHive 4.1.0","text":"<p>TheHive 4.1.0 comes with an updated application stack, with new components dedicated to performance improvement. TheHive 4.1.0 requires the usage of a dedicated index engine to manages indexed data. </p> <p>As a result, the minimum configuration required has been updated:</p> <ul> <li>If you are a new user of TheHive, follow the installation and configuration guide.</li> <li>If you are an existing user of TheHive 4.0.x, an index engine should be configured alongside the database. And wether you are using a standalone server or a cluster, the solution to implement and the configuration to update are different.</li> </ul> <p>According to the setup, the instance can use:</p> <ul> <li>A local engine, Lucene driven by TheHive</li> <li>A centralised engine, Elasticsearch.</li> </ul>"},{"location":"thehive/operations/update/#updating-a-standalone-server","title":"Updating a standalone server","text":"<p>In this case, a Lucene can be used. TheHive 4.1.0 comes with its Lucene engine. The configuration of TheHive, can be updated like this: </p> <ol> <li> <p>Create a dedicated folder for indexes (for example <code>/opt/thp/thehive/index</code>). This folder should belong to the user <code>thehive:thehive</code></p> <pre><code>mkdir /opt/thp/thehive/index\nchown -R thehive:thehive /opt/thp/thehive/index\n</code></pre> </li> <li> <p>Add the <code>index</code> configuration in the <code>db.janusgraph</code> part: </p> <pre><code>## Database Configuration\ndb {\n  provider: janusgraph\n  janusgraph {\n    ## Storage configuration\n    storage {\n      backend: cql\n      hostname: [\"127.0.0.1\"]\n      ## Cassandra authentication (if configured)\n      username: \"thehive_account\"\n      password: \"cassandra_password\"\n      cql {\n        cluster-name: thp\n        keyspace: thehive\n      }\n    }\n    ## Index configuration\n    index {\n      search {\n        backend: lucene\n        directory: /opt/thp/thehive/index\n      }\n    }\n\n  }\n}\n</code></pre> </li> <li> <p>Restart TheHive </p> <pre><code>service thehive restart\n</code></pre> </li> </ol> <p>Once TheHive configuration is updated and restarted, new indexes are created during the start-up phase.</p> <p>Warning</p> <p>The start-up phase of TheHive and the indexes creation can take a certain amount if time. This phase will be quicker once indexes exist.</p>"},{"location":"thehive/operations/update/#updating-a-cluster","title":"Updating a cluster","text":"<p>In this case, a Elasticsearch should be used, as all nodes should have access to the same index. </p> <p>Once your Elasticsearch instance is up and running, The configuration of TheHive can be updated like this: </p> <p>Here is an example of configuration, use your IP address/hostnames.</p> <pre><code>## Database Configuration\ndb {\n  provider: janusgraph\n  janusgraph {\n    ## Storage configuration\n    storage {\n      backend: cql\n      hostname: [\"10.1.2.1\", \"10.1.2.2\", \"10.1.2.3\"]\n      ## Cassandra authentication (if configured)\n      username: \"thehive_account\"\n      password: \"cassandra_password\"\n      cql {\n        cluster-name: thp\n        keyspace: thehive\n      }\n    }\n    ## Index configuration\n    index {\n      search {\n        backend : elasticsearch\n        hostname : [\"10.1.2.5\"]\n        index-name : thehive\n      }\n    }\n  }\n}                \n</code></pre> <p>In this configuration, all TheHive nodes should have the same configuration.</p> <p>Restart all nodes of the cluster. </p> <p>Info</p> <p>the cluster makes it work out ; one of the nodes manage the indexing process while others are waiting for it to be ready.</p>"},{"location":"thehive/operations/update/#more-information","title":"More information","text":"<p>More information about the configuration of database and indexes can be found in the dedicated configuration guide</p>"},{"location":"thehive/user-guides/","title":"User guides","text":"<p>Get a Quick start with TheHive or follow the guides bellow for more details:</p>"},{"location":"thehive/user-guides/#for-administrators","title":"For administrators","text":"<p>Administrators as users defined in the <code>admin</code> organisation, created by default in TheHive. Administators have the responsibility of managing the platform by defining organisations and all the platform data available for to all the organisations.</p> <ul> <li>Manage organisations</li> <li>Manage profiles, roles and permissions</li> <li>Manage Custom fields</li> <li>Manage Observable types</li> <li>Manage Analyzers templates</li> <li>Manage Tags &amp; taxonomies</li> <li>Manage Tactics, Techniques &amp; Procedures</li> <li>Platform Status</li> </ul>"},{"location":"thehive/user-guides/#for-organisation-managers","title":"For organisation managers","text":"<p>Organisation managers are users belonging to any organisation other than <code>admin</code> and having one of the following permissions to manage users, case template, custom tags and UI configuration. TheHive comes with a default role for organisation managers, called <code>org-admin</code>.</p> <ul> <li>Organisations, users and sharing</li> <li>Manage users</li> <li>Manage Case templates</li> <li>Manage custom tags</li> <li>Manage UI configurations</li> </ul>"},{"location":"thehive/user-guides/#for-analysts","title":"For Analysts","text":"<p>Analysts are user belonging to any organisation other than <code>admin</code> without organisation management permissions.</p> <ul> <li>Create Alerts</li> <li>Create Cases</li> <li>Create Tasks</li> <li>Create Observables</li> <li>Create TTPs</li> <li>Run Responders</li> <li>Run Analyzers</li> <li>Sharing Cases, Tasks and Observables</li> <li>Close Cases</li> <li>Export Cases to MISP</li> <li>User settings</li> </ul>"},{"location":"thehive/user-guides/quick-start/","title":"Quick start with TheHive","text":""},{"location":"thehive/user-guides/quick-start/#tldr","title":"TL;DR","text":"<ol> <li>Default administrator account: <code>admin@thehive.local</code>/<code>secret</code></li> <li>Login with default account</li> <li>Create an organisaton</li> <li>Create a user account</li> </ol>"},{"location":"thehive/user-guides/quick-start/#before-starting","title":"Before starting","text":"<p>Starting from TheHive 4.0-RC1, an email address is requested, and is mandatory to register a new user, and to log in the application. </p>"},{"location":"thehive/user-guides/quick-start/#intialize-thehive-4","title":"Intialize TheHive 4","text":"<p>This version of TheHive comes with a big improvement: </p> <ul> <li>Multi-tenancy support </li> <li>Fine grained permissions</li> <li>Customized user profiles (a set of permissions)</li> </ul> <p>After TheHive installation, a default organisation called \"admin\" is created and contains the initial default super administrator user, having a profile called \"admin\". We will discuss the user profiles later, but note that the \"admin\" user has all the administration permissions like:</p> <ul> <li>create organisation</li> <li>define profiles</li> <li>define observable types</li> <li>define custom fields</li> </ul> <p>Members of \"admin\" organisation are dedicated to user accounts in charge of administrating the solution. </p> <p>The initial user has the following credentials:</p> <ul> <li>login: <code>admin@thehive.local</code></li> <li>password: <code>secret</code></li> </ul> <p>This default group cannot create and own Cases or any other related objects like Tasks or Observables.</p>"},{"location":"thehive/user-guides/quick-start/#first-login","title":"First login","text":"<p>When TheHive starts the first time, you need to login using the credential of the \"admin\" user indicated above (<code>admin@thehive.local</code> / <code>secret</code>), and you will be redirected to the administration home page: List of organisations.</p> <p></p> <p>Note that this organisation cannot be deleted.</p> <p>Possible operations for the \"admin\" users (members of the \"admin\" organisation) are accessible from the \"Admin\" menu located on the header bar:</p> <p></p> <p>admin Organisation cannot manage Cases. so let's create an organisation and its users.</p>"},{"location":"thehive/user-guides/quick-start/#create-an-organisation","title":"Create an organisation","text":"<p>The initial action that a super admin have to make is to create the organisations (tenants) that will use TheHive to deal with incident response.</p> <p>From the \"List of organisations\" page, hit the \"New Organisation\" button to open the organisation dialog. The organisation name is required and must be unique.</p> <p>Hit \"Save\" to confirm.</p> <p></p>"},{"location":"thehive/user-guides/quick-start/#create-a-user","title":"Create a user","text":"<p>Once you have created an organisation you can open its details page by clicking \"Configure\". This organisation details page, for users with \"admin\" profile allows managing organisation users only.</p> <p></p> <p>You can see on this page:</p> <ul> <li>The details of the organisation: name, description, the user that created it</li> <li>A tab to manage users:</li> <li>Create them</li> <li>Edit their password, api key</li> <li>Edit their profile</li> <li>Reset their 2FA settings</li> <li>Lock and delete them</li> </ul> <p>To create a user, just click the \"Create new user\" button, that opens the user creation dialog.</p> <p></p> <p>Note: The \"Profile\" field will be populated by the profiles that can be assigned to organisation users only. (Administration profiles will not be listed).</p> <p>The first user you must create for each organisation, should be a user with \"org-admin\" profile. That profile allows all the operations within an organisation. </p> <p>A user with \"org-admin\" profile will be able to connect and configure its organisation by at least:</p> <ul> <li>Creating other users</li> <li>Creating case templates</li> </ul> <p>Once you have created the users, you can set their passwords (they will be able to change them from their own account page). To do that, click on the \"New password\" button on the corresponding user's row and then hit ENTER or click the green check button:</p> <p></p>"},{"location":"thehive/user-guides/quick-start/#login-as-org-admin-user","title":"Login as org-admin user","text":"<p>Once the user is created, (s)he can connect to TheHive and start using it based on the profile.</p> <p></p> <p>Note that users with \"org-admin\" profile have an \"Organisation\" menu in the right side corner of the header bar given access to the organisation configuration page with and additionnal tab for case template management.</p> <p></p> <p>Now that the organisation and users are created, let's define custom fields and then use them to define case templates.</p>"},{"location":"thehive/user-guides/administrators/analyzer-templates/","title":"Manage analyzer template","text":"<p>Before TheHive4, we used to call them Report templates and we allowed two types of templates:</p> <ul> <li>Short reports: used to customise the display of analysis report summary</li> <li>Long reports: used to customise the rendering of the raw report of a given analyzer report</li> </ul> <p>Starting from TheHive4, short reports have been removed, and TheHive will display the analysis summary the same way for all analyzers: display a tag using taxonomies and level color.</p>"},{"location":"thehive/user-guides/administrators/analyzer-templates/#list-analyzer-templates","title":"List analyzer templates","text":"<p>The management page is accessible from the header menu through the Admin &gt; Analyzer templates menu and required a use with the <code>manageAnalyzerTemplate</code> permission (refer to Profiles and permissions).</p> <p>Note that analyzer templates are global and common to all the organisations.</p> <p></p> <p>Analyzer templates are still customisable via the UI and can also be imported.</p>"},{"location":"thehive/user-guides/administrators/analyzer-templates/#import-analyzer-templates","title":"Import analyzer templates","text":"<p>TheHive Project provides a set of analyzer templates (we use the same <code>report-templates.zip</code> archive for backward compatibility reasons).</p> <p>The template archive is available at https://download.thehive-project.org/report-templates.zip.</p> <p>To import the zip file, click on the Import templates, this opens the import dialog. Drop the zip files or click to select it from your storage and finally click Yes, import template archive.</p> <p></p>"},{"location":"thehive/user-guides/administrators/custom-fields/","title":"Manage custom fields","text":"<p>In TheHive 4, Metrics have been removed. Why? Because metrics are simply, numeric custom fields.</p> <p>To manage Custom fields you need to login as an \"admin\" user (Member of the \"admin\" organisation) that has a profile including the <code>manageCustomField</code> permission (refer to Profiles and permissions for detailed information).</p> <p>The default \"admin\" user has that permission.</p> <p>\u26a0\ufe0f Note</p> <p>Custom fields are global to all the organisation.</p> <p></p> <p>When installing TheHive, the list of custom fields is initially empty, administrators have to populate it. </p> <p>To create a custom field, click on the \"Add custom field\" button that opens a dialog:</p> <p></p> <p>You need to set:</p> <ul> <li>a display name</li> <li>a name (automatically pre-filled by the UI based on the display name)</li> <li>a description</li> <li>a type: on of <code>string</code>, <code>intger</code>, <code>booleen</code>, <code>date</code> and <code>float</code> (new type added by TheHive 4)</li> <li>possible values (not available for <code>date</code> and <code>boolean</code> fields)</li> <li>wether the field is mandatory or not (will be prompted when you close a Case without setting its value)</li> </ul> <p>Once the custom field is created, you can edit its details or delete it:</p> <p></p> <p>Only unused custom fields can be removed:</p> <p></p>"},{"location":"thehive/user-guides/administrators/observable-types/","title":"Manage observable types","text":"<p>In TheHive4, we have big plans for observable types, since we plan to support observable templates insteand of a simple string value. But this feature is planned for the future.</p> <p>In TheHive 4.0 observable datatype are common to all the organisation, and manageable by administrators (members of the \"admin\" organisation).</p> <p>The management page is accessible from the header menu through the Admin &gt; Observable types menu and required a use with the <code>manageObservableTemplate</code> permission (refer to Profiles and permissions).</p> <p></p>"},{"location":"thehive/user-guides/administrators/organisations/","title":"Organisations","text":"<p>An organisation can't be deleted</p> <p>To create an <code>organisation</code>, clic on the New Organisation button in Admin &gt; Organisations:</p> <p></p> <p>Provide an <code>organisation</code> <code>name</code> and a <code>description</code> then clic Save:</p> <p></p>"},{"location":"thehive/user-guides/administrators/plateform-status/","title":"Plateform status","text":"<p>With the database update and the new indexing engine, a health status page has been introduced. </p> <p>This page not only displays health status for indexes, but also for global data in the database. Indeed, when an element is created, no duplicate should exist, a control is then processed. </p> <p>This is sumarised in the Data health status part.</p> <p>Accessing to this page requires to be <code>admin</code> of the plateform, or at least, have <code>managePlateform</code> permission.</p>"},{"location":"thehive/user-guides/administrators/plateform-status/#health-status-page","title":"Health status page","text":"<p>This plage can be accessed in the <code>Admin</code> organisation view. Open the <code>Admin</code> menu and click on <code>Plateform status</code></p> <p></p> <p>Note</p> <p>When opening the page, the indexes status can take a while.</p> <p></p> <p>with: </p> <ol> <li>List of indexes and their health status. Database objects number and Index objects number should be equal for a good health status</li> <li>When the status is <code>Error</code>, proceed to reindex</li> <li>List of data types health status in the database and their duplicate state</li> <li>Process for a duplicate check on a specific data type if status is XXX warning XXX</li> </ol> <p>Quand un \u00e9l\u00e9ment est cr\u00e9\u00e9 et qu'il ne doit pas y avoir de doublon (caseNumber, alert type+source+sourceRef, customField, ...), un contr\u00f4le est r\u00e9alis\u00e9 (duplicationCheck). Le r\u00e9sultat de ces contr\u00f4les sont dans la cl\u00e9 duplicateStats avec les champs :   - last pour le r\u00e9sultat du dernier check (avec le nombre de doublon et la dur\u00e9e du check en milliseconds),   - lastDate pour la date du dernier check   - global est l'aggr\u00e9gation de tous les checks depuis le lancement de TH (avec le nombre d'iterations)</p> <p>Les checks sont d\u00e9clench\u00e9s de fa\u00e7on \u00e0 limiter le nombre d'iterations quand on fait plusieurs ajouts dans un courte p\u00e9riode. needCheck indique qu'un check est en attente et duplicateTimer que je check est programm\u00e9.</p> <p>En plus des contr\u00f4les de doublon, il y a une multitude d'autres contr\u00f4les (un share doit \u00eatre attach\u00e9 \u00e0 une seule orga et un seule case, une alerte ne peut \u00eatre import\u00e9 qu'une fois, ...). Ces checks sont r\u00e9alis\u00e9s toutes les 6 heures par d\u00e9faut. On retrouve le r\u00e9sultat de ces checks dans globalStats avec la m\u00eame logique last, lastDate et global. Par contre, les cl\u00e9s ne sont pas duplicate mais un ensemble de valeurs propres \u00e0 chaque type de contr\u00f4le (orphan, extraOrganisation, nonExistentOrganisation, missingOrganisation, ...). Chaque valeur me permettent d'identifier la situation recontr\u00e9e.</p>"},{"location":"thehive/user-guides/administrators/profiles/","title":"User Profiles management","text":"<p>User profiles is a new concept introduced by TheHive4 and coming from the support of role based access control aka RBAC.</p> <p>In TheHive4, users will be assigned a Profile, within an Organisation. A Profile is composed by a set of predefined permissions.</p>"},{"location":"thehive/user-guides/administrators/profiles/#permissions","title":"Permissions","text":"<p>A Profile is a set of permissions attached to a User and an Organisation. It defines what the user can do on an object hold by the organisation. TheHive has a finite list of permissions:</p> <ul> <li>manageOrganisation (1) : the user can create, update an organisation</li> <li>manageConfig (1): the user can update configuration</li> <li>manageProfile (1): the user can create, update and delete profiles</li> <li>manageTag (1): the user can create, update and delete tags</li> <li>manageCustomField (1): the user can create, update and delete custom fields</li> <li>manageCase: the user can create, update and delete cases</li> <li>manageObservable: the user can create, update and delete observables</li> <li>manageAlert: the user can create, update and import alerts</li> <li>manageUser: the user can create, update and delete users</li> <li>manageCaseTemplate: the user can create, update and delete case template</li> <li>manageTask: the user can create, update and delete tasks</li> <li>manageShare: the user can share case, task and observable with other organisation</li> <li>manageAnalyse (2): the user can execute analyse</li> <li>manageAction (2): the user can execute actions</li> <li>manageAnalyzerTemplate (2): the user can create, update and delete analyzer template (previously named report template)</li> </ul> <p>(1) Organisations, configuration, profiles and tags are global objects. The related permissions are effective only on \u201cadmin\u201d organisation. (2) Actions, analysis and template is available only if Cortex connector is enabled</p> <p>Note</p> <p>Read information doesn\u2019t require specific permission. By default, users in an organisation can see all data shared with that organisation (cf. shares, discussed in Organisations,Users and sharing).</p>"},{"location":"thehive/user-guides/administrators/profiles/#profiles","title":"Profiles","text":"<p>We distinguish two types of profiles:</p> <ul> <li>Administration Profiles</li> <li>Organisation Profiles</li> </ul> <p>The management page is accessible from the header menu through the Admin &gt; Profiles menu and required a use with the <code>manageProfile</code> permission (refer to the section above).</p> <p>TheHive comes with default profiles but they can be updated and removed (if not used). New profiles can be created.</p> <p></p> <p>Once the New Profile button is clicked, a dialog is opened asking for the profile type, a name for the profile and a selection of permissions. Multiple selection can be made using CTRL+click.</p> <p></p> <p>If it is used, a profile can\u2019t be remove but can be updated.</p> <p>Default profiles are:</p> <ul> <li>admin: can manage all global objects and users. Can\u2019t create case.</li> <li>analyst: can manage cases and other related objects (observables, tasks, \u2026), including shring them</li> <li>org-admin: all permissions except those related to global objects</li> <li>read-only: no permission</li> </ul>"},{"location":"thehive/user-guides/administrators/tactics-techniques-procedures/","title":"Tactics, Techniques &amp; Procedures","text":"<p>TheHive 4.1.0+ is required to use TTPs</p> <p>Starting with version 4.1.0, TheHive allows to bind Cases to TTPs (Tactics, Techniques &amp; Procedures). The MITRE ATT&amp;CK framework has been chosen to define these TTPs.</p>"},{"location":"thehive/user-guides/administrators/tactics-techniques-procedures/#import-mitre-attck-patterns","title":"Import MITRE ATT&amp;CK patterns","text":"<p>To access and import MITRE ATT&amp;CK patterns definition, beeing <code>admin</code> or at least have the role <code>managePattern</code> is required.</p> <ol> <li> <p>In the admin organisation, open the <code>ATT&amp;CK Patterns</code> menu</p> <p></p> </li> <li> <p>Click on <code>Import MITRE ATT&amp;CK Patterns</code> and select the appropriate file</p> <p></p> </li> <li> <p>Ensure patterns are imported </p> <p></p> </li> </ol> <p>Tip</p> <p>A direct link to the current zip archive of MITRE ATT&amp;CK patterns let you download it quickly from the official github page.</p>"},{"location":"thehive/user-guides/administrators/tactics-techniques-procedures/#use-mitre-attck","title":"Use MITRE ATT&amp;CK","text":"<p>Refer to this page to learn how to add TTPs (Tactics, Techniques and Procedures) to a Case.</p>"},{"location":"thehive/user-guides/administrators/tags-and-taxonomies/","title":"Taxonomies and Tags","text":"<p>TheHive 4.1.0+ is required to use Taxonomies</p> <p>TheHive 4.1.0 introduces the support of Taxonomies as it is defined and published by MISP. These set of classification libraries can be used in THeHive to tag <code>Cases</code>, <code>Observables</code> and <code>Alerts</code>. </p> <p>Tip</p> <p>Not only MISP-Taxonomies are supported by TheHive, but you can also build your own by:</p> <ul> <li>Following the IETF draft https://tools.ietf.org/id/draft-dulaunoy-misp-taxonomy-format-07.html</li> <li>Draw inspiration from an existing definition file :-)</li> </ul> <p>By default, TheHive does not contain any taxonomy. </p>"},{"location":"thehive/user-guides/administrators/tags-and-taxonomies/#import-taxonomies","title":"Import taxonomies","text":"<p>To access and import taxonomies, beeing <code>admin</code> or at least have the role <code>manageTaxonomy</code> is required.</p> <ol> <li> <p>In the admin organisation, open the <code>Taxonomies</code> menu</p> <p></p> </li> <li> <p>Click on <code>Import taxonomies</code> and select the file containing the libraries</p> <p></p> </li> </ol> <p>Tip</p> <p>A direct link to the current zip archive of MISP-Taxonomies let you download it quickly.</p>"},{"location":"thehive/user-guides/administrators/tags-and-taxonomies/#enable-interesting-taxonomies","title":"Enable interesting taxonomies","text":"<p>Select the libraries you would like your user be able to use in <code>Case</code> or <code>Observables</code>, and enable it.</p>  Your browser does not support the video tag.  <p>Warning</p> <p>Enabling a taxonomy means all users of all Organisations can use one or more included tags in a <code>Case</code> or <code>Observable</code>.</p>"},{"location":"thehive/user-guides/administrators/tags-and-taxonomies/#tags-from-taxonomies-versus-free-text-tags","title":"Tags from taxonomies versus free text tags","text":"<p>In the UI, users can add free text tags, and also choose to add a tag from a library in a dedicated view. </p> <p></p> <p>Free text tags are managed at the Organisation level by users with <code>orgadmin</code> profile, or at least <code>manageTag</code> permission.</p> <p>Refer to appropriate pages to learn about how to manage custom tags, and how to use tags in TheHive.</p> <p>Info</p> <p>If a tag is imported with an <code>Alert</code> or created with the API, TheHive tries to dissect it as a machinetag. It tries to identify a namespace, a predicate and an optional value. </p> <p>If successful, and if an associated taxonomy exists and is enabled, the tag is linked to the library ; if not, it is considered as a free text tag.</p>"},{"location":"thehive/user-guides/analysts/close-case/","title":"Close Cases","text":"<p>Closing a <code>case</code> is one of the basic TheHive functionnalities. It indicates the investigations and responses on this incident are over.</p> <p>To close a <code>case</code>, you must have the <code>manageCase</code> permission (refer to Profiles and permissions)</p> <p>You can find the Close button on the <code>case</code> banner:</p> <p></p> <p>Closing a <code>case</code> requires that all <code>tasks</code> contained in the <code>case</code> are closed. If you didn't closed the <code>tasks</code> before, a pop-up will suggest you to close them all.</p> <p>Finally, provide the necessary details to close the case:</p> <ul> <li>Status: If the <code>case</code> was a True Positive, a False Positive, if this is still Indeterminate or Other (not an incident)<ul> <li>If True positive: Was there an impact (yes/no)</li> </ul> </li> <li>Summary: a summary of the incident</li> </ul> <p></p> <p>Once the details provided, clic on Close case.</p>"},{"location":"thehive/user-guides/analysts/create-alerts/","title":"Create Alerts","text":"<p>In TheHive4, creating an <code>alert</code> is possible only through the API. (refer to Create Alerts)</p> <p>To create an alert, the account must have <code>manageAlert</code> permission. (refer to Profiles and permissions)</p>"},{"location":"thehive/user-guides/analysts/create-case/","title":"Create Cases","text":"<p>Creating a <code>case</code> is one of the basic TheHive functionnalities.</p> <p>To create a <code>case</code>, you must have the <code>manageCase</code> permission (refer to Profiles and permissions)</p> <p>In TheHive banner, clic the button New case:</p> <p></p> <p>Then you can either chose to use a <code>Case template</code>, or start it from scratch using Empty case (this option may be unavailable following your <code>organisation</code> configuration):</p> <p></p> <p>Once you chose your template, fill the <code>case</code> details:</p> <ul> <li>Title *</li> <li>Date (<code>startDate</code>) *</li> <li>Severity *</li> <li>TLP/PAP *</li> <li>Tags</li> <li>Description *</li> <li>Case tasks</li> </ul> <p>Information annoted with a '*' are mandatory information. </p> <p></p> <p>Once <code>case</code> details filled, finally clic on Create case button.</p>"},{"location":"thehive/user-guides/analysts/create-observables/","title":"Create Case Observables","text":"<p>In a TheHive <code>case</code>, you can declare <code>observables</code>. </p> <p>To create an <code>observable</code>, open the Observables list (Case &gt; Observables). you must have the <code>manageCase</code> permission (refer to Profiles and permissions)</p> <p>You will find the Add observable button under the Observables tab:</p> <p></p> <p>In the pop-up, you are invited to fill the <code>observable</code>(s) details:</p> <ul> <li>Type *: The <code>observable</code> <code>dataType</code> (eg: ip, hash, domain, ...)</li> <li>Value *: Your <code>observable</code> value (eg: 8.8.8.8)<ul> <li>One observable per line: Create one <code>observable</code> per line inserted in value field.</li> <li>One single multiline observable: Create one <code>observable</code>, no matter the number of lines (useful for long URLs for example).</li> </ul> </li> <li>TLP *: Define here the way the information should be shared.</li> <li>Is IOC: Check it if this <code>observable</code> is considered as Indicator of Compromission.</li> <li>Has been sighted: Has this <code>observable</code> been sighted on your information system.</li> <li>Ignore for similarity: Do not correlate this <code>observable</code> with other similar <code>observables</code>.</li> <li>Tags **: Tag your <code>observable</code> with insightful information.</li> <li>Description **: Description of the <code>observable</code>.</li> </ul> <p>Details annoted with a '' are mandatory. Detail annoted with '*' mean at least.</p> <p></p> <p>Finally clic on Create Observable(s)</p>"},{"location":"thehive/user-guides/analysts/create-tasks/","title":"Manage Case Tasks","text":"<p>In a TheHive <code>case</code>, you can find the tab <code>tasks</code>.</p>"},{"location":"thehive/user-guides/analysts/create-tasks/#tasks-list","title":"Tasks List","text":"<p>You can consult <code>cases</code> Task list (Case &gt; Tasks). you must have the <code>manageCase</code> permission (refer to Profiles and permissions)</p> <p>The list contains the following information:</p> <ul> <li>Group: The <code>task</code> group membership</li> <li>Task: The <code>task</code> title</li> <li>Date: the startDate of the <code>task</code></li> <li>Assignee: The <code>user</code> assigned to the <code>task</code></li> <li>Actions: Delete, start/close or trigger a <code>responder</code> on the <code>task</code></li> </ul> <p></p>"},{"location":"thehive/user-guides/analysts/create-tasks/#create-a-task","title":"Create a task","text":"<p>You can create a <code>task</code> in a <code>case</code>. you must have the <code>manageCase</code> permission (refer to Profiles and permissions)</p> <p>Open your Task list and clic Create task button. On the top of the Task list a ribbon will appear, inviting you to fill the Task group and the Task title</p> <p></p>"},{"location":"thehive/user-guides/analysts/create-tasks/#task-information","title":"Task information","text":"<p>Open your <code>task</code> to retrieve it's information (Case &gt; Tasks &gt; Task)</p> <p></p>"},{"location":"thehive/user-guides/analysts/create-tasks/#task-actions","title":"Task Actions","text":"<p>Open your <code>task</code> to find the possible actions (Case &gt; Tasks &gt; Task)</p> <p>Task actions buttons are on the top-right of a Task page:</p> <p></p> <p>You can trigger the following actions on a <code>task</code>:</p> <ul> <li>Sharing: Ability to share with Linked organisations the <code>task</code></li> <li>Require Action: Declare that an action is required on this <code>task</code></li> <li>Flag: Put a flag on the <code>task</code></li> <li>Close: Close the <code>task</code></li> <li>Responders: Trigger a responder on the <code>task</code></li> </ul>"},{"location":"thehive/user-guides/analysts/create-tasks/#basic-information","title":"Basic information","text":"<p>Open your <code>task</code> to retrieve these information (Case &gt; Tasks &gt; Task)</p> <p>A <code>task</code> Basic information contains the following elements:</p> <ul> <li>Title of the <code>task</code> *</li> <li>Group of <code>tasks</code> *</li> <li>Assignee of the <code>task</code> *</li> <li>startDate of the <code>task</code> *</li> <li>Duration of the <code>task</code></li> <li>Status of the <code>task</code></li> </ul> <p>All information annoted with a '*' can be modified by clicking the pen when hovering the information.</p>"},{"location":"thehive/user-guides/analysts/create-tasks/#task-description","title":"Task description","text":"<p>Open your <code>task</code> to retrieve this information (Case &gt; Tasks &gt; Task)</p> <p>Under the Basic information, you can find the description field. It's a free text field, markdown formatted. </p>"},{"location":"thehive/user-guides/analysts/create-tasks/#task-logs","title":"Task logs","text":"<p>Open your <code>task</code> to retrieve the task logs (Case &gt; Tasks &gt; Task)</p> <p>The Add new task log allows you to create a Task log. </p> <p>Task logs are markdown formatted text. You can also attach a file to the log.</p> <p>Task logs possible actions are:</p> <ul> <li>Create a task log</li> <li>Modify a task log</li> <li>Delete a task log</li> <li>Trigger a responder on the task log</li> </ul>"},{"location":"thehive/user-guides/analysts/export-case/","title":"Export Cases to MISP","text":"<p>TheHive4 has the capability to export a <code>case</code> to a MISP instance.</p> <p>This functionnality allows you to easily share your incident and findings with communities. </p> <p>To export a <code>case</code>, you must have the <code>manageCase</code> permission (refer to Profiles and permissions)</p> <p>You also must have a MISP instance connected to your TheHive (refer to MISP Connector)</p> <p>Trigger the Export button on a <code>case</code> action ribbon (Case &gt; Export):</p> <p></p> <p>In the MISP export pop-up, you can chose the MISP instance(s) where you want to export your <code>case</code>. Clic the Export button to send your <code>case</code> to the MISP instance.</p> <p></p>"},{"location":"thehive/user-guides/analysts/run-analyzers/","title":"Run Analyzers","text":"<p>In TheHive4 you can run <code>analyzers</code> on <code>observables</code>.</p> <p>To run an <code>analyzer</code>, you must have the <code>manageAnalyse</code> permission (refer to Profiles and permissions)</p>"},{"location":"thehive/user-guides/analysts/run-analyzers/#from-an-observable-page","title":"From an observable page","text":"<p>You can trigger an <code>analyzer</code> on a single <code>observable</code> from it's page (Case &gt; Observables &gt; Observable).</p> <p>In the Analysis section, you'll find every <code>analyzers</code> available for your <code>organisation</code> and compatible with the <code>observable</code> <code>dataType</code>:</p> <p></p> <p>On the right side of the Analysis section, you can trigger the <code>analyzers</code> of your choice by clicking on the fire button, or run them all via the button Run all:</p> <p></p>"},{"location":"thehive/user-guides/analysts/run-analyzers/#from-the-observables-list","title":"From the observables list","text":"<p>You can also trigger one or more <code>analyzers</code> on one or more <code>observables</code> from the Observables list (Case &gt; Observables)</p> <p>On the left side of the Observables list, you have checkboxes to select which <code>observables</code> to act on. You can even select all of them using the checkbox that is at the very top of the Observables list: </p> <p></p> <p>Once selected, clic on the Selected observables menu, and chose Run analyzers:</p> <p></p> <p>Finally select the desired <code>analyzers</code> to trigger and clic Run selected analyzers:</p> <p></p>"},{"location":"thehive/user-guides/analysts/run-analyzers/#consult-analyzers-report","title":"Consult analyzers report","text":"<p>Once the <code>analyzer</code> has been triggered and the job terminated, you can consult the Job report directly within TheHive.</p>"},{"location":"thehive/user-guides/analysts/run-analyzers/#short-report","title":"Short report","text":"<p>In the Observables list (Case &gt; Observables), you have access to a <code>short report</code>:</p> <p></p>"},{"location":"thehive/user-guides/analysts/run-analyzers/#long-report","title":"Long report","text":"<p>On the Observable page (Case &gt; Observables &gt; Observable), in the Analysis table, you can consult a HTML formatted <code>long report</code> by clicking on the analysis link:</p> <p></p>"},{"location":"thehive/user-guides/analysts/run-responders/","title":"Run Responders","text":"<p>In TheHive4, you can run <code>responders</code> on 4 type of objects:</p> <ul> <li>A <code>case</code></li> <li>A <code>task</code></li> <li>A <code>task log</code></li> <li>An <code>observable</code></li> </ul> <p>To run a <code>responder</code>, you must have the <code>manageAction</code> permission (refer to Profiles and permissions)</p> <p>A <code>report</code> will be generated and provided to you.</p>"},{"location":"thehive/user-guides/analysts/run-responders/#from-a-case","title":"From a case","text":"<p>You can trigger a <code>responder</code> from a <code>case</code>.</p> <p>On the <code>case</code> Action ribbon, trigger the Responders button</p> <p></p>"},{"location":"thehive/user-guides/analysts/run-responders/#from-a-task","title":"From a task","text":"<p>You can trigger a <code>responder</code> from a <code>task</code> (Case &gt; Tasks &gt; Task)</p> <p>On the <code>task</code> Action ribbon, trigger the Responders button.</p> <p></p>"},{"location":"thehive/user-guides/analysts/run-responders/#from-a-task-log","title":"From a task log","text":"<p>You can trigger a <code>responder</code> from a <code>task log</code> (Case &gt; Tasks &gt; Task &gt; Task log)</p> <p>On the <code>task log</code> Action ribbon, trigger the Responders button.</p> <p></p>"},{"location":"thehive/user-guides/analysts/run-responders/#from-an-observable","title":"From an observable","text":"<p>You can trigger a <code>responder</code> from an <code>observable</code> (Case &gt; Observables &gt; Observable)</p> <p>On the <code>observable</code> Action ribbon, trigger the Responders button.</p> <p></p>"},{"location":"thehive/user-guides/analysts/run-responders/#view-responder-report","title":"View responder report","text":"<p><code>responders</code> provides you a report that can have two status:</p> <ul> <li>Success</li> <li>Failure</li> </ul> <p>The report is visible in the object where you triggered it (<code>case</code>, <code>observable</code>, <code>task</code> or <code>task log</code>)</p> <p>In addition of the status, a text report is provided allowing you to know what happens:</p> <p></p>"},{"location":"thehive/user-guides/analysts/sharing/","title":"Sharing Cases, Tasks and Observables","text":"<p>In TheHive4, you can share 3 type of objects:</p> <ul> <li>A <code>case</code></li> <li>A <code>task</code></li> <li>An <code>observable</code></li> </ul> <p>To share an object, you must have the <code>manageShare</code> permission (refer to Profiles and permissions)</p> <p>You can share only with <code>organisations</code> that are linked to your <code>organisation</code> (refer to Organisations, Users and sharing)</p>"},{"location":"thehive/user-guides/analysts/sharing/#share-a-case","title":"Share a case","text":"<p>You can share your <code>case</code> by clicking the Sharing button in the <code>case</code> Action ribbon</p> <p>When you share a <code>case</code>, you have to chose:</p> <ul> <li>To which <code>organisation(s)</code></li> <li>To which <code>profile</code></li> <li>To share <code>tasks</code> or not</li> <li>To share <code>observables</code> or not</li> </ul> <p></p>"},{"location":"thehive/user-guides/analysts/sharing/#share-a-task","title":"Share a task","text":"<p>You can share a <code>task</code> (the <code>case</code> have to be shared too for this functionnality to be available)</p> <p>At the very bottom of a Task page (Case &gt; Observables &gt; Observables), in the section Task sharing, clic on Add share</p> <p></p> <p>Then you can select to which <code>organisation</code> you will share the <code>task</code>:</p> <p></p>"},{"location":"thehive/user-guides/analysts/sharing/#share-an-observable","title":"Share an observable","text":"<p>You can share an <code>observable</code> (the <code>case</code> have to be shared too for this functionnality to be available)</p> <p>At the very bottom of a Observable page (Case &gt; Observables &gt; Observable), in the section Sharing, clic on Add share</p> <p></p> <p>Then you can select to which <code>organisation</code> you will share the <code>observable</code>:</p> <p></p>"},{"location":"thehive/user-guides/analysts/sharing/#delete-a-share","title":"Delete a share","text":"<p>You can cancel the share of an object. </p> <p>For each object type, go to the Share list and trigger the Delete button in the Actions column:</p> <p></p>"},{"location":"thehive/user-guides/analysts/ttps/","title":"Tactics, Techniques and Procedures","text":"<p>In TheHive4 you can enrich your <code>cases</code> with TTPs.</p> <p>To manage a <code>case</code> <code>TTPs</code>, you must have the <code>manageCase</code> permission (refer to Profiles and permissions)</p>"},{"location":"thehive/user-guides/analysts/ttps/#add-a-ttp-to-a-case","title":"Add a TTP to a case","text":"<p>To add a <code>TTP</code> to a <code>case</code>, go to the TTPs list (Case &gt; TTPs) then clic the Add TTP button:</p> <p></p> <p>In the Add Tactic, Technique and Procedure pop-up, you can select:</p> <ul> <li>The <code>occur date</code></li> <li>The Tactic</li> <li>The Technique (you can use filters on techniques)</li> <li>The Procedure (clic to Add procedure to open this free text field)</li> </ul> <p>Finally, clic on Add TTP in the bottom of the pop-up:</p> <p></p>"},{"location":"thehive/user-guides/analysts/ttps/#delete-a-ttp-from-a-case","title":"Delete a TTP from a case","text":"<p>You can delete a <code>TTP</code> from a <code>case</code>. </p> <p>Go to the TTPs list (Case &gt; TTPs), then clic on the Delete button in the Actions column:</p> <p></p>"},{"location":"thehive/user-guides/analysts/user-settings/","title":"User settings configuration","text":"<p>Every TheHive user, has a set of settings that can be updated through the <code>Settings</code> menu located on the right hand side of the navigation bar</p> <p></p> <p>This page allows the following operations:</p> <ul> <li>User settings configuration</li> <li>Update basic Info</li> <li>Update password</li> <li>Configure MFA</li> </ul> <p></p>"},{"location":"thehive/user-guides/analysts/user-settings/#update-basic-info","title":"Update basic Info","text":"<p>This section gives the user the ability to update the his/her name and upload an avatar image</p>"},{"location":"thehive/user-guides/analysts/user-settings/#update-password","title":"Update password","text":"<p>This section is hidden by default, the user needs to enable it, set the current password and the new one twice. Clicking Save button to submit the form</p>"},{"location":"thehive/user-guides/analysts/user-settings/#configure-mfa","title":"Configure MFA","text":"<p>This section allows a user to enable 2FA authentication using a TOTP application (Google Authenticator, Authy, Microsoft Authenticator, 1password etc.) to scan the QR code or the code underneath it.</p> <p></p> <p>The 2FA will generate A TOTP that the user should supply in the MFA Code area. If it is valid, 2FA will be activated.</p> <p>A Disable button allows the user to deactivate the 2FA settings.</p> <p></p> <p>A user with 2FA activated, will be prompted to provide a TOTP during login process.</p> <p></p>"},{"location":"thehive/user-guides/organisation-managers/case-templates/","title":"Case Templates","text":"<p>Some cases may share the same structure (<code>customfields</code>, <code>tags</code>, <code>tasks</code>, <code>description</code>, ...). Templates are here to automatically add tasks, description, metrics and custom fields while creating a new case. A user can choose to create an empty case or based on a registered template.</p>"},{"location":"thehive/user-guides/organisation-managers/case-templates/#list-case-templates","title":"List case templates","text":"<p>The management of the case templates is accessible through the menu Organisation &gt; Case Templates . To manage them your profile must have the permission 'manageCaseTemplate' (refer to Profiles and permissions).</p>"},{"location":"thehive/user-guides/organisation-managers/case-templates/#create-or-upload-template","title":"Create or upload template","text":""},{"location":"thehive/user-guides/organisation-managers/case-templates/#create-a-case-template","title":"Create a case template","text":"<p>In the case templates management page, clic the <code>New template</code> button (Organisation &gt; Case Templates &gt; New Template). </p> <p></p> <p>In the case template you can set:</p> <ul> <li>Title prefix</li> <li>Severity</li> <li>TLP/PAP</li> <li>Tags</li> <li>Description</li> <li>Tasks</li> <li>Customfields </li> </ul> <p>Two fields are mandatory: </p> <ul> <li>Template name (should be unique)</li> <li>Description</li> </ul>"},{"location":"thehive/user-guides/organisation-managers/case-templates/#import-a-case-template","title":"Import a case template","text":"<p>You can also import your case template using a file in JSON format by clicking on the <code>Import template</code> button (Organisation &gt; Case templates &gt; Import template)</p>"},{"location":"thehive/user-guides/organisation-managers/case-templates/#edit-a-case-template","title":"Edit a case template","text":"<p>To edit a case template, open the case template list and clic the edit button on the actions column (Organisation &gt; Case Templates &gt; Edit).</p> <p></p>"},{"location":"thehive/user-guides/organisation-managers/case-templates/#export-a-case-template","title":"Export a case template","text":"<p>To export a case template, open the case template list and clic the export button on the actions column (Organisation &gt; Case Templates &gt; Export).</p> <p></p>"},{"location":"thehive/user-guides/organisation-managers/case-templates/#delete-a-case-template","title":"Delete a case template","text":"<p>To delete a case template, open the case template list and clic the export button on the actions column (Organisation &gt; Case Templates &gt; Export).</p> <p></p>"},{"location":"thehive/user-guides/organisation-managers/custom-tags/","title":"Custom Tags","text":"<p><code>custom tags</code> are <code>tags</code> manually created (out of libraries). </p> <p>You must have the permission <code>manageTag</code> on your profile to manage custom tags. (refer to Profiles and permissions)</p>"},{"location":"thehive/user-guides/organisation-managers/custom-tags/#list-custom-tags","title":"List custom tags","text":"<p>You can find the list of your <code>custom tags</code> in Organization &gt; Custom tags.</p> <p>The list contains the following information, for each <code>tag</code>:</p> <ul> <li>Number of <code>cases</code> tagged</li> <li>Number of <code>alerts</code> tagged</li> <li>Number of <code>observables</code> tagged</li> <li>Number of <code>case templates</code> containing the tag</li> </ul> <p></p>"},{"location":"thehive/user-guides/organisation-managers/custom-tags/#modify-a-custom-tag-border-colour","title":"Modify a custom-tag border colour","text":"<p>You can modify your custom tags border colours. </p> <p>In the <code>custom tags</code> list (Organization &gt; Custom tags), in the Colour column, clic on the square or colour code value to modify it. This will apply to all <code>cases</code>, <code>alerts</code> and <code>observables</code> that contains the <code>tag</code>.</p> <p></p>"},{"location":"thehive/user-guides/organisation-managers/custom-tags/#delete-a-custom-tag","title":"Delete a custom tag","text":"<p>You can also delete a custom tag. </p> <p>In the <code>custom tags</code> list (Organization &gt; Custom tags), in the Actions column, clic on the delete button</p> <p>\u26a0\ufe0f Note</p> <p>Deleting a <code>custom tag</code> will delete the <code>tag</code> on each object containing it.</p>"},{"location":"thehive/user-guides/organisation-managers/organisations-users-sharing/","title":"Organisations, Users and sharing","text":""},{"location":"thehive/user-guides/organisation-managers/organisations-users-sharing/#user-role-profile-and-permission","title":"User role, profile and permission","text":""},{"location":"thehive/user-guides/organisation-managers/organisations-users-sharing/#user","title":"User","text":"<p>In TheHive, a user is a member of one or more organisations. One user has a profile for each organisation and can have different profiles for different organisations. For example:</p> <ul> <li>\u201canalyst\u201d in \u201corganisationA\u201d;</li> <li>and \u201cadmin\u201d in \u201corganisationB\u201d;</li> <li>and \u201cread-only\u201d in \u201corganisationC\u201d.</li> </ul>"},{"location":"thehive/user-guides/organisation-managers/organisations-users-sharing/#organisations-and-sharing","title":"Organisations and sharing","text":"<p>TheHive comes with a default organisation named \"admin\" and is dedicated to users with administrator permissions of TheHive instance. This organisation is very specific so that it can manage global objects and cannot contain cases or any other related elements. </p> <p>By default, organisations can\u2019t see each other, and can't share with any. To do so, an organisation must be \"linked\" with another one.  Only super administrators or users with manageOrganisation permissions can give the ability of a organisation to see an other one. This ability named \u201clink\u201d is unidirectional. </p>"},{"location":"thehive/user-guides/organisation-managers/organisations-users-sharing/#link-with-other-organisations","title":"Link with other organisations","text":"<p>To share a case with another organisation, a user must be able to see it: its organisation must be \"linked\" with the targeted organisation. </p> <p></p> <p></p>"},{"location":"thehive/user-guides/organisation-managers/organisations-users-sharing/#share-and-effective-permissions","title":"Share and effective permissions","text":"<p>When a user creates a case, the case is linked to the user\u2019s organisation with the profile \u201corg-admin\u201d. It means that there is no restriction, the effective permissions are the permissions the user has in his organisation.</p> <p>If he decides to share that case with another organisation, he must choose the profile applied on that share.</p> <p></p> <p>To exerce a action on a case, the related permission must be present in the user profile and in the case share.</p> <p></p> <p>When you share a case, you can share its tasks or observables but it is not mandatory. Tasks (and observables) can be unitary shared.</p> <p></p> <p></p> <p>They can be shared only with organisations for which case is already shared. A case can be shared only once for a given organisation. Thus a case an its tasks/observables are shared with the same permissions for the same organisation.</p>"},{"location":"thehive/user-guides/organisation-managers/ui-configuration/","title":"UI configuration","text":"<p>You can change some user interface settings in the page UI Configuration (Organisation &gt; UI Configuration)</p> <p>You must have the permission <code>manageConfig</code> on your profile to manage UI Configuration. (refer to Profiles and permissions)</p> <p></p>"},{"location":"thehive/user-guides/organisation-managers/ui-configuration/#hide-empty-case-button","title":"Hide Empty Case button","text":"<p>Check this checkbox to prevent your analyst to create a <code>case</code> without using a <code>case template</code>.</p>"},{"location":"thehive/user-guides/organisation-managers/ui-configuration/#merge-alerts-into-closed-cases","title":"Merge alerts into closed cases","text":"<p>Check this checkbox to disallow merging <code>alerts</code> into closed <code>cases</code></p>"},{"location":"thehive/user-guides/organisation-managers/ui-configuration/#select-the-default-filter-of-alert-case-similarity-panel","title":"Select the default filter of alert case similarity panel","text":"<p>In this dropdown list, you can chose from various filter the default one used in <code>alerts</code> or <code>cases</code> similarity panel</p>"},{"location":"thehive/user-guides/organisation-managers/ui-configuration/#define-the-default-date-format-used-to-display-dates","title":"Define the default date format used to display dates","text":"<p>Define the time format used in your <code>organisation</code>.</p>"},{"location":"thehive/user-guides/organisation-managers/users-management/","title":"Users management","text":"<p>In TheHive4 you can manage <code>users</code> that belongs to your <code>organisation</code> in the Users page (Organisation &gt; Users)</p> <p>You must have the permission <code>manageUser</code> on your profile to manage <code>users</code> of your <code>organisation</code>. (refer to Profiles and permissions)</p>"},{"location":"thehive/user-guides/organisation-managers/users-management/#create-new-user","title":"Create new user","text":"<p>You can create a new <code>user</code> in your <code>organisation</code>. clic the Create new user button in the Users page (Organisation &gt; Users)</p> <p>You must provide the following information (they are all mandatory):</p> <ul> <li>Organisation (autmatically filled, non modifiable)</li> <li>Login (This will be used by the <code>user</code> to authenticate)</li> <li>Full Name (This will be used as display name)</li> <li>Profile (drop-down list to set a profile, that will define <code>user</code> <code>permissions</code>)</li> </ul> <p></p>"},{"location":"thehive/user-guides/organisation-managers/users-management/#list-users","title":"List users","text":"<p>You can list the <code>users</code> that belongs to your <code>organisation</code> in the Users page (Organisation &gt; Users)</p> <p>In this list you can find the following information:</p> <ul> <li>Status</li> <li>Login</li> <li>Full Name</li> <li>Profile</li> <li>API Key</li> <li>MFA activation </li> <li>Creation and last update dates</li> </ul>"},{"location":"thehive/user-guides/organisation-managers/users-management/#set-or-modify-a-user-password","title":"Set or modify a user password","text":"<p>To set or modify a <code>user</code> password, clic the button New password (if the user never had a password) or Edit password in the column Password of the User list (Organisation &gt; Users)</p>"},{"location":"thehive/user-guides/organisation-managers/users-management/#create-renew-revoke-or-reveal-an-user-api-key","title":"Create, renew, revoke or reveal an user API Key","text":"<p>In the column API Key of the <code>user</code> list (Organisation &gt; Users), you can:</p> <ul> <li>Create an API Key if the <code>user</code> never had one before</li> <li>Renew the <code>user</code> API Key</li> <li>Revoke the <code>user</code> API Key</li> <li>Reveal the <code>user</code>API Key in your user interface.</li> </ul> <p></p>"},{"location":"thehive/user-guides/organisation-managers/users-management/#edit-user-information","title":"Edit user information","text":"<p>You can edit the following user information from the user list (Organisation &gt; Users):</p> <ul> <li>Full name</li> <li>Profile</li> </ul> <p>To edit an <code>user</code> information, clic the Edit user button on the Actions column:</p> <p></p>"},{"location":"thehive/user-guides/organisation-managers/users-management/#lock-an-user","title":"Lock an user","text":"<p>Locking an <code>user</code> make the account unusable for any action. You can lock an <code>user</code> from the User list (Organisation &gt; Users).</p> <p>To lock an <code>user</code>, clic on the lock button:</p> <p></p>"},{"location":"thehive/user-guides/organisation-managers/users-management/#delete-an-user","title":"Delete an user","text":"<p>You can delete an <code>user</code> from your organisation via the User list (Organisation &gt; Users)</p> <p>\u26a0\ufe0f Note</p> <p>Deleting an <code>user</code> is irrevocable. Recreating an <code>user</code> with the same information will not reattribute the <code>cases</code> the previous account was assigned to.</p> <p>To delete an user, clic on the trash icon:</p> <p></p>"}]}